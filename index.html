<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>久书的Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  
  
    <link rel="alternate" href="/atom.xml" title="久书的Blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
    
<link rel="stylesheet" href="/localshare/css/share.css">

  
  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">久书的Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/."><i class="fa fa-home"></i> Home</a>
        
          <a class="main-nav-link" href="/archives/"><i class="fa fa-archive"></i> Archive</a>
        
          <a class="main-nav-link" href="/about/"><i class="fa fa-user"></i> About</a>
        
          <a class="main-nav-link" href="/atom.xml"><i class="fa fa-rss"></i> RSS</a>
        
      </nav>
    </div>
    <div id="search-form">
      <div id="result-mask" class="hide"></div>
      <label><input id="search-key" type="text" autocomplete="off" placeholder="search"></label>
      <div id="result-wrap" class="hide">
        <div id="search-result"></div>
      </div>
      <div class="hide">
        <template id="search-tpl">
          <div class="item">
            <a href="/{path}" title="{title}">
              <div class="title">{title}</div>
              <div class="time">{date}</div>
              <div class="tags">{tags}</div>
            </a>
          </div>
        </template>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  <article id="post-CNN代码入门" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/09/13/CNN%E4%BB%A3%E7%A0%81%E5%85%A5%E9%97%A8/">CNN代码入门</a>
    </h1>
  


      </header>
    
    <div class="article-meta">
      
      <span class="article-date">
  <i class="fa fa-date"></i>
  <time class="dt-published" datetime="2024-09-13T07:23:19.000Z" itemprop="datePublished">2024年09月13日</time>
</span>
      
      
      
<a href="/2024/09/13/CNN%E4%BB%A3%E7%A0%81%E5%85%A5%E9%97%A8/#comments" class="article-comment-link">
  
  <i class="fa fa-commt"></i>
  Guestbook
</a>


    </div>
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="1D-CNN代码入门"><a href="#1D-CNN代码入门" class="headerlink" title="1D-CNN代码入门"></a>1D-CNN代码入门</h1><h2 id="分类流程"><a href="#分类流程" class="headerlink" title="分类流程"></a>分类流程</h2><p>高光谱图像分类的主要步骤包括：</p>
<ol>
<li><p><strong>数据预处理</strong>：去噪、降维、校正等。</p>
</li>
<li><p><strong>特征提取</strong>：从原始数据中提取有意义的特征。</p>
</li>
<li><p><strong>训练模型</strong>：使用标记的训练数据训练分类模型。</p>
</li>
<li><p><strong>测试模型</strong>：评估模型性能，调整参数。</p>
</li>
<li><p><strong>分类</strong>：应用模型对未标记的数据进行分类。</p>
</li>
</ol>
<h2 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pathlib  <span class="comment"># 用于路径处理，使代码更加跨平台</span></span><br><span class="line"><span class="keyword">import</span> random  <span class="comment"># 提供随机抽样和随机数生成功能</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio  <span class="comment"># 用于加载 .mat 格式的文件（MATLAB文件）</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf  <span class="comment"># 主要用于创建TFRecord文件和深度学习的相关操作</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os  <span class="comment"># 用于操作文件和目录</span></span><br><span class="line"><span class="keyword">import</span> unit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Data</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args</span>):</span><br><span class="line">        <span class="variable language_">self</span>.data_path = args.data_path  <span class="comment"># 数据路径</span></span><br><span class="line">        <span class="variable language_">self</span>.train_num = args.train_num  <span class="comment"># 训练样本的数量或比例</span></span><br><span class="line">        <span class="variable language_">self</span>.seed = args.seed  <span class="comment"># 随机种子，用于确保数据集划分的随机性一致。</span></span><br><span class="line">        <span class="variable language_">self</span>.data_name = args.data_name  <span class="comment"># 数据集名称</span></span><br><span class="line">        <span class="variable language_">self</span>.result = args.result  <span class="comment"># 存放处理结果的文件夹路径</span></span><br><span class="line">        <span class="variable language_">self</span>.tfrecords = args.tfrecords  <span class="comment"># 存放TFRecord文件的文件夹路径。</span></span><br><span class="line">        <span class="variable language_">self</span>.args = args  <span class="comment"># 方便整个参数对象可以在类中随时使用</span></span><br><span class="line">        <span class="comment"># 从指定路径加载 .mat 格式的数据文件，并将其存储为 self.data_dict</span></span><br><span class="line">        <span class="variable language_">self</span>.data_dict = sio.loadmat(<span class="built_in">str</span>(pathlib.Path(<span class="variable language_">self</span>.data_path, <span class="variable language_">self</span>.data_name + <span class="string">&#x27;.mat&#x27;</span>)))</span><br><span class="line">        <span class="comment"># 加载data_name_gt.mat，并将其存储为 self.data_gt_dict。</span></span><br><span class="line">        <span class="variable language_">self</span>.data_gt_dict = sio.loadmat(<span class="built_in">str</span>(pathlib.Path(<span class="variable language_">self</span>.data_path, <span class="variable language_">self</span>.data_name + <span class="string">&#x27;_gt.mat&#x27;</span>)))</span><br><span class="line">        <span class="comment"># 从 self.data_dict 的键列表中筛选出不以 __ 开头的键（因为MAT文件中的一些元数据键通常以 __ 开头），并选			# 择第一个有效的键作为 data_name</span></span><br><span class="line">        data_name = [t <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">list</span>(<span class="variable language_">self</span>.data_dict.keys()) <span class="keyword">if</span> <span class="keyword">not</span> t.startswith(<span class="string">&#x27;__&#x27;</span>)][<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 与上一行逻辑相同，从地面真值字典中筛选出有效的键，存储为 data_gt_name</span></span><br><span class="line">        data_gt_name = [t <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">list</span>(<span class="variable language_">self</span>.data_gt_dict.keys()) <span class="keyword">if</span> <span class="keyword">not</span> t.startswith(<span class="string">&#x27;__&#x27;</span>)][<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 使用之前获取的 data_name 作为键，从 self.data_dict 中提取实际数据</span></span><br><span class="line">        <span class="variable language_">self</span>.data = <span class="variable language_">self</span>.data_dict[data_name]</span><br><span class="line">        <span class="comment"># 对数据进行归一化，并将其类型转换为 float32，以便后续的深度学习模型处理</span></span><br><span class="line">        <span class="variable language_">self</span>.data = unit.max_min(<span class="variable language_">self</span>.data).astype(np.float32)</span><br><span class="line">        <span class="comment"># 从 self.data_gt_dict 中提取地面真值数据，使用之前获取的 data_gt_name 作为键，并将其转换为 int64 类    			 # 型，方便后续的标签处理。</span></span><br><span class="line">        <span class="variable language_">self</span>.data_gt = <span class="variable language_">self</span>.data_gt_dict[data_gt_name].astype(np.int64)</span><br><span class="line">        <span class="comment"># 获取数据的第三个维度，并将其赋值给 self.dim，以便后续进行数据维度处理。</span></span><br><span class="line">        <span class="variable language_">self</span>.dim = <span class="variable language_">self</span>.data.shape[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实现了对数据标签的处理和映射操作，筛选出数量大于400的类别，</span></span><br><span class="line">    <span class="comment"># 并将类别重新映射到0到8之间的整数，最后返回映射后的数据标签数组。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">read_data</span>(<span class="params">self</span>):</span><br><span class="line">        data = <span class="variable language_">self</span>.data</span><br><span class="line">        data_gt = <span class="variable language_">self</span>.data_gt</span><br><span class="line">        <span class="comment"># 如果使用PaviaU数据集则进行一下操作</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.data_name == <span class="string">&#x27;PaviaU&#x27;</span>:</span><br><span class="line">            imGIS = data_gt</span><br><span class="line">            origin_num = np.zeros(shape=[<span class="number">17</span>], dtype=<span class="built_in">int</span>)  <span class="comment"># Todo 为什么是17? </span></span><br><span class="line">            <span class="comment"># 统计data_gt每个类别的像素数量，存储在 origin_num 中</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(imGIS.shape[<span class="number">0</span>]):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(imGIS.shape[<span class="number">1</span>]):</span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">17</span>):</span><br><span class="line">                        <span class="keyword">if</span> imGIS[i][j] == k:</span><br><span class="line">                            origin_num[k] += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 只筛选出像素数量大于400的类别</span></span><br><span class="line">            index = <span class="number">0</span></span><br><span class="line">            data_num = np.zeros(shape=[<span class="number">9</span>], dtype=<span class="built_in">int</span>)  <span class="comment"># per calsses&#x27;s num</span></span><br><span class="line">            data_label = np.zeros(shape=[<span class="number">9</span>], dtype=<span class="built_in">int</span>)  <span class="comment"># original labels</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(origin_num)):</span><br><span class="line">                <span class="keyword">if</span> origin_num[i] &gt; <span class="number">400</span>:</span><br><span class="line">                    data_num[index] = origin_num[i]</span><br><span class="line">                    data_label[index] = i</span><br><span class="line">                    index += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 将类别映射到0到8之间</span></span><br><span class="line">            iG = np.zeros([imGIS.shape[<span class="number">0</span>], imGIS.shape[<span class="number">1</span>]], dtype=imGIS.dtype)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(imGIS.shape[<span class="number">0</span>]):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(imGIS.shape[<span class="number">1</span>]):</span><br><span class="line">                    <span class="keyword">if</span> imGIS[i, j] <span class="keyword">in</span> data_label:</span><br><span class="line">                        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data_label)):</span><br><span class="line">                            <span class="keyword">if</span> imGIS[i][j] == data_label[k]:</span><br><span class="line">                                iG[i, j] = k + <span class="number">1</span></span><br><span class="line">                                <span class="keyword">continue</span></span><br><span class="line">            imGIS = iG</span><br><span class="line">            <span class="comment"># 处理数据标签，生成训练集和测试集的像素位置信息，并为后续的数据处理和训练准备数据格式合适的特征			    # 类型。</span></span><br><span class="line">            data_gt = imGIS</span><br><span class="line">            <span class="variable language_">self</span>.data_gt = data_gt</span><br><span class="line">        <span class="comment"># 保存数据信息：将数据维度、特征、标签等信息保存为 info.mat 文件。</span></span><br><span class="line">        sio.savemat(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;info.mat&#x27;</span>), &#123;</span><br><span class="line">            <span class="string">&#x27;shape&#x27;</span>: <span class="variable language_">self</span>.data.shape,</span><br><span class="line">            <span class="string">&#x27;data&#x27;</span>: <span class="variable language_">self</span>.data,</span><br><span class="line">            <span class="string">&#x27;data_gt&#x27;</span>: <span class="variable language_">self</span>.data_gt,</span><br><span class="line">            <span class="string">&#x27;dim&#x27;</span>: <span class="variable language_">self</span>.data.shape[<span class="number">2</span>],</span><br><span class="line">            <span class="string">&#x27;class_num&#x27;</span>: np.<span class="built_in">max</span>(<span class="variable language_">self</span>.data_gt)</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取类别数</span></span><br><span class="line">        class_num = np.<span class="built_in">max</span>(data_gt)</span><br><span class="line">        <span class="comment"># 按类分割像素位置：data_pos 保存每个类别的像素位置。</span></span><br><span class="line">        data_pos = &#123;i: [] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, class_num + <span class="number">1</span>)&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data_gt.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(data_gt.shape[<span class="number">1</span>]):</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, class_num + <span class="number">1</span>):</span><br><span class="line">                    <span class="keyword">if</span> data_gt[i, j] == k:</span><br><span class="line">                        data_pos[k].append([i, j])</span><br><span class="line">        <span class="comment"># 训练集和测试集划分：根据 self.train_num 按比例或固定数量随机划分训练集和测试集。</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.args.fix_seed:</span><br><span class="line">            random.seed(<span class="variable language_">self</span>.seed)</span><br><span class="line">        train_pos = <span class="built_in">dict</span>()</span><br><span class="line">        test_pos = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> data_pos.items():</span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt; <span class="variable language_">self</span>.train_num &lt; <span class="number">1</span>:</span><br><span class="line">                train_num = <span class="variable language_">self</span>.train_num * <span class="built_in">len</span>(v)  <span class="comment"># 按比例划分</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                train_num = <span class="variable language_">self</span>.train_num  <span class="comment"># 按固定数量划分</span></span><br><span class="line">            <span class="comment"># 从一个序列v中随机选择train_num个不重复的元素。 # todo 作用是什么</span></span><br><span class="line">            train_pos[k] = random.sample(v, <span class="built_in">int</span>(train_num))  </span><br><span class="line">            test_pos[k] = [i <span class="keyword">for</span> i <span class="keyword">in</span> v <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> train_pos[k]]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建TFRecord文件：将训练数据转换为 TFRecord 格式并写入文件，像素数据以字节形式存储，标签以整数形式存		   # 储。</span></span><br><span class="line">        train_pos_all = <span class="built_in">list</span>()</span><br><span class="line">        test_pos_all = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> train_pos.items():</span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> v:</span><br><span class="line">                train_pos_all.append([k, t])</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> test_pos.items():</span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> v:</span><br><span class="line">                test_pos_all.append([k, t])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 特征转换：定义转换函数，将整数和字节数据转换为 TFRecord 支持的格式  #todo 什么是TFRecord</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_int64_feature</span>(<span class="params">value</span>):</span><br><span class="line">            <span class="keyword">return</span> tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_bytes_feature</span>(<span class="params">value</span>):</span><br><span class="line">            <span class="keyword">return</span> tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># train data</span></span><br><span class="line">        <span class="comment"># 将训练数据按照一定的格式写入到TFRecord文件中，其中包括像素数据和对应的标签信息。</span></span><br><span class="line">        train_data_name = os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;train_data.tfrecords&#x27;</span>)</span><br><span class="line">        writer = tf.python_io.TFRecordWriter(train_data_name)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> train_pos_all:  <span class="comment"># train_pos_all为二维数组</span></span><br><span class="line">            [r, c] = i[<span class="number">1</span>]</span><br><span class="line">            pixel_t = data[r, c].tostring()</span><br><span class="line">            label_t = np.array(np.array(i[<span class="number">0</span>] - <span class="number">1</span>).astype(np.int64))</span><br><span class="line">            example = tf.train.Example(features=(tf.train.Features(</span><br><span class="line">                feature=&#123;</span><br><span class="line">                    <span class="string">&#x27;traindata&#x27;</span>: _bytes_feature(pixel_t),</span><br><span class="line">                    <span class="string">&#x27;trainlabel&#x27;</span>: _int64_feature(label_t)</span><br><span class="line">                &#125;</span><br><span class="line">            )))</span><br><span class="line">            writer.write(example.SerializeToString())</span><br><span class="line">        writer.close()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># test data</span></span><br><span class="line">        <span class="comment"># 将测试数据写入到另一个TFRecord文件中，并使用不同的特征名称。</span></span><br><span class="line">        test_data_name = os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;test_data.tfrecords&#x27;</span>)</span><br><span class="line">        writer = tf.python_io.TFRecordWriter(test_data_name)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> test_pos_all:</span><br><span class="line">            [r, c] = i[<span class="number">1</span>]</span><br><span class="line">            pixel_t = data[r, c].tostring()</span><br><span class="line">            label_t = np.array(np.array(i[<span class="number">0</span>] - <span class="number">1</span>).astype(np.int64))</span><br><span class="line">            example = tf.train.Example(features=(tf.train.Features(</span><br><span class="line">                feature=&#123;</span><br><span class="line">                    <span class="string">&#x27;testdata&#x27;</span>: _bytes_feature(pixel_t),</span><br><span class="line">                    <span class="string">&#x27;testlabel&#x27;</span>: _int64_feature(label_t)</span><br><span class="line">                &#125;</span><br><span class="line">            )))</span><br><span class="line">            writer.write(example.SerializeToString())</span><br><span class="line">        writer.close()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># map data</span></span><br><span class="line">        <span class="comment"># 将地图数据以及对应的坐标信息写入TFRecord文件。每个像素点的数值会被转换成字节数组形式，</span></span><br><span class="line">        <span class="comment"># 并作为特征保存在TFRecord中，同时记录对应的位置信息。这样的数据格式可以方便地用于后续的数据处理和训			  # 练。</span></span><br><span class="line">        map_data_name = os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;map_data.tfrecords&#x27;</span>)</span><br><span class="line">        writer = tf.python_io.TFRecordWriter(map_data_name)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">1</span>]):</span><br><span class="line">                <span class="keyword">if</span> data_gt[i, j] == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                pixel_t = data[i, j, :].tostring()</span><br><span class="line">                pos = [i, j]</span><br><span class="line">                pos = np.asarray(pos, dtype=np.int64).tostring()</span><br><span class="line">                example = tf.train.Example(features=(tf.train.Features(</span><br><span class="line">                    feature=&#123;</span><br><span class="line">                        <span class="string">&#x27;mapdata&#x27;</span>: _bytes_feature(pixel_t),</span><br><span class="line">                        <span class="string">&#x27;pos&#x27;</span>: _bytes_feature(pos),</span><br><span class="line">                    &#125;</span><br><span class="line">                )))</span><br><span class="line">                writer.write(example.SerializeToString())</span><br><span class="line">        writer.close()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义了一个用于解析TFRecord数据的函数data_parse。</span></span><br><span class="line">        <span class="comment"># 根据不同的数据类型对TFRecord数据集进行预处理，包括解析、洗牌、划分批次，并创建一个用于逐批次获取数据		  # 的迭代器。</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">data_parse</span>(<span class="params">self, filename, <span class="built_in">type</span>=<span class="string">&#x27;train&#x27;</span></span>):</span><br><span class="line">            dataset = tf.data.TFRecordDataset([filename])</span><br><span class="line"></span><br><span class="line">            <span class="keyword">def</span> <span class="title function_">parser_train</span>(<span class="params">record</span>):</span><br><span class="line">                keys_to_features = &#123;</span><br><span class="line">                    <span class="string">&#x27;traindata&#x27;</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">                    <span class="string">&#x27;trainlabel&#x27;</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">                &#125;</span><br><span class="line">                features = tf.parse_single_example(record, features=keys_to_features)</span><br><span class="line">                train_data = tf.decode_raw(features[<span class="string">&#x27;traindata&#x27;</span>], tf.float32)</span><br><span class="line">                train_label = tf.cast(features[<span class="string">&#x27;trainlabel&#x27;</span>], tf.int64)</span><br><span class="line">                shape = [<span class="variable language_">self</span>.dim]</span><br><span class="line">                train_data = tf.reshape(train_data, shape)</span><br><span class="line">                train_label = tf.reshape(train_label, [<span class="number">1</span>])</span><br><span class="line">                <span class="keyword">return</span> train_data, train_label</span><br><span class="line"></span><br><span class="line">            <span class="keyword">def</span> <span class="title function_">parser_test</span>(<span class="params">record</span>):</span><br><span class="line">                keys_to_features = &#123;</span><br><span class="line">                    <span class="string">&#x27;testdata&#x27;</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">                    <span class="string">&#x27;testlabel&#x27;</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">                &#125;</span><br><span class="line">                features = tf.parse_single_example(record, features=keys_to_features)</span><br><span class="line">                test_data = tf.decode_raw(features[<span class="string">&#x27;testdata&#x27;</span>], tf.float32)</span><br><span class="line">                test_label = tf.cast(features[<span class="string">&#x27;testlabel&#x27;</span>], tf.int64)</span><br><span class="line">                shape = [<span class="variable language_">self</span>.dim]</span><br><span class="line">                test_data = tf.reshape(test_data, shape)</span><br><span class="line">                test_label = tf.reshape(test_label, [<span class="number">1</span>])</span><br><span class="line">                <span class="keyword">return</span> test_data, test_label</span><br><span class="line"></span><br><span class="line">            <span class="keyword">def</span> <span class="title function_">parser_map</span>(<span class="params">record</span>):</span><br><span class="line">                keys_to_features = &#123;</span><br><span class="line">                    <span class="string">&#x27;mapdata&#x27;</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">                    <span class="string">&#x27;pos&#x27;</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">                &#125;</span><br><span class="line">                features = tf.parse_single_example(record, features=keys_to_features)</span><br><span class="line">                map_data = tf.decode_raw(features[<span class="string">&#x27;mapdata&#x27;</span>], tf.float32)</span><br><span class="line">                pos = tf.decode_raw(features[<span class="string">&#x27;pos&#x27;</span>], tf.int64)</span><br><span class="line">                shape = [<span class="variable language_">self</span>.dim]</span><br><span class="line">                map_data = tf.reshape(map_data, shape)</span><br><span class="line">                pos = tf.reshape(pos, [<span class="number">2</span>])</span><br><span class="line">                <span class="keyword">return</span> map_data, pos</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">type</span> == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                dataset = dataset.<span class="built_in">map</span>(parser_train)</span><br><span class="line">                dataset = dataset.shuffle(buffer_size=<span class="number">20000</span>).cache()</span><br><span class="line">                dataset = dataset.batch(<span class="variable language_">self</span>.args.batch_size)</span><br><span class="line">                dataset = dataset.repeat()</span><br><span class="line">                iterator = dataset.make_one_shot_iterator()</span><br><span class="line">                <span class="keyword">return</span> iterator.get_next()</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">type</span> == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">                dataset = dataset.<span class="built_in">map</span>(parser_test).cache()</span><br><span class="line">                dataset = dataset.batch(<span class="variable language_">self</span>.args.test_batch)</span><br><span class="line">                iterator = dataset.make_one_shot_iterator()</span><br><span class="line">                <span class="keyword">return</span> iterator.get_next()</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">type</span> == <span class="string">&#x27;map&#x27;</span>:</span><br><span class="line">                dataset = dataset.<span class="built_in">map</span>(parser_map).repeat(<span class="number">1</span>).cache()</span><br><span class="line">                dataset = dataset.batch(<span class="variable language_">self</span>.args.test_batch)</span><br><span class="line">                iterator = dataset.make_one_shot_iterator()</span><br><span class="line">                <span class="keyword">return</span> iterator.get_next()</span><br></pre></td></tr></table></figure>

<h2 id="CNN模型构建"><a href="#CNN模型构建" class="headerlink" title="CNN模型构建"></a>CNN模型构建</h2><p>以下代码实现了一个用于深度学习模型训练、测试、保存的类 <code>Model</code>，并使用 TensorFlow 处理输入数据、构建模型、定义损失函数、优化器以及训练、测试过程。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入必要的库</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型类，用于初始化模型参数和变量，以及进行训练和推断</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args, sess</span>):</span><br><span class="line">        <span class="comment"># 初始化TensorFlow会话和模型参数</span></span><br><span class="line">        <span class="variable language_">self</span>.sess = sess</span><br><span class="line">        <span class="variable language_">self</span>.result = args.result  <span class="comment"># 结果目录</span></span><br><span class="line">        <span class="comment"># 加载.mat文件中的数据，包括形状、维度、类别数、真实标签等</span></span><br><span class="line">        info = sio.loadmat(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;info.mat&#x27;</span>))</span><br><span class="line">        <span class="variable language_">self</span>.shape = info[<span class="string">&#x27;shape&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.dim = info[<span class="string">&#x27;dim&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.class_num = <span class="built_in">int</span>(info[<span class="string">&#x27;class_num&#x27;</span>])</span><br><span class="line">        <span class="variable language_">self</span>.data_gt = info[<span class="string">&#x27;data_gt&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.log = args.log  <span class="comment"># 日志目录</span></span><br><span class="line">        <span class="variable language_">self</span>.model = args.model  <span class="comment"># 模型保存目录</span></span><br><span class="line">        <span class="variable language_">self</span>.data_path = args.data_path  <span class="comment"># 数据路径</span></span><br><span class="line">        <span class="variable language_">self</span>.tfrecords = args.tfrecords  <span class="comment"># TFRecords文件路径</span></span><br><span class="line">        <span class="variable language_">self</span>.iter_num = args.iter_num  <span class="comment"># 迭代次数</span></span><br><span class="line">        <span class="comment"># 初始化全局步长</span></span><br><span class="line">        <span class="variable language_">self</span>.global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 定义训练和测试占位符</span></span><br><span class="line">        <span class="variable language_">self</span>.training = tf.placeholder(tf.<span class="built_in">bool</span>)</span><br><span class="line">        <span class="variable language_">self</span>.feed_train = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.feed_test = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 根据是否使用学习率衰减来设置学习率</span></span><br><span class="line">        <span class="keyword">if</span> args.use_lr_decay:</span><br><span class="line">            <span class="variable language_">self</span>.lr = tf.train.exponential_decay(</span><br><span class="line">                learning_rate=args.lr,</span><br><span class="line">                global_step=<span class="variable language_">self</span>.global_step,</span><br><span class="line">                decay_rate=args.decay_rete,  <span class="comment"># 注意：原代码中可能存在拼写错误，应为args.decay_rate：</span></span><br><span class="line">                decay_steps=args.decay_steps</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.lr = args.lr</span><br><span class="line">        <span class="comment"># 定义输入图像和标签的占位符</span></span><br><span class="line">        <span class="variable language_">self</span>.image = tf.placeholder(dtype=tf.float32, shape=(<span class="literal">None</span>, <span class="variable language_">self</span>.dim))</span><br><span class="line">        <span class="variable language_">self</span>.label = tf.placeholder(dtype=tf.int64, shape=(<span class="literal">None</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># 调用分类器函数获取预测标签</span></span><br><span class="line">        <span class="variable language_">self</span>.pre_label = <span class="variable language_">self</span>.classifier(<span class="variable language_">self</span>.image, <span class="variable language_">self</span>.training)</span><br><span class="line">        <span class="comment"># 设置模型保存文件名</span></span><br><span class="line">        <span class="variable language_">self</span>.model_name = os.path.join(<span class="string">&#x27;model.ckpt&#x27;</span>)</span><br><span class="line">        <span class="comment"># 定义损失函数</span></span><br><span class="line">        <span class="variable language_">self</span>.loss()</span><br><span class="line">        <span class="comment"># 初始化TensorBoard的写入器</span></span><br><span class="line">        <span class="variable language_">self</span>.summary_write = tf.summary.FileWriter(os.path.join(<span class="variable language_">self</span>.log), graph=<span class="variable language_">self</span>.sess.graph)</span><br><span class="line">        <span class="comment"># 初始化Saver用于保存和加载模型</span></span><br><span class="line">        <span class="variable language_">self</span>.saver = tf.train.Saver(max_to_keep=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self</span>):</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;loss&#x27;</span>):</span><br><span class="line">            <span class="comment"># 计算交叉熵损失</span></span><br><span class="line">            loss_cross_entropy = tf.losses.sparse_softmax_cross_entropy(<span class="variable language_">self</span>.label, <span class="variable language_">self</span>.pre_label,</span><br><span class="line">                                                                        scope=<span class="string">&#x27;loss_cross_entropy&#x27;</span>)</span><br><span class="line">            loss_cross_entropy = tf.reduce_mean(loss_cross_entropy)</span><br><span class="line">            <span class="variable language_">self</span>.loss_total = loss_cross_entropy</span><br><span class="line">            <span class="comment"># 记录总损失</span></span><br><span class="line">            tf.summary.scalar(<span class="string">&#x27;loss_total&#x27;</span>, <span class="variable language_">self</span>.loss_total)</span><br><span class="line">            <span class="comment"># 定义优化器并最小化损失</span></span><br><span class="line">        <span class="variable language_">self</span>.optimizer = tf.train.AdamOptimizer(<span class="variable language_">self</span>.lr).minimize(<span class="variable language_">self</span>.loss_total, global_step=<span class="variable language_">self</span>.global_step)</span><br><span class="line">        <span class="comment"># 合并所有summary</span></span><br><span class="line">        <span class="variable language_">self</span>.merged = tf.summary.merge_all()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义分类器结构</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">classifier</span>(<span class="params">self, feature, training=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="comment"># 扩展特征维度</span></span><br><span class="line">        feature = tf.expand_dims(feature, <span class="number">2</span>)</span><br><span class="line">        f_num = <span class="number">16</span>  <span class="comment"># 卷积核数量</span></span><br><span class="line">        <span class="comment"># 定义卷积层和批归一化层</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;classifier&#x27;</span>, reuse=tf.AUTO_REUSE):</span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;conv0&#x27;</span>):</span><br><span class="line">                conv0 = tf.layers.conv1d(feature, f_num, (<span class="number">8</span>), strides=(<span class="number">3</span>), padding=<span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">                conv0 = tf.layers.batch_normalization(conv0, training=training, momentum=<span class="number">0.99</span>)</span><br><span class="line">                conv0 = tf.nn.relu(conv0)</span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;conv1&#x27;</span>):</span><br><span class="line">                conv1 = tf.layers.conv1d(conv0, f_num * <span class="number">2</span>, (<span class="number">3</span>), strides=(<span class="number">2</span>), padding=<span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">                conv1 = tf.layers.batch_normalization(conv1, training=training, momentum=<span class="number">0.99</span>)</span><br><span class="line">                conv1 = tf.nn.relu(conv1)</span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;conv2&#x27;</span>):</span><br><span class="line">                conv2 = tf.layers.conv1d(conv1, f_num * <span class="number">4</span>, (<span class="number">3</span>), strides=(<span class="number">2</span>), padding=<span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">                conv2 = tf.layers.batch_normalization(conv2, training=training, momentum=<span class="number">0.99</span>)</span><br><span class="line">                conv2 = tf.nn.relu(conv2)</span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;global_info&#x27;</span>):</span><br><span class="line">                <span class="comment"># 使用全局平均池化或类似操作</span></span><br><span class="line">                f_shape = conv2.get_shape()</span><br><span class="line">                feature = tf.layers.conv1d(conv2, <span class="variable language_">self</span>.class_num, (<span class="built_in">int</span>(f_shape[<span class="number">1</span>])), (<span class="number">1</span>))</span><br><span class="line">                feature = tf.layers.flatten(feature)</span><br><span class="line">        <span class="keyword">return</span> feature</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载模型</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load</span>(<span class="params">self, checkpoint_dir</span>):</span><br><span class="line">        <span class="comment"># 加载保存的模型</span></span><br><span class="line">        model_name = os.path.join(checkpoint_dir)</span><br><span class="line">        ckpt = tf.train.get_checkpoint_state(model_name)</span><br><span class="line">        <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)</span><br><span class="line">            <span class="variable language_">self</span>.saver.restore(<span class="variable language_">self</span>.sess, os.path.join(model_name, ckpt_name))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Load successful.&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Load fail!!!&quot;</span>)</span><br><span class="line">            exit(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练模型</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, dataset</span>):</span><br><span class="line">        <span class="comment"># 加载训练数据</span></span><br><span class="line">        train_dataset = dataset.data_parse(os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;train_data.tfrecords&#x27;</span>), <span class="built_in">type</span>=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">        <span class="comment"># 初始化全局变量</span></span><br><span class="line">        init = tf.global_variables_initializer()</span><br><span class="line">        <span class="variable language_">self</span>.sess.run(init)</span><br><span class="line">        <span class="comment"># 开始训练循环</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.iter_num):</span><br><span class="line">            train_data, train_label = <span class="variable language_">self</span>.sess.run(train_dataset)</span><br><span class="line">            <span class="comment"># 计算学习率、损失、优化器更新和summary</span></span><br><span class="line">            lr, l, _, summary = <span class="variable language_">self</span>.sess.run([<span class="variable language_">self</span>.lr, <span class="variable language_">self</span>.loss_total, <span class="variable language_">self</span>.optimizer, <span class="variable language_">self</span>.merged],</span><br><span class="line">                                   feed_dict=&#123;<span class="variable language_">self</span>.image: train_data, <span class="variable language_">self</span>.label: train_label,</span><br><span class="line">                                   <span class="variable language_">self</span>.training: <span class="variable language_">self</span>.feed_train&#125;)</span><br><span class="line">            <span class="comment"># 每1000步打印一次信息</span></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(i, <span class="string">&#x27;step:&#x27;</span>, l, <span class="string">&#x27;learning rate:&#x27;</span>, lr)</span><br><span class="line">                <span class="comment"># 每10000步保存一次模型并测试</span></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">10000</span> == <span class="number">0</span> <span class="keyword">and</span> i != <span class="number">0</span>:</span><br><span class="line">                <span class="variable language_">self</span>.saver.save(<span class="variable language_">self</span>.sess, os.path.join(<span class="variable language_">self</span>.model, <span class="variable language_">self</span>.model_name), global_step=i)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;saved...&#x27;</span>)</span><br><span class="line">                <span class="variable language_">self</span>.test(dataset)</span><br><span class="line">                <span class="comment"># 写入TensorBoard</span></span><br><span class="line">            <span class="variable language_">self</span>.summary_write.add_summary(summary, i)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 测试模型</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">self, dataset</span>):</span><br><span class="line">        <span class="comment"># 加载测试数据</span></span><br><span class="line">        test_dataset = dataset.data_parse(os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;test_data.tfrecords&#x27;</span>), <span class="built_in">type</span>=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">        <span class="comment"># 初始化变量</span></span><br><span class="line">        acc_num, test_num = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        matrix = np.zeros((<span class="variable language_">self</span>.class_num, <span class="variable language_">self</span>.class_num), dtype=np.int64)</span><br><span class="line">        <span class="comment"># 遍历测试数据集</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                test_data, test_label = <span class="variable language_">self</span>.sess.run(test_dataset)</span><br><span class="line">                pre_label = <span class="variable language_">self</span>.sess.run(<span class="variable language_">self</span>.pre_label, feed_dict=&#123;<span class="variable language_">self</span>.image: test_data, <span class="variable language_">self</span>.label: 											test_label,</span><br><span class="line">                                 	 <span class="variable language_">self</span>.training: <span class="variable language_">self</span>.feed_test&#125;)</span><br><span class="line">                pre_label = np.argmax(pre_label, <span class="number">1</span>)</span><br><span class="line">                pre_label = np.expand_dims(pre_label, <span class="number">1</span>)</span><br><span class="line">                <span class="comment"># 更新准确率和混淆矩阵</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(pre_label.shape[<span class="number">0</span>]):</span><br><span class="line">                    [r,c]=pos[i]</span><br><span class="line">                    de_map[r,c] = pre_label[i]</span><br><span class="line">        <span class="keyword">except</span> tf.errors.OutOfRangeError:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;test end!&quot;</span>)</span><br><span class="line">        plt.subplots_adjust(left=<span class="number">0</span>, right=<span class="number">1</span>, bottom=<span class="number">0</span>, top=<span class="number">1</span>, hspace=<span class="number">0</span>, wspace=<span class="number">0</span>)</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        plt.pcolor(de_map, cmap=<span class="string">&#x27;jet&#x27;</span>)</span><br><span class="line">        plt.savefig(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;decode_map.png&#x27;</span>), <span class="built_in">format</span>=<span class="string">&#x27;png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;decode map get finished&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="主函数"><a href="#主函数" class="headerlink" title="主函数"></a>主函数</h2><p>设置 TensorFlow 环境，创建和训练模型，执行测试，并根据需要保存解码后的结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># 设置和配置深度学习任务的参数和环境，以及创建必要的文件夹。</span></span><br><span class="line"><span class="keyword">from</span> data_loader <span class="keyword">import</span> Data</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建了一个 ArgumentParser 对象，用于从命令行解析参数。</span></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;Copresion and Classification for HSI&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加参数</span></span><br><span class="line"><span class="comment"># dest=&#x27;result&#x27; 表示解析后的结果将存储在 result 属性中。</span></span><br><span class="line"><span class="comment"># default=&#x27;result&#x27; 表示如果用户未提供此参数，则使用默认值 &#x27;result&#x27;，用于指定结果的保存路径。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--result&#x27;</span>, dest=<span class="string">&#x27;result&#x27;</span>, default=<span class="string">&#x27;result&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加了 --log 参数，解析后存储在 log 属性中，默认值为 &#x27;log&#x27;，表示日志文件的保存路径。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--log&#x27;</span>, dest=<span class="string">&#x27;log&#x27;</span>, default=<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加了 --model 参数，解析后存储在 model 属性中，默认值为 &#x27;model&#x27;，用于指定模型保存的路径。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--model&#x27;</span>, dest=<span class="string">&#x27;model&#x27;</span>, default=<span class="string">&#x27;model&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加了 --tfrecords 参数，解析后存储在 tfrecords 属性中，默认值为 &#x27;tfrecords&#x27;，表示 TFRecords 数据的保存路径。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--tfrecords&#x27;</span>, dest=<span class="string">&#x27;tfrecords&#x27;</span>, default=<span class="string">&#x27;tfrecords&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加了 --data_name 参数，解析后存储在 data_name 属性中，默认值为 &#x27;PaviaU&#x27;，表示数据集的名称。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--data_name&#x27;</span>, dest=<span class="string">&#x27;data_name&#x27;</span>, default=<span class="string">&#x27;PaviaU&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加了 --data_path 参数，解析后存储在 data_path 属性中，默认值为 D:\DataSet，表示数据集存储的路径。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--data_path&#x27;</span>, dest=<span class="string">&#x27;data_path&#x27;</span>, default=<span class="string">&quot;D:\DataSet&quot;</span>)</span><br><span class="line"><span class="comment"># 添加了 --use_lr_decay 参数，解析后存储在 use_lr_decay 属性中，默认值为 True，用于指定是否使用学习率衰减。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--use_lr_decay&#x27;</span>,dest=<span class="string">&#x27;use_lr_decay&#x27;</span>,default=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 添加了 --decay_rate 参数，解析后存储在 decay_rate 属性中，默认值为 0.90，用于指定学习率衰减的速率。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--decay_rete&#x27;</span>,dest=<span class="string">&#x27;decay_rate&#x27;</span>,default=<span class="number">0.90</span>)</span><br><span class="line"><span class="comment"># 添加了 --decay_steps 参数，解析后存储在 decay_steps 属性中，默认值为 10000，用于指定学习率衰减的步数。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--decay_steps&#x27;</span>,dest=<span class="string">&#x27;decay_steps&#x27;</span>,default=<span class="number">10000</span>)</span><br><span class="line"><span class="comment"># 添加了 --learning_rate 参数，解析后存储在 lr 属性中，默认值为 0.001，用于指定初始学习率。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--learning_rate&#x27;</span>,dest=<span class="string">&#x27;lr&#x27;</span>,default=<span class="number">0.001</span>)</span><br><span class="line"><span class="comment"># 添加了 --train_num 参数，解析后存储在 train_num 属性中，默认值为 200，用于指定训练样本的数量。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--train_num&#x27;</span>,dest=<span class="string">&#x27;train_num&#x27;</span>,default=<span class="number">200</span>) <span class="comment"># intger for number and decimal for percentage</span></span><br><span class="line"><span class="comment"># 添加了 --batch_size 参数，解析后存储在 batch_size 属性中，默认值为 200，用于指定训练时每批数据的大小。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--batch_size&#x27;</span>,dest=<span class="string">&#x27;batch_size&#x27;</span>,default=<span class="number">200</span>)</span><br><span class="line"><span class="comment"># 添加了 --fix_seed 参数，解析后存储在 fix_seed 属性中，默认值为 False，用于指定是否固定随机种子以确保实验的可复现性。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--fix_seed&#x27;</span>,dest=<span class="string">&#x27;fix_seed&#x27;</span>,default=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 添加了 --seed 参数，解析后存储在 seed 属性中，默认值为 666，用于指定随机种子的值。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--seed&#x27;</span>,dest=<span class="string">&#x27;seed&#x27;</span>,default=<span class="number">666</span>)</span><br><span class="line"><span class="comment"># 添加了 --test_batch 参数，解析后存储在 test_batch 属性中，默认值为 5000，用于指定测试时的批次大小</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--test_batch&#x27;</span>,dest=<span class="string">&#x27;test_batch&#x27;</span>,default=<span class="number">5000</span>)</span><br><span class="line"><span class="comment"># 添加了 --iter_num 参数，解析后存储在 iter_num 属性中，默认值为 10000，用于指定训练的迭代次数</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--iter_num&#x27;</span>,dest=<span class="string">&#x27;iter_num&#x27;</span>,default=<span class="number">10000</span>)</span><br><span class="line"><span class="comment"># 添加了 --save_decode_map 参数，解析后存储在 save_decode_map 属性中，默认值为 True，用于指定是否保存解码图（测试结果的可视化图像）</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--save_decode_map&#x27;</span>,dest=<span class="string">&#x27;save_decode_map&#x27;</span>,default=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 添加了 --load_model 参数，解析后存储在 load_model 属性中，默认值为 False，用于指定是否加载预训练的模型。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--load_model&#x27;</span>,dest=<span class="string">&#x27;load_model&#x27;</span>,default=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># parser.parse_args() 解析命令行输入的参数，并将其存储在 args 对象中。</span></span><br><span class="line"><span class="comment"># args 中包含之前通过 add_argument 定义的所有参数的值（可以是默认值或用户在命令行中提供的值）。</span></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"><span class="comment"># 如果目录不存在创建该目录</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(args.model):</span><br><span class="line">    os.mkdir(args.model)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(args.log):</span><br><span class="line">    os.mkdir(args.log)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(args.result):</span><br><span class="line">    os.mkdir(args.result)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(args.tfrecords):</span><br><span class="line">    os.mkdir(args.tfrecords)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过迭代任务来设置和执行训练、测试和保存操作。代码中使用了自定义的Data和Model类进行数据处理、模型训练和测试阶段的操作。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># 设置Tensorflow GPU环境</span></span><br><span class="line">    <span class="comment"># 设置 GPU 设备顺序为 PCI 总线 ID，这样可以确保 TensorFlow 在使用 GPU 时按 PCI ID 顺序排序。</span></span><br><span class="line">    os.environ[<span class="string">&#x27;CUDA_DEVICE_ORDER&#x27;</span>] = <span class="string">&#x27;PCI_BUS_ID&#x27;</span></span><br><span class="line">    <span class="comment"># 指定 TensorFlow 仅使用编号为 0 的 GPU。如果系统中有多个 GPU，这个设置将限制 TensorFlow 只使用第一个 GPU</span></span><br><span class="line">    os.environ[<span class="string">&#x27;CUDA_VISIBLE_DEVICES&#x27;</span>] = <span class="string">&#x27;0&#x27;</span></span><br><span class="line">    <span class="comment"># 创建一个 ConfigProto 对象，配置 TensorFlow 会话</span></span><br><span class="line">    config = tf.ConfigProto()</span><br><span class="line">    <span class="comment"># 允许 GPU 内存动态增长。TensorFlow 会根据实际需求逐步分配 GPU 内存，而不是一次性占满所有可用内存</span></span><br><span class="line">    config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>):</span><br><span class="line">        args.<span class="built_in">id</span> = <span class="built_in">str</span>(i)</span><br><span class="line">        <span class="comment"># 重置 TensorFlow 默认图，这样每次循环开始时都能从干净的图开始，防止图中累积旧的操作和变量</span></span><br><span class="line">        tf.reset_default_graph()</span><br><span class="line">        <span class="comment"># 使用前面配置的 config 创建一个 TensorFlow 会话 sess，并在上下文管理器中使用，以确保会话在使用后正确关闭</span></span><br><span class="line">        <span class="keyword">with</span> tf.Session(config=config) <span class="keyword">as</span> sess:</span><br><span class="line">            <span class="comment"># 根据实验 ID 创建独立的目录来存储结果、日志、模型和 TFRecords 文件</span></span><br><span class="line">            args.result = os.path.join(args.result,args.<span class="built_in">id</span>)</span><br><span class="line">            args.log = os.path.join(args.log, args.<span class="built_in">id</span>)</span><br><span class="line">            args.model = os.path.join(args.model, args.<span class="built_in">id</span>)</span><br><span class="line">            args.tfrecords = os.path.join(args.tfrecords, args.<span class="built_in">id</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(args.model):</span><br><span class="line">                os.mkdir(args.model)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(args.log):</span><br><span class="line">                os.mkdir(args.log)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(args.result):</span><br><span class="line">                os.mkdir(args.result)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(args.tfrecords):</span><br><span class="line">                os.mkdir(args.tfrecords)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 创建 Data 类的实例 dataset，并读取数据</span></span><br><span class="line">            dataset = Data(args)</span><br><span class="line">            dataset.read_data()</span><br><span class="line">            <span class="comment"># 创建 Model 类的实例 model，并传入 TensorFlow 会话 sess</span></span><br><span class="line">            model = Model(args, sess)</span><br><span class="line">            <span class="comment"># 如果 args.load_model 为 False，则训练模型；如果为 True，则加载已经保存的模型</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> args.load_model:</span><br><span class="line">                model.train(dataset)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                model.load(args.model)</span><br><span class="line">            <span class="comment"># 使用测试数据集测试训练好的模型</span></span><br><span class="line">            model.test(dataset)</span><br><span class="line">            <span class="comment"># 如果 args.save_decode_map 为 True，则调用 model.save_decode_map(dataset) 保存解码后的dataset</span></span><br><span class="line">            <span class="keyword">if</span> args.save_decode_map:</span><br><span class="line">                model.save_decode_map(dataset)</span><br><span class="line">            <span class="comment"># 将目录路径重置为默认值，以便后续的操作或实验不会受到影响</span></span><br><span class="line">            args.result = <span class="string">&#x27;result&#x27;</span></span><br><span class="line">            args.log = <span class="string">&#x27;log&#x27;</span></span><br><span class="line">            args.tfrecords = <span class="string">&#x27;tfrecords&#x27;</span></span><br><span class="line">            args.model = <span class="string">&#x27;model&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<h1 id="2D-CNN代码入门"><a href="#2D-CNN代码入门" class="headerlink" title="2D-CNN代码入门"></a>2D-CNN代码入门</h1><h2 id="数据加载-1"><a href="#数据加载-1" class="headerlink" title="数据加载"></a>数据加载</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pathlib, random</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> unit, os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Data</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args</span>):</span><br><span class="line">        <span class="variable language_">self</span>.data_path = args.data_path</span><br><span class="line">        <span class="variable language_">self</span>.train_num = args.train_num</span><br><span class="line">        <span class="variable language_">self</span>.seed = args.seed</span><br><span class="line">        <span class="variable language_">self</span>.data_name = args.data_name</span><br><span class="line">        <span class="variable language_">self</span>.result = args.result</span><br><span class="line">        <span class="variable language_">self</span>.tfrecords = args.tfrecords</span><br><span class="line">        <span class="variable language_">self</span>.args = args</span><br><span class="line">        <span class="variable language_">self</span>.cube_size = args.cube_size</span><br><span class="line">        <span class="variable language_">self</span>.data_dict = sio.loadmat(<span class="built_in">str</span>(pathlib.Path(<span class="variable language_">self</span>.data_path, <span class="variable language_">self</span>.data_name + <span class="string">&#x27;.mat&#x27;</span>)))</span><br><span class="line">        <span class="variable language_">self</span>.data_gt_dict = sio.loadmat(<span class="built_in">str</span>(pathlib.Path(<span class="variable language_">self</span>.data_path, <span class="variable language_">self</span>.data_name + <span class="string">&#x27;_gt.mat&#x27;</span>)))</span><br><span class="line">        data_name = [t <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">list</span>(<span class="variable language_">self</span>.data_dict.keys()) <span class="keyword">if</span> <span class="keyword">not</span> t.startswith(<span class="string">&#x27;__&#x27;</span>)][<span class="number">0</span>]</span><br><span class="line">        data_gt_name = [t <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">list</span>(<span class="variable language_">self</span>.data_gt_dict.keys()) <span class="keyword">if</span> <span class="keyword">not</span> t.startswith(<span class="string">&#x27;__&#x27;</span>)][<span class="number">0</span>]</span><br><span class="line">        <span class="variable language_">self</span>.data = <span class="variable language_">self</span>.data_dict[data_name]</span><br><span class="line">        <span class="variable language_">self</span>.data = unit.max_min(<span class="variable language_">self</span>.data).astype(np.float32)</span><br><span class="line">        <span class="variable language_">self</span>.data_gt = <span class="variable language_">self</span>.data_gt_dict[data_gt_name].astype(np.int64)</span><br><span class="line">        <span class="variable language_">self</span>.dim = <span class="variable language_">self</span>.data.shape[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        @description 生成以某个点 (row, col) 为中心的一个 w_size x w_size 大小的局部邻域数据块（cube）。</span></span><br><span class="line"><span class="string">                 当邻域范围超出数据边界时，它会从训练或测试数据的指定标签中随机抽取样本来填充这些位置。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">	 <span class="comment"># 给出 row，col和标签，返回w_size大小的cube，flag=True表示为训练样本</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">neighbor_add</span>(<span class="params">self, row, col, labels, w_size=<span class="number">3</span>, flag=<span class="literal">True</span></span>):  </span><br><span class="line">        <span class="comment"># 计算邻域范围的半径，得到中心点</span></span><br><span class="line">        t = w_size // <span class="number">2</span></span><br><span class="line">        <span class="comment"># 初始化一个全零的三维数组 cube，大小为 w_size x w_size，深度与 self.data 的深度相同</span></span><br><span class="line">        cube = np.zeros(shape=[w_size, w_size, <span class="variable language_">self</span>.data.shape[<span class="number">2</span>]])</span><br><span class="line">        <span class="comment"># 标签值加 1，是为了避免标签为 0 的情况可能影响索引操作</span></span><br><span class="line">        labels += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 在(-t, t)遍历数据</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(-t, t + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(-t, t + <span class="number">1</span>):</span><br><span class="line">                <span class="comment"># 数据超出范围</span></span><br><span class="line">                <span class="keyword">if</span> i + row &lt; <span class="number">0</span> <span class="keyword">or</span> i + row &gt;= <span class="variable language_">self</span>.data.shape[<span class="number">0</span>] <span class="keyword">or</span> j + col &lt; <span class="number">0</span> <span class="keyword">or</span> j + col &gt;= 																						<span class="variable language_">self</span>.data.shape[<span class="number">1</span>]:</span><br><span class="line">                    <span class="comment"># 训练样本</span></span><br><span class="line">                    <span class="keyword">if</span> flag:</span><br><span class="line">                        <span class="comment"># 从 self.train_pos[labels] 中随机抽取一个样本，并将其数据填充到对应位置。</span></span><br><span class="line">                        s = random.sample(<span class="variable language_">self</span>.train_pos[labels], <span class="number">1</span>)</span><br><span class="line">                        cube[i + t, j + t] = s[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">                    <span class="comment"># 测试样本</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="comment"># 从 self.test_pos[labels] 中随机抽取一个样本，并将其数据填充到对应位置</span></span><br><span class="line">                        s = random.sample(<span class="variable language_">self</span>.test_pos[labels], <span class="number">1</span>)</span><br><span class="line">                        cube[i + t, j + t] = s[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">                <span class="comment"># 数据范围合法</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 从 self.data 中提取该位置的值，填入 cube</span></span><br><span class="line">                    cube[i + t, j + t] = <span class="variable language_">self</span>.data[i + row, j + col]</span><br><span class="line">        <span class="keyword">return</span> cube</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        @description: 对数据进行了分类、筛选、标签重编码以及训练和测试集的划分，</span></span><br><span class="line"><span class="string">                     并通过保存处理后的数据和生成相应的样本位置，为后续模型训练或测试做好准备</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">read_data</span>(<span class="params">self</span>):</span><br><span class="line">        data = <span class="variable language_">self</span>.data</span><br><span class="line">        data_gt = <span class="variable language_">self</span>.data_gt</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.data_name == <span class="string">&#x27;PaviaU&#x27;</span>:</span><br><span class="line">            imGIS = data_gt</span><br><span class="line">            origin_num = np.zeros(shape=[<span class="number">17</span>], dtype=<span class="built_in">int</span>)</span><br><span class="line">            <span class="comment"># 统计data_gt每个类别的像素数量，存储在 origin_num 中</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(imGIS.shape[<span class="number">0</span>]):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(imGIS.shape[<span class="number">1</span>]):</span><br><span class="line">                    <span class="comment"># class一共有16个故范围为(1, 17) 详见科普PPT</span></span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">17</span>):</span><br><span class="line">                        <span class="keyword">if</span> imGIS[i][j] == k:</span><br><span class="line">                            origin_num[k] += <span class="number">1</span></span><br><span class="line">            index = <span class="number">0</span></span><br><span class="line">            data_num = np.zeros(shape=[<span class="number">9</span>], dtype=<span class="built_in">int</span>)  <span class="comment"># per calsses&#x27;s num</span></span><br><span class="line">            data_label = np.zeros(shape=[<span class="number">9</span>], dtype=<span class="built_in">int</span>)  <span class="comment"># original labels</span></span><br><span class="line">            <span class="comment"># 筛选出像素数量大于400的类存储在data_num和data_label中</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(origin_num)):</span><br><span class="line">                <span class="keyword">if</span> origin_num[i] &gt; <span class="number">400</span>:</span><br><span class="line">                    data_num[index] = origin_num[i]</span><br><span class="line">                    data_label[index] = i</span><br><span class="line">                    index += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 重新标注标签</span></span><br><span class="line">            iG = np.zeros([imGIS.shape[<span class="number">0</span>], imGIS.shape[<span class="number">1</span>]], dtype=imGIS.dtype)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(imGIS.shape[<span class="number">0</span>]):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(imGIS.shape[<span class="number">1</span>]):</span><br><span class="line">                    <span class="keyword">if</span> imGIS[i, j] <span class="keyword">in</span> data_label:</span><br><span class="line">                        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data_label)):</span><br><span class="line">                            <span class="keyword">if</span> imGIS[i][j] == data_label[k]:</span><br><span class="line">                                iG[i, j] = k + <span class="number">1</span></span><br><span class="line">                                <span class="keyword">continue</span></span><br><span class="line">            imGIS = iG</span><br><span class="line"></span><br><span class="line">            data_gt = imGIS</span><br><span class="line">            <span class="variable language_">self</span>.data_gt = data_gt</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存数据到info.mat</span></span><br><span class="line">        sio.savemat(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;info.mat&#x27;</span>), &#123;</span><br><span class="line">            <span class="string">&#x27;shape&#x27;</span>: <span class="variable language_">self</span>.data.shape,</span><br><span class="line">            <span class="string">&#x27;data&#x27;</span>: <span class="variable language_">self</span>.data,</span><br><span class="line">            <span class="string">&#x27;data_gt&#x27;</span>: <span class="variable language_">self</span>.data_gt,</span><br><span class="line">            <span class="string">&#x27;dim&#x27;</span>: <span class="variable language_">self</span>.data.shape[<span class="number">2</span>],</span><br><span class="line">            <span class="string">&#x27;class_num&#x27;</span>: np.<span class="built_in">max</span>(<span class="variable language_">self</span>.data_gt)</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">        class_num = np.<span class="built_in">max</span>(data_gt)</span><br><span class="line">        data_pos = &#123;i: [] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, class_num + <span class="number">1</span>)&#125;</span><br><span class="line">        <span class="comment"># 将每个标签对应的像素位置保存到data_pos中</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data_gt.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(data_gt.shape[<span class="number">1</span>]):</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, class_num + <span class="number">1</span>):</span><br><span class="line">                    <span class="keyword">if</span> data_gt[i, j] == k:</span><br><span class="line">                        data_pos[k].append([i, j])</span><br><span class="line">        <span class="variable language_">self</span>.data_pos = data_pos</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 划分训练集和测试集</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.args.fix_seed:</span><br><span class="line">            random.seed(<span class="variable language_">self</span>.seed)</span><br><span class="line">        train_pos = <span class="built_in">dict</span>()</span><br><span class="line">        test_pos = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> data_pos.items():</span><br><span class="line">            <span class="comment"># 按比例划分</span></span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt; <span class="variable language_">self</span>.train_num &lt; <span class="number">1</span>:</span><br><span class="line">                train_num = <span class="variable language_">self</span>.train_num * <span class="built_in">len</span>(v)</span><br><span class="line">            <span class="comment"># 按数量划分</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                train_num = <span class="variable language_">self</span>.train_num</span><br><span class="line">            train_pos[k] = random.sample(v, <span class="built_in">int</span>(train_num))</span><br><span class="line">            test_pos[k] = [i <span class="keyword">for</span> i <span class="keyword">in</span> v <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> train_pos[k]]</span><br><span class="line">        <span class="variable language_">self</span>.train_pos = train_pos</span><br><span class="line">        <span class="variable language_">self</span>.test_pos = test_pos</span><br><span class="line">        <span class="comment"># 整合训练和测试样本</span></span><br><span class="line">        train_pos_all = <span class="built_in">list</span>()</span><br><span class="line">        test_pos_all = <span class="built_in">list</span>()</span><br><span class="line">        <span class="comment"># 将所有类别的训练和测试样本位置整合到 train_pos_all 和 test_pos_all 列表中</span></span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> train_pos.items():</span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> v:</span><br><span class="line">                train_pos_all.append([k, t])</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> test_pos.items():</span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> v:</span><br><span class="line">                test_pos_all.append([k, t])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将数据转换为 TensorFlow 的 Feature 格式，通常用于保存到 TFRecord 文件中</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_int64_feature</span>(<span class="params">value</span>):</span><br><span class="line">            <span class="keyword">return</span> tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_bytes_feature</span>(<span class="params">value</span>):</span><br><span class="line">            <span class="keyword">return</span> tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># train data</span></span><br><span class="line">        train_data_name = os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;train_data.tfrecords&#x27;</span>)</span><br><span class="line">        writer = tf.python_io.TFRecordWriter(train_data_name)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> train_pos_all:</span><br><span class="line">            [r, c] = i[<span class="number">1</span>]</span><br><span class="line">            <span class="comment"># 以 train_data.tfrecords 的形式保存，包含每个非背景像素的邻域数据块和像素的位置坐标</span></span><br><span class="line">            pixel_t = <span class="variable language_">self</span>.neighbor_add(r, c, i[<span class="number">0</span>] - <span class="number">1</span>, w_size=<span class="variable language_">self</span>.cube_size).astype(np.float32).tostring()</span><br><span class="line">            label_t = np.array(np.array(i[<span class="number">0</span>] - <span class="number">1</span>).astype(np.int64))</span><br><span class="line">            example = tf.train.Example(features=(tf.train.Features(</span><br><span class="line">                feature=&#123;</span><br><span class="line">                    <span class="string">&#x27;traindata&#x27;</span>: _bytes_feature(pixel_t),</span><br><span class="line">                    <span class="string">&#x27;trainlabel&#x27;</span>: _int64_feature(label_t)</span><br><span class="line">                &#125;</span><br><span class="line">            )))</span><br><span class="line">            writer.write(example.SerializeToString())</span><br><span class="line">        writer.close()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># test data</span></span><br><span class="line">        test_data_name = os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;test_data.tfrecords&#x27;</span>)</span><br><span class="line">        writer = tf.python_io.TFRecordWriter(test_data_name)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> test_pos_all:</span><br><span class="line">            [r, c] = i[<span class="number">1</span>]</span><br><span class="line">            <span class="comment"># 以 test_data.tfrecords 的形式保存，包含每个非背景像素的邻域数据块和像素的位置坐标</span></span><br><span class="line">            pixel_t = <span class="variable language_">self</span>.neighbor_add(r, c, i[<span class="number">0</span>] - <span class="number">1</span>, w_size=<span class="variable language_">self</span>.cube_size).astype(np.float32).tostring()</span><br><span class="line">            label_t = np.array(np.array(i[<span class="number">0</span>] - <span class="number">1</span>).astype(np.int64))</span><br><span class="line">            example = tf.train.Example(features=(tf.train.Features(</span><br><span class="line">                feature=&#123;</span><br><span class="line">                    <span class="string">&#x27;testdata&#x27;</span>: _bytes_feature(pixel_t),</span><br><span class="line">                    <span class="string">&#x27;testlabel&#x27;</span>: _int64_feature(label_t)</span><br><span class="line">                &#125;</span><br><span class="line">            )))</span><br><span class="line">            writer.write(example.SerializeToString())</span><br><span class="line">        writer.close()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># map data</span></span><br><span class="line">        map_data_name = os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;map_data.tfrecords&#x27;</span>)</span><br><span class="line">        writer = tf.python_io.TFRecordWriter(map_data_name)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">1</span>]):</span><br><span class="line">                <span class="keyword">if</span> data_gt[i, j] == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="comment"># 以 map_data.tfrecords 的形式保存，包含每个非背景像素的邻域数据块和像素的位置坐标</span></span><br><span class="line">                pixel_t = <span class="variable language_">self</span>.neighbor_add(i, j, <span class="number">1</span>, w_size=<span class="variable language_">self</span>.cube_size).astype(np.float32).tostring()</span><br><span class="line">                pos = [i, j]</span><br><span class="line">                pos = np.asarray(pos, dtype=np.int64).tostring()</span><br><span class="line">                example = tf.train.Example(features=(tf.train.Features(</span><br><span class="line">                    feature=&#123;</span><br><span class="line">                        <span class="string">&#x27;mapdata&#x27;</span>: _bytes_feature(pixel_t),</span><br><span class="line">                        <span class="string">&#x27;pos&#x27;</span>: _bytes_feature(pos),</span><br><span class="line">                    &#125;</span><br><span class="line">                )))</span><br><span class="line">                writer.write(example.SerializeToString())</span><br><span class="line">        writer.close()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 参考1D-CNN</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">data_parse</span>(<span class="params">self, filename, <span class="built_in">type</span>=<span class="string">&#x27;train&#x27;</span></span>):</span><br><span class="line">        dataset = tf.data.TFRecordDataset([filename])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">parser_train</span>(<span class="params">record</span>):</span><br><span class="line">            keys_to_features = &#123;</span><br><span class="line">                <span class="string">&#x27;traindata&#x27;</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">                <span class="string">&#x27;trainlabel&#x27;</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">            &#125;</span><br><span class="line">            features = tf.parse_single_example(record, features=keys_to_features)</span><br><span class="line">            train_data = tf.decode_raw(features[<span class="string">&#x27;traindata&#x27;</span>], tf.float32)</span><br><span class="line">            train_label = tf.cast(features[<span class="string">&#x27;trainlabel&#x27;</span>], tf.int64)</span><br><span class="line">            shape = [<span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.dim]</span><br><span class="line">            train_data = tf.reshape(train_data, shape)</span><br><span class="line">            train_label = tf.reshape(train_label, [<span class="number">1</span>])</span><br><span class="line">            <span class="keyword">return</span> train_data, train_label</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">parser_test</span>(<span class="params">record</span>):</span><br><span class="line">            keys_to_features = &#123;</span><br><span class="line">                <span class="string">&#x27;testdata&#x27;</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">                <span class="string">&#x27;testlabel&#x27;</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">            &#125;</span><br><span class="line">            features = tf.parse_single_example(record, features=keys_to_features)</span><br><span class="line">            test_data = tf.decode_raw(features[<span class="string">&#x27;testdata&#x27;</span>], tf.float32)</span><br><span class="line">            test_label = tf.cast(features[<span class="string">&#x27;testlabel&#x27;</span>], tf.int64)</span><br><span class="line">            shape = [<span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.dim]</span><br><span class="line">            test_data = tf.reshape(test_data, shape)</span><br><span class="line">            test_label = tf.reshape(test_label, [<span class="number">1</span>])</span><br><span class="line">            <span class="keyword">return</span> test_data, test_label</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">parser_map</span>(<span class="params">record</span>):</span><br><span class="line">            keys_to_features = &#123;</span><br><span class="line">                <span class="string">&#x27;mapdata&#x27;</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">                <span class="string">&#x27;pos&#x27;</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">            &#125;</span><br><span class="line">            features = tf.parse_single_example(record, features=keys_to_features)</span><br><span class="line">            map_data = tf.decode_raw(features[<span class="string">&#x27;mapdata&#x27;</span>], tf.float32)</span><br><span class="line">            pos = tf.decode_raw(features[<span class="string">&#x27;pos&#x27;</span>], tf.int64)</span><br><span class="line">            shape = [<span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.dim]</span><br><span class="line">            map_data = tf.reshape(map_data, shape)</span><br><span class="line">            pos = tf.reshape(pos, [<span class="number">2</span>])</span><br><span class="line">            <span class="keyword">return</span> map_data, pos</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span> == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(parser_train)</span><br><span class="line">            dataset = dataset.shuffle(buffer_size=<span class="number">20000</span>)</span><br><span class="line">            dataset = dataset.batch(<span class="variable language_">self</span>.args.batch_size)</span><br><span class="line">            dataset = dataset.repeat()</span><br><span class="line">            iterator = dataset.make_one_shot_iterator()</span><br><span class="line">            <span class="keyword">return</span> iterator.get_next()</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span> == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(parser_test)</span><br><span class="line">            dataset = dataset.batch(<span class="variable language_">self</span>.args.test_batch)</span><br><span class="line">            iterator = dataset.make_one_shot_iterator()</span><br><span class="line">            <span class="keyword">return</span> iterator.get_next()</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span> == <span class="string">&#x27;map&#x27;</span>:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(parser_map).repeat(<span class="number">1</span>)</span><br><span class="line">            dataset = dataset.batch(<span class="variable language_">self</span>.args.test_batch)</span><br><span class="line">            iterator = dataset.make_one_shot_iterator()</span><br><span class="line">            <span class="keyword">return</span> iterator.get_next()</span><br></pre></td></tr></table></figure>

<h2 id="CNN模型构建-1"><a href="#CNN模型构建-1" class="headerlink" title="CNN模型构建"></a>CNN模型构建</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>:</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        @description: 深度学习模型初始化的过程，包含了会话初始化、数据读取、参数设置、占位符定义、学习率策略、前						向传播等。通过这些步骤，模型的基本结构被搭建起来，后续可以进行训练、测试等操作</span></span><br><span class="line"><span class="string">        :param</span></span><br><span class="line"><span class="string">            sess: tensorflow session会话</span></span><br><span class="line"><span class="string">            result: 输出结果路径</span></span><br><span class="line"><span class="string">            cube_size: 每个图像立方体的大小</span></span><br><span class="line"><span class="string">            epoch: 训练的轮数</span></span><br><span class="line"><span class="string">            tfrecords: TFRecords 文件路径，用于数据存储和读取</span></span><br><span class="line"><span class="string">            global_step: 用于跟踪训练步骤的变量 trainable=False 表示它不会在反向传播过程中更新</span></span><br><span class="line"><span class="string">            use_lr_decay: 是否启用学习率衰减</span></span><br><span class="line"><span class="string">            image: 输入图像数据的占位符</span></span><br><span class="line"><span class="string">            label: 输入图像标签的占位符</span></span><br><span class="line"><span class="string">            classifier: 定义了一个分类器</span></span><br><span class="line"><span class="string">            training: 是否处于训练模式</span></span><br><span class="line"><span class="string">            train_feed 训练模式的状态</span></span><br><span class="line"><span class="string">            test_feed: 测试模式的状态</span></span><br><span class="line"><span class="string">            pre_label: 调用 classifier 函数进行前向传播，得到模型的预测输出</span></span><br><span class="line"><span class="string">            model_name: 用于保存训练中模型的检查点文件路径</span></span><br><span class="line"><span class="string">            loss() 来定义模型的损失函数和优化器</span></span><br><span class="line"><span class="string">            summary_write: 使用 TensorFlow 的 FileWriter 来记录训练过程中的日志，日志将存储在 self.log 路径下，可以用于后续在 TensorBoard 中可视化训练过程</span></span><br><span class="line"><span class="string">            saver: 使用 tf.train.Saver 定义一个保存器，用于在训练过程中保存模型的检查点。 max_to_keep=100 指定最多保存 100 个模型检查点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args, sess</span>):</span><br><span class="line">        <span class="variable language_">self</span>.sess = sess</span><br><span class="line">        <span class="variable language_">self</span>.result = args.result</span><br><span class="line">        info = sio.loadmat(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;info.mat&#x27;</span>))</span><br><span class="line">        <span class="variable language_">self</span>.shape = info[<span class="string">&#x27;shape&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.dim = info[<span class="string">&#x27;dim&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.class_num = <span class="built_in">int</span>(info[<span class="string">&#x27;class_num&#x27;</span>])</span><br><span class="line">        <span class="variable language_">self</span>.data_gt = info[<span class="string">&#x27;data_gt&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.log = args.log</span><br><span class="line">        <span class="variable language_">self</span>.model = args.model</span><br><span class="line">        <span class="variable language_">self</span>.cube_size = args.cube_size</span><br><span class="line">        <span class="variable language_">self</span>.data_path = args.data_path</span><br><span class="line">        <span class="variable language_">self</span>.epoch = args.epoch</span><br><span class="line">        <span class="variable language_">self</span>.tfrecords = args.tfrecords</span><br><span class="line">        <span class="variable language_">self</span>.global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">if</span> args.use_lr_decay:</span><br><span class="line">            <span class="variable language_">self</span>.lr = tf.train.exponential_decay(learning_rate=args.lr,</span><br><span class="line">                                                 global_step=<span class="variable language_">self</span>.global_step,</span><br><span class="line">                                                 decay_rate=args.decay_rete,</span><br><span class="line">                                                 decay_steps=args.decay_steps)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.lr = args.lr</span><br><span class="line">		  <span class="variable language_">self</span>.image = tf.placeholder(dtype=tf.float32, shape=(<span class="literal">None</span>, <span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.cube_size,                                                                      <span class="variable language_">self</span>.dim))</span><br><span class="line">        <span class="variable language_">self</span>.label = tf.placeholder(dtype=tf.int64, shape=(<span class="literal">None</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="variable language_">self</span>.classifier = <span class="variable language_">self</span>.classifer</span><br><span class="line">        <span class="variable language_">self</span>.training = tf.placeholder(tf.<span class="built_in">bool</span>)</span><br><span class="line">        <span class="variable language_">self</span>.train_feed = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.test_feed = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.pre_label = <span class="variable language_">self</span>.classifer(<span class="variable language_">self</span>.image)</span><br><span class="line">        <span class="variable language_">self</span>.model_name = os.path.join(<span class="string">&#x27;model.ckpt&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.loss()</span><br><span class="line">        <span class="variable language_">self</span>.summary_write = tf.summary.FileWriter(os.path.join(<span class="variable language_">self</span>.log), graph=<span class="variable language_">self</span>.sess.graph)</span><br><span class="line">        <span class="variable language_">self</span>.saver = tf.train.Saver(max_to_keep=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        @description: 损失函数</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;loss&#x27;</span>):</span><br><span class="line">            <span class="comment"># 使用稀疏的交叉熵作为分类任务的损失函数</span></span><br><span class="line">            loss_cross_entropy = tf.losses.sparse_softmax_cross_entropy(<span class="variable language_">self</span>.label, <span class="variable language_">self</span>.pre_label,</span><br><span class="line">                                                     scope=<span class="string">&#x27;loss_cross_entropy&#x27;</span>)</span><br><span class="line">            <span class="comment"># 对交叉熵损失求平均，得到总的损失 loss_total</span></span><br><span class="line">            loss_cross_entropy = tf.reduce_mean(loss_cross_entropy)</span><br><span class="line">            <span class="variable language_">self</span>.loss_total = loss_cross_entropy</span><br><span class="line">            <span class="comment"># 记录损失值，用于后续的可视化</span></span><br><span class="line">            tf.summary.scalar(<span class="string">&#x27;loss_total&#x27;</span>, <span class="variable language_">self</span>.loss_total)</span><br><span class="line">        <span class="comment"># 使用 Adam 优化器来最小化总损失</span></span><br><span class="line">        <span class="variable language_">self</span>.optimizer = tf.train.AdamOptimizer(<span class="variable language_">self</span>.lr).minimize(<span class="variable language_">self</span>.loss_total, 																					global_step=<span class="variable language_">self</span>.global_step)</span><br><span class="line">        <span class="variable language_">self</span>.merged = tf.summary.merge_all()</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        @description: 分类器函数</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">classifer</span>(<span class="params">self, feature, training=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="comment"># f_num: 卷积层的初始滤波器数量</span></span><br><span class="line">        f_num = <span class="number">128</span></span><br><span class="line">        <span class="built_in">print</span>(feature)</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;classifer&#x27;</span>, reuse=tf.AUTO_REUSE):</span><br><span class="line">            <span class="comment"># 第一个卷积层，卷积核大小为 (cube_size, cube_size)，通道数为 f_num。使用批归一化和 ReLU 激活函数</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;conv0&#x27;</span>):</span><br><span class="line">                conv0 = tf.layers.conv2d(feature, f_num, (<span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.cube_size), strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                         padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">                conv0 = tf.layers.batch_normalization(conv0, training=training)</span><br><span class="line">                conv0 = tf.nn.relu(conv0)</span><br><span class="line">                <span class="built_in">print</span>(conv0)</span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;conv1&#x27;</span>):</span><br><span class="line">                <span class="comment"># 第二个卷积层，卷积核大小为 (cube_size, 1)，通道数加倍</span></span><br><span class="line">                conv1 = tf.layers.conv2d(conv0, f_num * <span class="number">2</span>, (<span class="variable language_">self</span>.cube_size, <span class="number">1</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), 												padding=<span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">                conv1 = tf.layers.batch_normalization(conv1, training=training)</span><br><span class="line">                conv1 = tf.nn.relu(conv1)</span><br><span class="line">                <span class="built_in">print</span>(conv1)</span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;conv2&#x27;</span>):</span><br><span class="line">                <span class="comment"># 第三个卷积层，卷积核大小为 (1, cube_size)，通道数进一步加倍</span></span><br><span class="line">                conv2 = tf.layers.conv2d(conv1, f_num * <span class="number">4</span>, (<span class="number">1</span>, <span class="variable language_">self</span>.cube_size), strides=(<span class="number">1</span>, <span class="number">1</span>), 												padding=<span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">                conv2 = tf.layers.batch_normalization(conv2, training=training)</span><br><span class="line">                conv2 = tf.nn.relu(conv2)</span><br><span class="line">                <span class="built_in">print</span>(conv2)</span><br><span class="line">            <span class="comment"># global_info: 全局信息提取层，通过一个卷积核大小为 (1, 1) 的卷积层将特征映射到类别数，然后进行展			   # 平，得到最终的特征</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;global_info&#x27;</span>):</span><br><span class="line">                feature = tf.layers.conv2d(conv2, <span class="variable language_">self</span>.class_num, (<span class="number">1</span>, <span class="number">1</span>), (<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">                feature = tf.layers.flatten(feature)</span><br><span class="line">                <span class="built_in">print</span>(feature)</span><br><span class="line">        <span class="keyword">return</span> feature</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        @description: 从指定路径加载模型</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load</span>(<span class="params">self, checkpoint_dir</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Loading model ...&quot;</span>)</span><br><span class="line">        model_name = os.path.join(checkpoint_dir)</span><br><span class="line">        ckpt = tf.train.get_checkpoint_state(model_name)</span><br><span class="line">        <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)</span><br><span class="line">            <span class="variable language_">self</span>.saver.restore(<span class="variable language_">self</span>.sess, os.path.join(model_name, ckpt_name))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Load successful.&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Load fail!!!&quot;</span>)</span><br><span class="line">            exit(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        @description: 训练函数</span></span><br><span class="line"><span class="string">            参考1D_CNN</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, dataset</span>):</span><br><span class="line">        train_dataset = dataset.data_parse(os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;train_data.tfrecords&#x27;</span>), <span class="built_in">type</span>=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">        init = tf.global_variables_initializer()</span><br><span class="line">        <span class="variable language_">self</span>.sess.run(init)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.epoch):</span><br><span class="line">            train_data, train_label = <span class="variable language_">self</span>.sess.run(train_dataset)</span><br><span class="line">            l, _, summery, lr = <span class="variable language_">self</span>.sess.run([<span class="variable language_">self</span>.loss_total, <span class="variable language_">self</span>.optimizer, <span class="variable language_">self</span>.merged, <span class="variable language_">self</span>.lr],</span><br><span class="line">                                              feed_dict=&#123;<span class="variable language_">self</span>.image: train_data,</span><br><span class="line">                                                       <span class="variable language_">self</span>.label:train_label,</span><br><span class="line">                                                       <span class="variable language_">self</span>.training:<span class="variable language_">self</span>.train_feed&#125;)</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(i, <span class="string">&#x27;step:&#x27;</span>, l, <span class="string">&#x27;learning rate:&#x27;</span>, lr)</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">10000</span> == <span class="number">0</span> <span class="keyword">and</span> i != <span class="number">0</span>:</span><br><span class="line">                <span class="variable language_">self</span>.saver.save(<span class="variable language_">self</span>.sess, os.path.join(<span class="variable language_">self</span>.model, <span class="variable language_">self</span>.model_name), global_step=i)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;saved...&#x27;</span>)</span><br><span class="line">                <span class="variable language_">self</span>.test(dataset)</span><br><span class="line">            <span class="variable language_">self</span>.summary_write.add_summary(summery, i)</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        @description: 测试函数</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">self, dataset</span>):</span><br><span class="line">        test_dataset = dataset.data_parse(os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;test_data.tfrecords&#x27;</span>), <span class="built_in">type</span>=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">        <span class="comment"># 正确分类的样本总数，测试样本总数</span></span><br><span class="line">        acc_num, test_num = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="comment"># 初始化混淆矩阵，大小为 [class_num, class_num]，用来记录各类的预测情况</span></span><br><span class="line">        matrix = np.zeros((<span class="variable language_">self</span>.class_num, <span class="variable language_">self</span>.class_num), dtype=np.int64)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                <span class="comment"># 使用 self.sess.run 从 test_dataset 获取测试数据和标签</span></span><br><span class="line">                test_data, test_label = <span class="variable language_">self</span>.sess.run(test_dataset)</span><br><span class="line">                <span class="comment"># 调用 self.sess.run 执行模型的前向传播，计算预测标签 pre_label</span></span><br><span class="line">                pre_label = <span class="variable language_">self</span>.sess.run(<span class="variable language_">self</span>.pre_label, feed_dict=&#123;<span class="variable language_">self</span>.image: test_data, 																			<span class="variable language_">self</span>.label:test_label,</span><br><span class="line">                                                    <span class="variable language_">self</span>.training: <span class="variable language_">self</span>.test_feed&#125;)</span><br><span class="line">                <span class="comment"># np.argmax(pre_label, 1)：将模型的输出通过 argmax 转换为类别标签</span></span><br><span class="line">                pre_label = np.argmax(pre_label, <span class="number">1</span>)</span><br><span class="line">                <span class="comment"># np.expand_dims(pre_label, 1)：将预测标签扩展成二维数组，方便与真实标签进行比较</span></span><br><span class="line">                pre_label = np.expand_dims(pre_label, <span class="number">1</span>)</span><br><span class="line">                <span class="comment"># 计算预测正确的数量，并累计到 acc_num</span></span><br><span class="line">                acc_num += np.<span class="built_in">sum</span>((pre_label == test_label))</span><br><span class="line">                <span class="comment"># 累加测试样本的数量</span></span><br><span class="line">                test_num += test_label.shape[<span class="number">0</span>]</span><br><span class="line">                <span class="comment"># 输出当前累计的正确样本数、总样本数以及当前的准确率</span></span><br><span class="line">                <span class="built_in">print</span>(acc_num, test_num, acc_num / test_num)</span><br><span class="line">                <span class="comment"># 更新混淆矩阵，记录真实标签 test_label[i] 和预测标签 pre_label[i] 的对应关系</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(pre_label.shape[<span class="number">0</span>]):</span><br><span class="line">                    matrix[pre_label[i], test_label[i]] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">except</span> tf.errors.OutOfRangeError:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;test end!&quot;</span>)</span><br><span class="line"></span><br><span class="line">        ac_list = []</span><br><span class="line">        <span class="comment"># 遍历混淆矩阵的每一行，计算每个类别的准确率（该类别预测正确的数量除以真实属于该类别的总数），并保存到 		   # ac_list 中</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(matrix)):</span><br><span class="line">            ac = matrix[i, i] / <span class="built_in">sum</span>(matrix[:, i])</span><br><span class="line">            ac_list.append(ac)</span><br><span class="line">            <span class="built_in">print</span>(i + <span class="number">1</span>, <span class="string">&#x27;class:&#x27;</span>, <span class="string">&#x27;(&#x27;</span>, matrix[i, i], <span class="string">&#x27;/&#x27;</span>, <span class="built_in">sum</span>(matrix[:, i]), <span class="string">&#x27;)&#x27;</span>, ac)</span><br><span class="line">        <span class="comment"># 打印混淆矩阵 matrix，显示模型对各个类别的分类情况</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;confusion matrix:&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(np.int_(matrix))</span><br><span class="line">        <span class="comment"># oa</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;total right num:&#x27;</span>, np.<span class="built_in">sum</span>(np.trace(matrix)))</span><br><span class="line">        accuracy = np.<span class="built_in">sum</span>(np.trace(matrix)) / np.<span class="built_in">sum</span>(matrix)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;oa:&#x27;</span>, accuracy)</span><br><span class="line">        <span class="comment"># kappa</span></span><br><span class="line">        <span class="comment"># kk: 累加每一类预测值和真实值的乘积</span></span><br><span class="line">        kk = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(matrix.shape[<span class="number">0</span>]):</span><br><span class="line">            kk += np.<span class="built_in">sum</span>(matrix[i]) * np.<span class="built_in">sum</span>(matrix[:, i])</span><br><span class="line">        <span class="comment"># pe: 计算理论上的随机一致性概率</span></span><br><span class="line">        pe = kk / (np.<span class="built_in">sum</span>(matrix) * np.<span class="built_in">sum</span>(matrix))</span><br><span class="line">        <span class="comment"># pa: 计算实际上的一致性概率（即 OA）</span></span><br><span class="line">        pa = np.trace(matrix) / np.<span class="built_in">sum</span>(matrix)</span><br><span class="line">        <span class="comment"># kappa: 根据 pa 和 pe 计算 Kappa 系数，衡量分类结果的随机性修正后的一致性</span></span><br><span class="line">        kappa = (pa - pe) / (<span class="number">1</span> - pe)</span><br><span class="line">        <span class="comment"># aa</span></span><br><span class="line">        ac_list = np.asarray(ac_list)</span><br><span class="line">        aa = np.mean(ac_list)</span><br><span class="line">        oa = accuracy</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;aa:&#x27;</span>, aa)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;kappa:&#x27;</span>, kappa)</span><br><span class="line">        <span class="comment"># 保存测试结果</span></span><br><span class="line">        sio.savemat(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;result.mat&#x27;</span>),</span><br><span class="line">                    &#123;<span class="string">&#x27;oa&#x27;</span>: oa, <span class="string">&#x27;aa&#x27;</span>: aa, <span class="string">&#x27;kappa&#x27;</span>: kappa, <span class="string">&#x27;ac_list&#x27;</span>: ac_list, <span class="string">&#x27;matrix&#x27;</span>: matrix&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        @description: 解码结果图像</span></span><br><span class="line"><span class="string">     &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_decode_map</span>(<span class="params">self, dataset</span>):</span><br><span class="line">        <span class="comment"># 读取解码数据集</span></span><br><span class="line">        map_dataset = dataset.data_parse(os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;map_data.tfrecords&#x27;</span>), <span class="built_in">type</span>=<span class="string">&#x27;map&#x27;</span>)</span><br><span class="line">        <span class="comment"># 加载data_gt</span></span><br><span class="line">        info = sio.loadmat(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;info.mat&#x27;</span>))</span><br><span class="line">        data_gt = info[<span class="string">&#x27;data_gt&#x27;</span>]</span><br><span class="line">        <span class="comment"># plt.figure(figsize=(map.shape[1] / 5, map.shape[0] / 5), dpi=100)# set size</span></span><br><span class="line">        <span class="comment"># 设置子图的边距，确保图像填充整个画布</span></span><br><span class="line">        plt.subplots_adjust(left=<span class="number">0</span>, right=<span class="number">1</span>, bottom=<span class="number">0</span>, top=<span class="number">1</span>, hspace=<span class="number">0</span>, wspace=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 关闭坐标轴</span></span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        <span class="comment"># 使用伪彩色（jet 色图）来绘制地面实况图，data_gt 是地面实况的二维矩阵</span></span><br><span class="line">        plt.pcolor(data_gt, cmap=<span class="string">&#x27;jet&#x27;</span>)</span><br><span class="line">        <span class="comment"># 将生成的地面实况图保存为 &#x27;groundtrouth.png&#x27; 文件</span></span><br><span class="line">        plt.savefig(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;groundtrouth.png&#x27;</span>), <span class="built_in">format</span>=<span class="string">&#x27;png&#x27;</span>)</span><br><span class="line">        <span class="comment"># 关闭当前图，释放资源</span></span><br><span class="line">        plt.close()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Groundtruth map get finished&#x27;</span>)</span><br><span class="line">        <span class="comment"># 初始化 de_map 为全零矩阵，形状与 data_gt 相同，存储解码结果</span></span><br><span class="line">        de_map = np.zeros(data_gt.shape, dtype=np.int32)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                <span class="comment"># 通过 self.sess.run(map_dataset) 逐批获取地图数据 map_data 和位置 pos</span></span><br><span class="line">                map_data, pos = <span class="variable language_">self</span>.sess.run(map_dataset)</span><br><span class="line">                <span class="comment"># 运行模型的前向传播，获取预测结果 pre_label</span></span><br><span class="line">                pre_label = <span class="variable language_">self</span>.sess.run(<span class="variable language_">self</span>.pre_label,</span><br><span class="line">                                 feed_dict=&#123;<span class="variable language_">self</span>.image: map_data, <span class="variable language_">self</span>.training: <span class="variable language_">self</span>.test_feed&#125;)</span><br><span class="line">                pre_label = np.argmax(pre_label, <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(pre_label.shape[<span class="number">0</span>]):</span><br><span class="line">                    [r, c] = pos[i]</span><br><span class="line">                    de_map[r, c] = pre_label[i]</span><br><span class="line">        <span class="keyword">except</span> tf.errors.OutOfRangeError:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;test end!&quot;</span>)</span><br><span class="line">        <span class="comment"># 绘制解码图</span></span><br><span class="line">        plt.subplots_adjust(left=<span class="number">0</span>, right=<span class="number">1</span>, bottom=<span class="number">0</span>, top=<span class="number">1</span>, hspace=<span class="number">0</span>, wspace=<span class="number">0</span>)</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        plt.pcolor(de_map, cmap=<span class="string">&#x27;jet&#x27;</span>)</span><br><span class="line">        plt.savefig(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;decode_map.png&#x27;</span>), <span class="built_in">format</span>=<span class="string">&#x27;png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;decode map get finished&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="主函数-1"><a href="#主函数-1" class="headerlink" title="主函数"></a>主函数</h2><p>参考1D-CNN主函数</p>
<h1 id="3D-CNN代码入门"><a href="#3D-CNN代码入门" class="headerlink" title="3D-CNN代码入门"></a>3D-CNN代码入门</h1><h2 id="数据加载-2"><a href="#数据加载-2" class="headerlink" title="数据加载"></a>数据加载</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pathlib, random</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> unit, os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Data</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args</span>):</span><br><span class="line">        <span class="variable language_">self</span>.data_path = args.data_path</span><br><span class="line">        <span class="variable language_">self</span>.train_num = args.train_num</span><br><span class="line">        <span class="variable language_">self</span>.seed = args.seed</span><br><span class="line">        <span class="variable language_">self</span>.data_name = args.data_name</span><br><span class="line">        <span class="variable language_">self</span>.result = args.result</span><br><span class="line">        <span class="variable language_">self</span>.tfrecords = args.tfrecords</span><br><span class="line">        <span class="variable language_">self</span>.args = args</span><br><span class="line">        <span class="variable language_">self</span>.cube_size = args.cube_size</span><br><span class="line">        <span class="variable language_">self</span>.data_dict = sio.loadmat(<span class="built_in">str</span>(pathlib.Path(<span class="variable language_">self</span>.data_path, <span class="variable language_">self</span>.data_name + <span class="string">&#x27;.mat&#x27;</span>)))</span><br><span class="line">        <span class="variable language_">self</span>.data_gt_dict = sio.loadmat(<span class="built_in">str</span>(pathlib.Path(<span class="variable language_">self</span>.data_path, <span class="variable language_">self</span>.data_name + <span class="string">&#x27;_gt.mat&#x27;</span>)))</span><br><span class="line">        data_name = [t <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">list</span>(<span class="variable language_">self</span>.data_dict.keys()) <span class="keyword">if</span> <span class="keyword">not</span> t.startswith(<span class="string">&#x27;__&#x27;</span>)][<span class="number">0</span>]</span><br><span class="line">        data_gt_name = [t <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">list</span>(<span class="variable language_">self</span>.data_gt_dict.keys()) <span class="keyword">if</span> <span class="keyword">not</span> t.startswith(<span class="string">&#x27;__&#x27;</span>)][<span class="number">0</span>]</span><br><span class="line">        <span class="variable language_">self</span>.data = <span class="variable language_">self</span>.data_dict[data_name]</span><br><span class="line">        <span class="variable language_">self</span>.data = unit.max_min(<span class="variable language_">self</span>.data).astype(np.float32)</span><br><span class="line">        <span class="variable language_">self</span>.data_gt = <span class="variable language_">self</span>.data_gt_dict[data_gt_name].astype(np.int64)</span><br><span class="line">        <span class="variable language_">self</span>.dim = <span class="variable language_">self</span>.data.shape[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        @description 生成以某个点 (row, col) 为中心的一个 w_size x w_size 大小的局部邻域数据块（cube）。</span></span><br><span class="line"><span class="string">                     当邻域范围超出数据边界时，它会从训练或测试数据的指定标签中随机抽取样本来填充这些位							置。细节参考2D—CNN</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">	<span class="comment"># 给出 row，col和标签，返回w_size大小的cube，flag=True表示为训练样本</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">neighbor_add</span>(<span class="params">self, row, col, labels, w_size=<span class="number">3</span>, flag=<span class="literal">True</span></span>):  </span><br><span class="line">        t = w_size // <span class="number">2</span></span><br><span class="line">        cube = np.zeros(shape=[w_size, w_size, <span class="variable language_">self</span>.data.shape[<span class="number">2</span>]])</span><br><span class="line">        labels += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(-t, t + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(-t, t + <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> i + row &lt; <span class="number">0</span> <span class="keyword">or</span> i + row &gt;= <span class="variable language_">self</span>.data.shape[<span class="number">0</span>] <span class="keyword">or</span> j + col &lt; <span class="number">0</span> <span class="keyword">or</span> j + col &gt;= 																						<span class="variable language_">self</span>.data.shape[<span class="number">1</span>]:</span><br><span class="line">                    <span class="keyword">if</span> flag:</span><br><span class="line">                        s = random.sample(<span class="variable language_">self</span>.train_pos[labels], <span class="number">1</span>)</span><br><span class="line">                        cube[i + t, j + t] = s[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        s = random.sample(<span class="variable language_">self</span>.test_pos[labels], <span class="number">1</span>)</span><br><span class="line">                        cube[i + t, j + t] = s[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    cube[i + t, j + t] = <span class="variable language_">self</span>.data[i + row, j + col]</span><br><span class="line">        <span class="keyword">return</span> cube</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">read_data</span>(<span class="params">self</span>):</span><br><span class="line">        data = <span class="variable language_">self</span>.data</span><br><span class="line">        data_gt = <span class="variable language_">self</span>.data_gt</span><br><span class="line">        <span class="variable language_">self</span>.data_gt = data_gt</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存数据</span></span><br><span class="line">        sio.savemat(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;info.mat&#x27;</span>), &#123;</span><br><span class="line">            <span class="string">&#x27;shape&#x27;</span>: <span class="variable language_">self</span>.data.shape,</span><br><span class="line">            <span class="string">&#x27;data&#x27;</span>: <span class="variable language_">self</span>.data,</span><br><span class="line">            <span class="string">&#x27;data_gt&#x27;</span>: <span class="variable language_">self</span>.data_gt,</span><br><span class="line">            <span class="string">&#x27;dim&#x27;</span>: <span class="variable language_">self</span>.data.shape[<span class="number">2</span>],</span><br><span class="line">            <span class="string">&#x27;class_num&#x27;</span>: np.<span class="built_in">max</span>(<span class="variable language_">self</span>.data_gt)</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">        class_num = np.<span class="built_in">max</span>(data_gt)</span><br><span class="line">        data_pos = &#123;i: [] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, class_num + <span class="number">1</span>)&#125;</span><br><span class="line">        <span class="comment"># 像素分类并统计位置信息  行列二维信息统计为字典类型的一维信息</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data_gt.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(data_gt.shape[<span class="number">1</span>]):</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, class_num + <span class="number">1</span>):</span><br><span class="line">                    <span class="keyword">if</span> data_gt[i, j] == k:</span><br><span class="line">                        data_pos[k].append([i, j])</span><br><span class="line">        <span class="variable language_">self</span>.data_pos = data_pos</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.args.fix_seed:</span><br><span class="line">            random.seed(<span class="variable language_">self</span>.seed)</span><br><span class="line">        <span class="comment"># 按比例或数量划分训练集和测试集</span></span><br><span class="line">        train_pos = <span class="built_in">dict</span>()</span><br><span class="line">        test_pos = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> data_pos.items():  <span class="comment"># k: class_num  v: []</span></span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt; <span class="variable language_">self</span>.train_num &lt; <span class="number">1</span>:</span><br><span class="line">                train_num = <span class="variable language_">self</span>.train_num * <span class="built_in">len</span>(v)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">len</span>(v) &lt; <span class="variable language_">self</span>.train_num:</span><br><span class="line">                train_num = <span class="number">15</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                train_num = <span class="variable language_">self</span>.train_num</span><br><span class="line">            train_pos[k] = random.sample(v, <span class="built_in">int</span>(train_num))</span><br><span class="line">            test_pos[k] = [i <span class="keyword">for</span> i <span class="keyword">in</span> v <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> train_pos[k]]</span><br><span class="line">        <span class="variable language_">self</span>.train_pos = train_pos</span><br><span class="line">        <span class="variable language_">self</span>.test_pos = test_pos</span><br><span class="line">        train_pos_all = <span class="built_in">list</span>()</span><br><span class="line">        test_pos_all = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> train_pos.items():  <span class="comment"># k: class_num  v: []</span></span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> v:</span><br><span class="line">                train_pos_all.append([k, t])</span><br><span class="line">                <span class="comment"># train_pos_all[class_num,v[0]] train_pos_all[class_num,v[1]]</span></span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> test_pos.items():</span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> v:</span><br><span class="line">                test_pos_all.append([k, t])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_int64_feature</span>(<span class="params">value</span>):</span><br><span class="line">            <span class="keyword">return</span> tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_bytes_feature</span>(<span class="params">value</span>):</span><br><span class="line">            <span class="keyword">return</span> tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># train data</span></span><br><span class="line">        train_data_name = os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;train_data.tfrecords&#x27;</span>)</span><br><span class="line">        writer = tf.python_io.TFRecordWriter(train_data_name)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> train_pos_all:</span><br><span class="line">            [r, c] = i[<span class="number">1</span>]</span><br><span class="line">            pixel_t = <span class="variable language_">self</span>.neighbor_add(r, c, i[<span class="number">0</span>] - <span class="number">1</span>, w_size=<span class="variable language_">self</span>.cube_size).astype(np.float32).tostring()</span><br><span class="line">            label_t = np.array(np.array(i[<span class="number">0</span>] - <span class="number">1</span>).astype(np.int64))</span><br><span class="line">            example = tf.train.Example(features=(tf.train.Features(</span><br><span class="line">                feature=&#123;</span><br><span class="line">                    <span class="string">&#x27;traindata&#x27;</span>: _bytes_feature(pixel_t),</span><br><span class="line">                    <span class="string">&#x27;trainlabel&#x27;</span>: _int64_feature(label_t)</span><br><span class="line">                &#125;</span><br><span class="line">            )))</span><br><span class="line">            writer.write(example.SerializeToString())</span><br><span class="line">        writer.close()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># test data</span></span><br><span class="line">        test_data_name = os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;test_data.tfrecords&#x27;</span>)</span><br><span class="line">        writer = tf.python_io.TFRecordWriter(test_data_name)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> test_pos_all:</span><br><span class="line">            [r, c] = i[<span class="number">1</span>]</span><br><span class="line">            pixel_t = <span class="variable language_">self</span>.neighbor_add(r, c, i[<span class="number">0</span>] - <span class="number">1</span>, w_size=<span class="variable language_">self</span>.cube_size).astype(np.float32).tostring()</span><br><span class="line">            label_t = np.array(np.array(i[<span class="number">0</span>] - <span class="number">1</span>).astype(np.int64))</span><br><span class="line">            example = tf.train.Example(features=(tf.train.Features(</span><br><span class="line">                feature=&#123;</span><br><span class="line">                    <span class="string">&#x27;testdata&#x27;</span>: _bytes_feature(pixel_t),</span><br><span class="line">                    <span class="string">&#x27;testlabel&#x27;</span>: _int64_feature(label_t)</span><br><span class="line">                &#125;</span><br><span class="line">            )))</span><br><span class="line">            writer.write(example.SerializeToString())</span><br><span class="line">        writer.close()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># map data</span></span><br><span class="line">        map_data_name = os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;map_data.tfrecords&#x27;</span>)</span><br><span class="line">        writer = tf.python_io.TFRecordWriter(map_data_name)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">1</span>]):</span><br><span class="line">                <span class="keyword">if</span> data_gt[i, j] == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                pixel_t = <span class="variable language_">self</span>.neighbor_add(i, j, <span class="number">1</span>, w_size=<span class="variable language_">self</span>.cube_size).astype(np.float32).tostring()</span><br><span class="line">                pos = [i, j]</span><br><span class="line">                pos = np.asarray(pos, dtype=np.int64).tostring()</span><br><span class="line">                example = tf.train.Example(features=(tf.train.Features(</span><br><span class="line">                    feature=&#123;</span><br><span class="line">                        <span class="string">&#x27;mapdata&#x27;</span>: _bytes_feature(pixel_t),</span><br><span class="line">                        <span class="string">&#x27;pos&#x27;</span>: _bytes_feature(pos),</span><br><span class="line">                    &#125;</span><br><span class="line">                )))</span><br><span class="line">                writer.write(example.SerializeToString())</span><br><span class="line">        writer.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">data_parse</span>(<span class="params">self, filename, <span class="built_in">type</span>=<span class="string">&#x27;train&#x27;</span></span>):</span><br><span class="line">        dataset = tf.data.TFRecordDataset([filename])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">parser_train</span>(<span class="params">record</span>):</span><br><span class="line">            keys_to_features = &#123;</span><br><span class="line">                <span class="string">&#x27;traindata&#x27;</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">                <span class="string">&#x27;trainlabel&#x27;</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">            &#125;</span><br><span class="line">            features = tf.parse_single_example(record, features=keys_to_features)</span><br><span class="line">            train_data = tf.decode_raw(features[<span class="string">&#x27;traindata&#x27;</span>], tf.float32)</span><br><span class="line">            train_label = tf.cast(features[<span class="string">&#x27;trainlabel&#x27;</span>], tf.int64)</span><br><span class="line">            shape = [<span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.dim]</span><br><span class="line">            train_data = tf.reshape(train_data, shape)</span><br><span class="line">            train_label = tf.reshape(train_label, [<span class="number">1</span>])</span><br><span class="line">            <span class="keyword">return</span> train_data, train_label</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">parser_test</span>(<span class="params">record</span>):</span><br><span class="line">            keys_to_features = &#123;</span><br><span class="line">                <span class="string">&#x27;testdata&#x27;</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">                <span class="string">&#x27;testlabel&#x27;</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">            &#125;</span><br><span class="line">            features = tf.parse_single_example(record, features=keys_to_features)</span><br><span class="line">            test_data = tf.decode_raw(features[<span class="string">&#x27;testdata&#x27;</span>], tf.float32)</span><br><span class="line">            test_label = tf.cast(features[<span class="string">&#x27;testlabel&#x27;</span>], tf.int64)</span><br><span class="line">            shape = [<span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.dim]</span><br><span class="line">            test_data = tf.reshape(test_data, shape)</span><br><span class="line">            test_label = tf.reshape(test_label, [<span class="number">1</span>])</span><br><span class="line">            <span class="keyword">return</span> test_data, test_label</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">parser_map</span>(<span class="params">record</span>):</span><br><span class="line">            keys_to_features = &#123;</span><br><span class="line">                <span class="string">&#x27;mapdata&#x27;</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">                <span class="string">&#x27;pos&#x27;</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">            &#125;</span><br><span class="line">            features = tf.parse_single_example(record, features=keys_to_features)</span><br><span class="line">            map_data = tf.decode_raw(features[<span class="string">&#x27;mapdata&#x27;</span>], tf.float32)</span><br><span class="line">            pos = tf.decode_raw(features[<span class="string">&#x27;pos&#x27;</span>], tf.int64)</span><br><span class="line">            shape = [<span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.dim]</span><br><span class="line">            map_data = tf.reshape(map_data, shape)</span><br><span class="line">            pos = tf.reshape(pos, [<span class="number">2</span>])</span><br><span class="line">            <span class="keyword">return</span> map_data, pos</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span> == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(parser_train)</span><br><span class="line">            dataset = dataset.shuffle(buffer_size=<span class="number">20000</span>)</span><br><span class="line">            dataset = dataset.batch(<span class="variable language_">self</span>.args.batch_size)</span><br><span class="line">            dataset = dataset.repeat()</span><br><span class="line">            iterator = dataset.make_one_shot_iterator()</span><br><span class="line">            <span class="keyword">return</span> iterator.get_next()</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span> == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(parser_test)</span><br><span class="line">            dataset = dataset.batch(<span class="variable language_">self</span>.args.test_batch)</span><br><span class="line">            iterator = dataset.make_one_shot_iterator()</span><br><span class="line">            <span class="keyword">return</span> iterator.get_next()</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span> == <span class="string">&#x27;map&#x27;</span>:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(parser_map).repeat(<span class="number">1</span>)</span><br><span class="line">            dataset = dataset.batch(<span class="variable language_">self</span>.args.test_batch)</span><br><span class="line">            iterator = dataset.make_one_shot_iterator()</span><br><span class="line">            <span class="keyword">return</span> iterator.get_next()</span><br></pre></td></tr></table></figure>

<h2 id="CNN模型构建-2"><a href="#CNN模型构建-2" class="headerlink" title="CNN模型构建"></a>CNN模型构建</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args, sess</span>):</span><br><span class="line">        <span class="variable language_">self</span>.sess = sess</span><br><span class="line">        <span class="variable language_">self</span>.data_name = args.data_name</span><br><span class="line">        <span class="variable language_">self</span>.result = args.result</span><br><span class="line">        info = sio.loadmat(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;info.mat&#x27;</span>))</span><br><span class="line">        <span class="variable language_">self</span>.shape = info[<span class="string">&#x27;shape&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.dim = info[<span class="string">&#x27;dim&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.class_num = <span class="built_in">int</span>(info[<span class="string">&#x27;class_num&#x27;</span>])</span><br><span class="line">        <span class="variable language_">self</span>.data_gt = info[<span class="string">&#x27;data_gt&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.log = args.log</span><br><span class="line">        <span class="variable language_">self</span>.model = args.model</span><br><span class="line">        <span class="variable language_">self</span>.cube_size = args.cube_size</span><br><span class="line">        <span class="variable language_">self</span>.data_path = args.data_path</span><br><span class="line">        <span class="variable language_">self</span>.iter_num = args.iter_num</span><br><span class="line">        <span class="variable language_">self</span>.tfrecords = args.tfrecords</span><br><span class="line">        <span class="variable language_">self</span>.best_oa = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.training = tf.placeholder(<span class="built_in">bool</span>)</span><br><span class="line">        <span class="variable language_">self</span>.train_feed = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.test_feed = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> args.use_lr_decay:</span><br><span class="line">            <span class="variable language_">self</span>.lr = tf.train.exponential_decay(learning_rate=args.lr,</span><br><span class="line">                                                 global_step=<span class="variable language_">self</span>.global_step,</span><br><span class="line">                                                 decay_rate=args.decay_rete,</span><br><span class="line">                                                 decay_steps=args.decay_steps)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.lr = args.lr</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.image = tf.placeholder(dtype=tf.float32, shape=(<span class="literal">None</span>, <span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.cube_size, <span class="variable language_">self</span>.dim))</span><br><span class="line">        <span class="variable language_">self</span>.label = tf.placeholder(dtype=tf.int64, shape=(<span class="literal">None</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="variable language_">self</span>.classifer = <span class="variable language_">self</span>.classifer</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.pre_label = <span class="variable language_">self</span>.classifer(<span class="variable language_">self</span>.image, <span class="variable language_">self</span>.training)</span><br><span class="line">        <span class="variable language_">self</span>.model_name = os.path.join(<span class="string">&#x27;model.ckpt&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.loss()</span><br><span class="line">        <span class="variable language_">self</span>.summary_write = tf.summary.FileWriter(os.path.join(<span class="variable language_">self</span>.log), graph=<span class="variable language_">self</span>.sess.graph)</span><br><span class="line">        <span class="variable language_">self</span>.saver = tf.train.Saver(max_to_keep=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        @description: 损失函数</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;loss&#x27;</span>):</span><br><span class="line">            loss_cross_entropy = tf.losses.sparse_softmax_cross_entropy(<span class="variable language_">self</span>.label, <span class="variable language_">self</span>.pre_label,                                                                 scope=<span class="string">&#x27;loss_cross_entropy&#x27;</span>)</span><br><span class="line">            loss_cross_entropy = tf.reduce_mean(loss_cross_entropy)</span><br><span class="line">            <span class="variable language_">self</span>.loss_total = loss_cross_entropy</span><br><span class="line">            tf.summary.scalar(<span class="string">&#x27;loss_total&#x27;</span>, <span class="variable language_">self</span>.loss_total)</span><br><span class="line">        <span class="variable language_">self</span>.optimizer = tf.train.AdamOptimizer(<span class="variable language_">self</span>.lr).minimize(<span class="variable language_">self</span>.loss_total, 																							global_step=<span class="variable language_">self</span>.global_step)</span><br><span class="line">        <span class="variable language_">self</span>.merged = tf.summary.merge_all()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">classifer</span>(<span class="params">self, feature, training=<span class="literal">False</span></span>):</span><br><span class="line">        f_num = <span class="number">64</span></span><br><span class="line">        <span class="comment"># 将feature拓展为5维张量</span></span><br><span class="line">        feature = tf.compat.v1.expand_dims(feature, <span class="number">4</span>)</span><br><span class="line">        <span class="built_in">print</span>(feature)</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;classifer&#x27;</span>, reuse=tf.AUTO_REUSE):</span><br><span class="line">            <span class="comment"># 第一层卷积</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;conv0&#x27;</span>):</span><br><span class="line">                conv0 = tf.layers.conv3d(feature, f_num, (<span class="variable language_">self</span>.cube_size, <span class="number">1</span>, <span class="number">8</span>), strides=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>), 																					padding=<span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">                conv0 = tf.layers.batch_normalization(conv0, training=training)</span><br><span class="line">                conv0 = tf.nn.relu(conv0)</span><br><span class="line">                <span class="built_in">print</span>(conv0)</span><br><span class="line">            <span class="comment"># 第二层卷积</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;conv1&#x27;</span>):</span><br><span class="line">                conv1 = tf.layers.conv3d(conv0, f_num * <span class="number">2</span>, (<span class="number">1</span>, <span class="variable language_">self</span>.cube_size, <span class="number">3</span>), strides=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>), 																					padding=<span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">                conv1 = tf.layers.batch_normalization(conv1, training=training)</span><br><span class="line">                conv1 = tf.nn.relu(conv1)</span><br><span class="line">                <span class="built_in">print</span>(conv1)</span><br><span class="line">            <span class="comment"># 第三层卷积</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;conv2&#x27;</span>):</span><br><span class="line">                conv2 = tf.layers.conv3d(conv1, f_num * <span class="number">4</span>, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>), strides=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>), padding=<span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">                conv2 = tf.layers.batch_normalization(conv2, training=training)</span><br><span class="line">                conv2 = tf.nn.relu(conv2)</span><br><span class="line">                <span class="built_in">print</span>(conv2)</span><br><span class="line">                shape = <span class="built_in">int</span>(conv2.get_shape().as_list()[<span class="number">3</span>])</span><br><span class="line">            <span class="comment"># 全局信息提取</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;global_info&#x27;</span>):</span><br><span class="line">                feature = tf.layers.conv3d(conv2, f_num * <span class="number">8</span>, (<span class="number">1</span>, <span class="number">1</span>, shape), (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">                feature = tf.layers.flatten(feature)</span><br><span class="line">                <span class="built_in">print</span>(feature)</span><br><span class="line">            <span class="comment"># 全连接层</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;fc&#x27;</span>):</span><br><span class="line">                fc = tf.layers.dense(feature, <span class="number">512</span>)</span><br><span class="line">                fc = tf.layers.batch_normalization(fc)</span><br><span class="line">                fc = tf.nn.relu(fc)</span><br><span class="line">            <span class="comment"># 输出层</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;logits&#x27;</span>):</span><br><span class="line">                logits = tf.layers.dense(fc, <span class="variable language_">self</span>.class_num)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        @description: 从指定路径加载模型</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load</span>(<span class="params">self, checkpoint_dir</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Loading model ...&quot;</span>)</span><br><span class="line">        model_name = os.path.join(checkpoint_dir)</span><br><span class="line">        ckpt = tf.train.get_checkpoint_state(model_name)</span><br><span class="line">        <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)</span><br><span class="line">            <span class="variable language_">self</span>.saver.restore(<span class="variable language_">self</span>.sess, os.path.join(model_name, ckpt_name))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Load successful.&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Load fail!!!&quot;</span>)</span><br><span class="line">            exit(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        @description: 训练函数</span></span><br><span class="line"><span class="string">            参考1D_CNN</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, dataset</span>):</span><br><span class="line">        train_dataset = dataset.data_parse(os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;train_data.tfrecords&#x27;</span>), <span class="built_in">type</span>=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">        init = tf.global_variables_initializer()</span><br><span class="line">        <span class="variable language_">self</span>.best_oa = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.sess.run(init)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.iter_num):</span><br><span class="line">            train_data, train_label = <span class="variable language_">self</span>.sess.run(train_dataset)</span><br><span class="line">            <span class="comment"># print(train_data.shape,train_label.shape)</span></span><br><span class="line">            l, _, summery, lr = <span class="variable language_">self</span>.sess.run([<span class="variable language_">self</span>.loss_total, <span class="variable language_">self</span>.optimizer, <span class="variable language_">self</span>.merged, <span class="variable language_">self</span>.lr],</span><br><span class="line">                                   feed_dict=&#123;<span class="variable language_">self</span>.image: train_data, <span class="variable language_">self</span>.label: train_label,</span><br><span class="line">                                   <span class="variable language_">self</span>.training: <span class="variable language_">self</span>.train_feed&#125;)</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(i, <span class="string">&#x27;step:&#x27;</span>, l, <span class="string">&#x27;learning rate:&#x27;</span>, lr)</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">10000</span> == <span class="number">0</span> <span class="keyword">and</span> i != <span class="number">0</span>:</span><br><span class="line">                <span class="variable language_">self</span>.saver.save(<span class="variable language_">self</span>.sess, os.path.join(<span class="variable language_">self</span>.model, <span class="variable language_">self</span>.model_name), global_step=i)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;saved...&#x27;</span>)</span><br><span class="line">                <span class="variable language_">self</span>.test(dataset)</span><br><span class="line">                <span class="variable language_">self</span>.save_decode_map(dataset)</span><br><span class="line">            <span class="variable language_">self</span>.summary_write.add_summary(summery, i)</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        @description: 测试函数</span></span><br><span class="line"><span class="string">            参考2D-CNN</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">self, dataset</span>):</span><br><span class="line">        test_dataset = dataset.data_parse(os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;test_data.tfrecords&#x27;</span>), <span class="built_in">type</span>=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">        acc_num, test_num = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        matrix = np.zeros((<span class="variable language_">self</span>.class_num, <span class="variable language_">self</span>.class_num), dtype=np.int64)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                test_data, test_label = <span class="variable language_">self</span>.sess.run(test_dataset)</span><br><span class="line">                pre_label = <span class="variable language_">self</span>.sess.run(<span class="variable language_">self</span>.pre_label, feed_dict=&#123;<span class="variable language_">self</span>.image: test_data, <span class="variable language_">self</span>.label: 										  test_label,<span class="variable language_">self</span>.training: <span class="variable language_">self</span>.test_feed&#125;)</span><br><span class="line">                pre_label = np.argmax(pre_label, <span class="number">1</span>)</span><br><span class="line">                pre_label = np.expand_dims(pre_label, <span class="number">1</span>)</span><br><span class="line">                acc_num += np.<span class="built_in">sum</span>((pre_label == test_label))</span><br><span class="line">                test_num += test_label.shape[<span class="number">0</span>]</span><br><span class="line">                <span class="built_in">print</span>(acc_num, test_num, acc_num / test_num)</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(pre_label.shape[<span class="number">0</span>]):</span><br><span class="line">                    matrix[pre_label[i], test_label[i]] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">except</span> tf.errors.OutOfRangeError:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;test end!&quot;</span>)</span><br><span class="line"></span><br><span class="line">        ac_list = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(matrix)):</span><br><span class="line">            ac = matrix[i, i] / <span class="built_in">sum</span>(matrix[:, i])</span><br><span class="line">            ac_list.append(ac)</span><br><span class="line">            <span class="built_in">print</span>(i + <span class="number">1</span>, <span class="string">&#x27;class:&#x27;</span>, <span class="string">&#x27;(&#x27;</span>, matrix[i, i], <span class="string">&#x27;/&#x27;</span>, <span class="built_in">sum</span>(matrix[:, i]), <span class="string">&#x27;)&#x27;</span>, ac)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;confusion matrix:&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(np.int_(matrix))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;total right num:&#x27;</span>, np.<span class="built_in">sum</span>(np.trace(matrix)))</span><br><span class="line">        accuracy = np.<span class="built_in">sum</span>(np.trace(matrix)) / np.<span class="built_in">sum</span>(matrix)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;oa:&#x27;</span>, accuracy)</span><br><span class="line">        <span class="comment"># kappa</span></span><br><span class="line">        kk = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(matrix.shape[<span class="number">0</span>]):</span><br><span class="line">            kk += np.<span class="built_in">sum</span>(matrix[i]) * np.<span class="built_in">sum</span>(matrix[:, i])</span><br><span class="line">        pe = kk / (np.<span class="built_in">sum</span>(matrix) * np.<span class="built_in">sum</span>(matrix))</span><br><span class="line">        pa = np.trace(matrix) / np.<span class="built_in">sum</span>(matrix)</span><br><span class="line">        kappa = (pa - pe) / (<span class="number">1</span> - pe)</span><br><span class="line">        ac_list = np.asarray(ac_list)</span><br><span class="line">        aa = np.mean(ac_list)</span><br><span class="line">        oa = accuracy</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;aa:&#x27;</span>, aa)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;kappa:&#x27;</span>, kappa)</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.best_oa &lt; oa:</span><br><span class="line">            <span class="variable language_">self</span>.best_oa = oa</span><br><span class="line">        sio.savemat(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;result&#x27;</span> + <span class="variable language_">self</span>.data_name + <span class="string">&#x27;.mat&#x27;</span>),</span><br><span class="line">                    &#123;<span class="string">&#x27;oa&#x27;</span>: oa, <span class="string">&#x27;aa&#x27;</span>: aa, <span class="string">&#x27;kappa&#x27;</span>: kappa, <span class="string">&#x27;ac_list&#x27;</span>: ac_list, <span class="string">&#x27;matrix&#x27;</span>: matrix, <span class="string">&#x27;best_oa&#x27;</span>: 						  <span class="variable language_">self</span>.best_oa&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        @description: 解码结果图像</span></span><br><span class="line"><span class="string">            参考2D-CNN</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_decode_map</span>(<span class="params">self, dataset</span>):</span><br><span class="line">        map_dataset = dataset.data_parse(os.path.join(<span class="variable language_">self</span>.tfrecords, <span class="string">&#x27;map_data.tfrecords&#x27;</span>), <span class="built_in">type</span>=<span class="string">&#x27;map&#x27;</span>)</span><br><span class="line">        info = sio.loadmat(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;info.mat&#x27;</span>))</span><br><span class="line">        data_gt = info[<span class="string">&#x27;data_gt&#x27;</span>]</span><br><span class="line">        plt.subplots_adjust(left=<span class="number">0</span>, right=<span class="number">1</span>, bottom=<span class="number">0</span>, top=<span class="number">1</span>, hspace=<span class="number">0</span>, wspace=<span class="number">0</span>)</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        plt.pcolor(data_gt, cmap=<span class="string">&#x27;jet&#x27;</span>)</span><br><span class="line">        plt.savefig(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;groundtrouth.png&#x27;</span>), <span class="built_in">format</span>=<span class="string">&#x27;png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Groundtruth map get finished&#x27;</span>)</span><br><span class="line">        de_map = np.zeros(data_gt.shape, dtype=np.int32)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                map_data, pos = <span class="variable language_">self</span>.sess.run(map_dataset)</span><br><span class="line">                pre_label = <span class="variable language_">self</span>.sess.run(<span class="variable language_">self</span>.pre_label,</span><br><span class="line">                                    feed_dict=&#123;<span class="variable language_">self</span>.image: map_data, <span class="variable language_">self</span>.training: 													 <span class="variable language_">self</span>.test_feed&#125;)</span><br><span class="line">                pre_label = np.argmax(pre_label, <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(pre_label.shape[<span class="number">0</span>]):</span><br><span class="line">                    [r, c] = pos[i]</span><br><span class="line">                    de_map[r, c] = pre_label[i] + <span class="number">1</span></span><br><span class="line">        <span class="keyword">except</span> tf.errors.OutOfRangeError:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;test end!&quot;</span>)</span><br><span class="line">        plt.subplots_adjust(left=<span class="number">0</span>, right=<span class="number">1</span>, bottom=<span class="number">0</span>, top=<span class="number">1</span>, hspace=<span class="number">0</span>, wspace=<span class="number">0</span>)</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        plt.pcolor(de_map, cmap=<span class="string">&#x27;jet&#x27;</span>)</span><br><span class="line">        plt.savefig(os.path.join(<span class="variable language_">self</span>.result, <span class="string">&#x27;decode_map&#x27;</span> + <span class="variable language_">self</span>.data_name + <span class="string">&#x27;.png&#x27;</span>), <span class="built_in">format</span>=<span class="string">&#x27;png&#x27;</span>)</span><br><span class="line">        plt.close()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;decode map get finished&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="主函数-2"><a href="#主函数-2" class="headerlink" title="主函数"></a>主函数</h2><p>参考1D-CNN主函数</p>
<h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h1><h2 id="TFRecord"><a href="#TFRecord" class="headerlink" title="TFRecord"></a>TFRecord</h2><p><strong>TFRecord</strong> 是 TensorFlow 提供的一种数据格式，用于高效地存储大量的结构化数据。TFRecord 文件将数据序列化为二进制格式，便于读取和处理。相比其他常见的数据格式（如 CSV 或 JSON），TFRecord 在处理大规模数据集时具有以下优点：</p>
<h3 id="1-高效的存储方式"><a href="#1-高效的存储方式" class="headerlink" title="1. 高效的存储方式"></a>1. <strong>高效的存储方式</strong></h3><ul>
<li>TFRecord 使用二进制格式来存储数据，减少了文件的大小，并加快了读取速度。</li>
<li>二进制格式比文本格式（如 CSV、JSON）更加紧凑，可以更好地利用磁盘空间。</li>
</ul>
<h3 id="2-序列化与结构化"><a href="#2-序列化与结构化" class="headerlink" title="2. 序列化与结构化"></a>2. <strong>序列化与结构化</strong></h3><ul>
<li>TensorFlow 提供了 <code>tf.train.Example</code> 和 <code>tf.train.Feature</code> 两种主要的序列化数据结构，用于将各种类型的数据（如字符串、整数、浮点数）打包存入 TFRecord 文件中。</li>
<li>数据可以是单一值或数组，这使得它特别适合保存图像、音频等大规模数据。</li>
</ul>
<h3 id="3-与-TensorFlow-原生兼容"><a href="#3-与-TensorFlow-原生兼容" class="headerlink" title="3. 与 TensorFlow 原生兼容"></a>3. <strong>与 TensorFlow 原生兼容</strong></h3><ul>
<li>TFRecord 与 TensorFlow 的输入管道高度集成。使用 TFRecord 可以在训练模型时通过 <code>tf.data</code> API 轻松读取和解析数据，支持批处理、数据增强、并行读取等操作。</li>
<li>在分布式环境中，TFRecord 的格式也更容易被 TensorFlow 处理，能够提高数据读取的效率。</li>
</ul>
<h3 id="4-跨平台支持"><a href="#4-跨平台支持" class="headerlink" title="4. 跨平台支持"></a>4. <strong>跨平台支持</strong></h3><ul>
<li>TFRecord 文件可以跨操作系统和不同的硬件平台使用，TensorFlow 在各个设备（CPU、GPU、TPU）上都支持这种数据格式。</li>
</ul>
<h3 id="典型使用流程"><a href="#典型使用流程" class="headerlink" title="典型使用流程"></a>典型使用流程</h3><p>TFRecord 文件的使用分为两步：<strong>写入</strong> 和 <strong>读取</strong>。</p>
<h4 id="写入-TFRecord"><a href="#写入-TFRecord" class="headerlink" title="写入 TFRecord"></a>写入 TFRecord</h4><p>通过将原始数据转换为 <code>tf.train.Example</code>，然后将其序列化为二进制数据并写入 TFRecord 文件。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">python复制代码import tensorflow as tf</span><br><span class="line"></span><br><span class="line">def _bytes_feature(value):</span><br><span class="line">    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))</span><br><span class="line"></span><br><span class="line">def _int64_feature(value):</span><br><span class="line">    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))</span><br><span class="line"></span><br><span class="line">def write_tfrecord(file_path, data):</span><br><span class="line">    with tf.io.TFRecordWriter(file_path) as writer:</span><br><span class="line">        for features in data:</span><br><span class="line">            feature = &#123;</span><br><span class="line">                &#x27;image_raw&#x27;: _bytes_feature(features[&#x27;image&#x27;]),</span><br><span class="line">                &#x27;label&#x27;: _int64_feature(features[&#x27;label&#x27;])</span><br><span class="line">            &#125;</span><br><span class="line">            example = tf.train.Example(features=tf.train.Features(feature=feature))</span><br><span class="line">            writer.write(example.SerializeToString())</span><br></pre></td></tr></table></figure>

<h4 id="读取-TFRecord"><a href="#读取-TFRecord" class="headerlink" title="读取 TFRecord"></a>读取 TFRecord</h4><p>读取时通过 <code>tf.data.TFRecordDataset</code> 读取二进制文件，解析 <code>tf.train.Example</code>，并转换为 TensorFlow 能处理的格式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">python复制代码def _parse_function(proto):</span><br><span class="line">    keys_to_features = &#123;</span><br><span class="line">        &#x27;image_raw&#x27;: tf.io.FixedLenFeature([], tf.string),</span><br><span class="line">        &#x27;label&#x27;: tf.io.FixedLenFeature([], tf.int64),</span><br><span class="line">    &#125;</span><br><span class="line">    parsed_features = tf.io.parse_single_example(proto, keys_to_features)</span><br><span class="line">    image = tf.io.decode_raw(parsed_features[&#x27;image_raw&#x27;], tf.uint8)</span><br><span class="line">    label = parsed_features[&#x27;label&#x27;]</span><br><span class="line">    return image, label</span><br><span class="line"></span><br><span class="line">dataset = tf.data.TFRecordDataset(&quot;data.tfrecord&quot;).map(_parse_function)</span><br><span class="line">for image, label in dataset:</span><br><span class="line">    print(image, label)</span><br></pre></td></tr></table></figure>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><code>TFRecord</code> 是一种高效的二进制文件格式，专为处理大规模数据而设计，尤其适用于机器学习任务。它与 <code>TensorFlow</code> 紧密集成，支持并行处理、批处理等操作，有助于提高数据加载效率和模型训练的速度。</p>

        
        
          <blockquote id="copyright">
              <p>Original link: <a href="http://example.com/index.html">http://example.com/index.html</a></p>
              <p>Copyright Notice: 转载请注明出处.</p>
          </blockquote>
        
      
    </div>
    <footer class="article-footer">
      
        <div class="article-tag-wrap">
          

          
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CNN-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" rel="tag">CNN 图像处理</a></li></ul>

          
    <div class="social-share">
      <span>Share:</span>
    </div>



        </div>
      
      
      
    </footer>
  </div>
</article>


  <article id="post-CNN卷积神经网络" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/09/09/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">CNN卷积神经网络</a>
    </h1>
  


      </header>
    
    <div class="article-meta">
      
      <span class="article-date">
  <i class="fa fa-date"></i>
  <time class="dt-published" datetime="2024-09-09T11:06:35.000Z" itemprop="datePublished">2024年09月09日</time>
</span>
      
      
      
<a href="/2024/09/09/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/#comments" class="article-comment-link">
  
  <i class="fa fa-commt"></i>
  Guestbook
</a>


    </div>
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="CNN卷积神经网络"><a href="#CNN卷积神经网络" class="headerlink" title="CNN卷积神经网络"></a>CNN卷积神经网络</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p><code>卷积神经网络（Convolutional Neural Network，CNN）</code>是一种在计算机视觉领域取得了巨大成功的深度学习模型。它们的设计灵感来自于生物学中的视觉系统，旨在模拟人类视觉处理的方式。在过去的几年中，CNN已经在图像识别、目标检测、图像生成和许多其他领域取得了显著的进展，成为了计算机视觉和深度学习研究的重要组成部分。</p>
<h2 id="什么是卷积"><a href="#什么是卷积" class="headerlink" title="什么是卷积"></a>什么是卷积</h2><p>在卷积神经网络中，卷积操作是指将一个可移动的<strong>小窗口（称为数据窗口，如下图绿色矩形）</strong>与图像进行逐元素相乘然后相加的操作。这个小窗口其实是一组固定的权重，它可以被看作是一个特定的<strong>滤波器（filter）</strong>或<strong>卷积核</strong>。这个操作的名称“卷积”，源自于这种元素级相乘和求和的过程。这一操作是卷积神经网络名字的来源。</p>
<img src="7cabb107dc4fd77c9edd4fe790bfea17.png" alt="img">

<p>上图这个绿色小窗就是数据窗口。简而言之，<strong>卷积操作就是用一个可移动的小窗口来提取图像中的特征</strong>，这个小窗口包含了一组特定的权重，通过与图像的不同位置进行卷积操作，网络能够学习并捕捉到不同特征的信息。</p>
<p>下图中蓝色的框就是指一个数据窗口，红色框为卷积核（滤波器），最后得到的绿色方形就是卷积的结果（数据窗口中的数据与卷积核逐个元素相乘再求和）</p>
<img src="d0172774f7e42ae2f6310b63e59b4906.gif" alt="img">

<h2 id="卷积神经网络层级结构"><a href="#卷积神经网络层级结构" class="headerlink" title="卷积神经网络层级结构"></a>卷积神经网络层级结构</h2><p>一个卷积神经网络主要由以下5层组成：</p>
<ul>
<li>数据输入层&#x2F; Input layer</li>
<li>卷积计算层&#x2F; CONV layer</li>
<li>ReLU激励层</li>
<li>池化层 &#x2F; Pooling layer</li>
<li>全连接层 &#x2F; FC layer</li>
</ul>
<img src="3c266da23107494b04b09683b8427f0e.png" alt="img">

<h3 id="数据输入层"><a href="#数据输入层" class="headerlink" title="数据输入层"></a>数据输入层</h3><p>该层要做的处理主要是对原始图像数据进行预处理，其中包括：</p>
<ul>
<li><strong>去均值</strong>：把输入数据各个维度都中心化为0，如下图所示，其目的就是把样本的中心拉回到坐标系原点上。</li>
<li><strong>归一化</strong>：幅度归一化到同样的范围，如下所示，即减少各维度数据取值范围的差异而带来的干扰，比如，我们有两个维度的特征A和B，A范围是0到10，而B范围是0到10000，如果直接使用这两个特征是有问题的，好的做法就是归一化，即A和B的数据都变为0到1的范围。</li>
<li><strong>PCA&#x2F;白化</strong>：用PCA降维；白化是对数据各个特征轴上的幅度归一化</li>
</ul>
<p>去均值与归一化效果图：</p>
<img src="v2-4c3b00f07cce0c7dccf2e4ba5e167e30_r.jpg" alt="img">

<p>去相关与白化效果图：</p>
<img src="v2-229a2c9828a26d594dc854b659cfc8a5_1440w.webp" alt="img">

<h3 id="卷积计算层"><a href="#卷积计算层" class="headerlink" title="卷积计算层"></a>卷积计算层</h3><p>这一层就是卷积神经网络最重要的一个层次，也是“卷积神经网络”的名字来源。<br>在这个卷积层，有两个关键操作：</p>
<ul>
<li><strong>局部关联</strong>。每个神经元看做一个滤波器(filter)</li>
<li><strong>窗口(receptive field)滑动</strong>， filter对局部数据计算</li>
</ul>
<p>先介绍卷积层遇到的几个名词：</p>
<ul>
<li><strong>深度&#x2F;depth</strong>：卷积核的个数</li>
<li><strong>步幅&#x2F;stride</strong>：窗口一次滑动的长度</li>
<li><strong>填充值&#x2F;zero-padding</strong>：在外围边缘补充若干圈0，方便从初始位置以步长为单位可以刚好滑倒末尾位置，通俗地讲就是为了总长能被步长整除。</li>
</ul>
<img src="v2-821048bfaee14d8c03cc5044e04fe336_r.jpg" alt="img">

<h4 id="为什么要填充"><a href="#为什么要填充" class="headerlink" title="为什么要填充"></a>为什么要填充</h4><ol>
<li><strong>保留边缘信息</strong>：当卷积核在图像边缘进行卷积时，如果不进行填充，边缘的像素将无法得到完整的卷积运算，因为卷积核无法完全覆盖边缘区域。通过填充，可以确保边缘像素也能被卷积核完整覆盖，从而保留更多的图像信息。</li>
<li><strong>控制输出尺寸</strong>：填充可以控制卷积层输出的特征图（Feature Map）的尺寸。例如，通过适当的填充，可以使输出特征图的尺寸与输入图像的尺寸相同，这在某些网络结构设计中是必要的。</li>
<li><strong>防止信息丢失</strong>：在多次卷积操作中，如果不使用填充，每次卷积都会导致输出尺寸减小，这可能会导致图像的边缘信息快速丢失。适当的填充可以减缓尺寸的减小，避免信息丢失过快。</li>
<li><strong>实现特定的网络结构</strong>：在某些网络结构中，为了保持输入和输出的形状匹配，或者为了实现特定的网络功能，可能需要使用填充。</li>
</ol>
<p>如果你的步幅为 1，而且把零填充设置为</p>
<img src="v2-96a40f41090b4bb5e7ebbf0a0e186d9a_1440w.webp" alt="img">

<p>K 是过滤器尺寸，那么输入和输出内容就总能保持一致的空间维度。</p>
<p>计算任意给定卷积层的输出的大小的公式是</p>
<img src="v2-2ea24e54873121ae877b5e7f03db8844_1440w.webp" alt="img">

<p>其中 O 是输出尺寸，K 是过滤器尺寸，P 是填充，S 是步幅。</p>
<h3 id="激活层（非线性层）"><a href="#激活层（非线性层）" class="headerlink" title="激活层（非线性层）"></a>激活层（非线性层）</h3><p>把卷积层输出结果做非线性映射</p>
<img src="v2-4f12096f7b6fb83ce6dc96b3ecf915c8_1440w.webp" alt="img">



<p>CNN采用的激活函数一般为ReLU(The Rectified Linear Unit&#x2F;修正线性单元)，它的特点是收敛快，求梯度简单，但较脆弱，图像如下。</p>
<img src="v2-a559927aa4df378c6b1a25c2cb86db5b_1440w.webp" alt="img">

<p><strong>激励层的实践经验：</strong></p>
<p>①不要用sigmoid！不要用sigmoid！不要用sigmoid<br>② 首先试RELU，因为快，但要小心点<br>③ 如果2失效，请用Leaky ReLU或者Maxout<br>④ 某些情况下tanh倒是有不错的结果，但是很少</p>
<h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>池化层夹在连续的卷积层中间， 用于压缩数据和参数的量，减小<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?q=%E8%BF%87%E6%8B%9F%E5%90%88&zhida_source=entity&is_preview=1">过拟合</a>。<br>简而言之，如<strong>果输入是图像的话，那么池化层的最主要作用就是压缩图像。</strong></p>
<p>这里再展开叙述池化层的具体作用：</p>
<ol>
<li>**特征<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?q=%E4%B8%8D%E5%8F%98%E6%80%A7&zhida_source=entity&is_preview=1">不变性</a>**，也就是我们在图像处理中经常提到的特征的尺度不变性，池化操作就是图像的resize，平时一张狗的图像被缩小了一倍我们还能认出这是一张狗的照片，这说明这张图像中仍保留着狗最重要的特征，我们一看就能判断图像中画的是一只狗，<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?q=%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9&zhida_source=entity&is_preview=1">图像压缩</a>时去掉的信息只是一些无关紧要的信息，而留下的信息则是具有尺度不变性的特征，是最能表达图像的特征。</li>
<li>**<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?q=%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4&zhida_source=entity&is_preview=1">特征降维</a>**，我们知道一幅图像含有的信息是很大的，特征也很多，但是有些信息对于我们做图像任务时没有太多用途或者有重复，我们可以把这类<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?q=%E5%86%97%E4%BD%99%E4%BF%A1%E6%81%AF&zhida_source=entity&is_preview=1">冗余信息</a>去除，把最重要的特征抽取出来，这也是池化操作的一大作用。</li>
<li>在一定程度上<strong>防止过拟合</strong>，更方便优化。</li>
</ol>
<img src="v2-deeacf1fc2ef42c0e41070fae4fb5381_1440w-1725865814124-32-1725865824045-34.webp" alt="img">



<p>池化层用的方法有Max pooling 和 average pooling，而实际用的较多的是<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?q=Max+pooling&zhida_source=entity&is_preview=1">Max pooling</a>。这里就说一下Max pooling，其实思想非常简单。</p>
<img src="v2-7b28abd70e3bc4294b2b28cc6ff348ef_1440w.webp" alt="img">



<p>对于每个2 * 2的窗口选出最大的数作为输出矩阵的相应元素的值，比如输入矩阵第一个2 * 2窗口中最大的数是6，那么输出矩阵的第一个元素就是6，如此类推。</p>
<h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>两层之间所有神经元都有权重连接，通常全连接层在卷积神经网络尾部。也就是跟传统的<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A5%9E%E7%BB%8F%E5%85%83&zhida_source=entity&is_preview=1">神经网络神经元</a>的连接方式是一样的：</p>
<img src="v2-9cbccaabf38a4c5c4c8494afc3556c12_1440w.webp" alt="img">



<h2 id="CNN代码实现一般步骤"><a href="#CNN代码实现一般步骤" class="headerlink" title="CNN代码实现一般步骤"></a>CNN代码实现一般步骤</h2><p>在实现卷积神经网络（CNN）时，常见的步骤可以分为以下几个部分。下面我将以 Python 和 TensorFlow&#x2F;Keras 为例，介绍 CNN 的一般实现步骤：</p>
<h3 id="1-导入必要的库"><a href="#1-导入必要的库" class="headerlink" title="1. 导入必要的库"></a>1. <strong>导入必要的库</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, models</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>

<h3 id="2-加载和预处理数据"><a href="#2-加载和预处理数据" class="headerlink" title="2. 加载和预处理数据"></a>2. <strong>加载和预处理数据</strong></h3><p>以 CIFAR-10 数据集为例，加载并预处理数据（包括归一化、划分训练集和测试集等）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载CIFAR-10数据集</span></span><br><span class="line">(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据归一化到0-1之间</span></span><br><span class="line">train_images, test_images = train_images / <span class="number">255.0</span>, test_images / <span class="number">255.0</span></span><br></pre></td></tr></table></figure>

<h3 id="3-构建CNN模型"><a href="#3-构建CNN模型" class="headerlink" title="3. 构建CNN模型"></a>3. <strong>构建CNN模型</strong></h3><p>构建一个简单的卷积神经网络模型，包括卷积层（Conv2D）、池化层（MaxPooling2D）、全连接层（Dense）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第1层卷积层和池化层</span></span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第2层卷积层和池化层</span></span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第3层卷积层和池化层</span></span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展平（Flatten）层，把3D特征图转成1D</span></span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 全连接层</span></span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出层，10个类</span></span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>))</span><br></pre></td></tr></table></figure>

<h3 id="4-编译模型"><a href="#4-编译模型" class="headerlink" title="4. 编译模型"></a>4. <strong>编译模型</strong></h3><p>在编译步骤中，指定损失函数、优化器和评估指标。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure>

<h3 id="5-训练模型"><a href="#5-训练模型" class="headerlink" title="5. 训练模型"></a>5. <strong>训练模型</strong></h3><p>使用训练数据训练模型，设置训练的批次大小和训练的轮数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(train_images, train_labels, epochs=<span class="number">10</span>, </span><br><span class="line">                    validation_data=(test_images, test_labels))</span><br></pre></td></tr></table></figure>

<h3 id="6-评估模型"><a href="#6-评估模型" class="headerlink" title="6. 评估模型"></a>6. <strong>评估模型</strong></h3><p>使用测试数据评估模型的准确性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n测试准确率: <span class="subst">&#123;test_acc&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="7-可视化训练过程"><a href="#7-可视化训练过程" class="headerlink" title="7. 可视化训练过程"></a>7. <strong>可视化训练过程</strong></h3><p>可以使用 Matplotlib 来可视化训练过程中的准确率和损失变化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(history.history[<span class="string">&#x27;accuracy&#x27;</span>], label=<span class="string">&#x27;训练准确率&#x27;</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_accuracy&#x27;</span>], label=<span class="string">&#x27;验证准确率&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;lower right&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol>
<li><strong>加载数据</strong>：准备数据并进行预处理。</li>
<li><strong>构建模型</strong>：搭建卷积层、池化层、全连接层等。</li>
<li><strong>编译模型</strong>：指定损失函数和优化器。</li>
<li><strong>训练模型</strong>：通过数据训练模型。</li>
<li><strong>评估模型</strong>：用测试集评估模型性能。</li>
<li><strong>可视化结果</strong>：查看训练过程中模型的表现。</li>
</ol>
<p>这就是实现卷积神经网络的一般步骤。可以根据需要增加模型的复杂度或改变超参数来优化模型。</p>
<h2 id="1D-CNN"><a href="#1D-CNN" class="headerlink" title="1D-CNN"></a>1D-CNN</h2><p>1D卷积神经网络（1D-CNN）是一种处理一维序列数据的深度学习模型。它广泛应用于时间序列数据、自然语言处理、音频信号处理等领域。</p>
<h3 id="1-输入数据"><a href="#1-输入数据" class="headerlink" title="1. 输入数据"></a>1. <strong>输入数据</strong></h3><p>1D-CNN 的输入是一个一维的序列数据，通常形状为 <code>(batch_size, sequence_length, channels)</code>，其中：</p>
<ul>
<li><code>batch_size</code>：一次性输入的样本数。</li>
<li><code>sequence_length</code>：输入序列的长度，例如时间序列数据的时间步长或文本中的单词数量。</li>
<li><code>channels</code>：输入数据的维度，例如时间序列中可以是不同传感器的数据，文本中可以是词向量的维度。</li>
</ul>
<h3 id="2-卷积操作"><a href="#2-卷积操作" class="headerlink" title="2. 卷积操作"></a>2. <strong>卷积操作</strong></h3><p>1D卷积的本质是在一维数据上滑动卷积核（过滤器），并对局部区域进行特征提取。具体过程如下：</p>
<ul>
<li><strong>卷积核（kernel&#x2F;filter）</strong>：一个大小为 <code>k</code> 的窗口，会滑动经过输入序列，并在每次滑动时计算输入和卷积核的逐点乘积和。</li>
<li><strong>滑动窗口</strong>：卷积核从输入数据的一端开始，以设定的步长（stride）向右滑动，依次计算出一系列的卷积结果（称为特征图，feature map）。</li>
<li><strong>输出特征图</strong>：每个卷积核在输入数据上滑动并计算输出，结果是一个新的序列，称为特征图。多个卷积核可以提取不同的特征，产生多个特征图。</li>
</ul>
<p>公式上可以表示为：<br>$$<br>{output}[i] &#x3D; \sum_{j&#x3D;1}^{k} \text{input}[i+j] \times \text{kernel}[j]<br>$$<br>其中，<code>i</code> 表示卷积窗口的起始位置，<code>k</code> 是卷积核的大小。</p>
<h3 id="3-激活函数"><a href="#3-激活函数" class="headerlink" title="3. 激活函数"></a>3. <strong>激活函数</strong></h3><p>卷积后的特征图通常会经过一个非线性激活函数（例如 ReLU），来引入非线性特性，提高模型的表达能力。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output = tf.nn.relu(conv_output)</span><br></pre></td></tr></table></figure>

<h3 id="4-池化操作（可选）"><a href="#4-池化操作（可选）" class="headerlink" title="4. 池化操作（可选）"></a>4. <strong>池化操作（可选）</strong></h3><p>1D-CNN 中通常使用池化操作（如最大池化 <code>max pooling</code> 或平均池化 <code>average pooling</code>），通过取窗口中的最大值或平均值来对特征进行下采样，减少数据维度，保留重要信息，同时防止过拟合。池化的窗口也是一维的，通常设定为固定大小。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pooled_output = tf.layers.max_pooling1d(output, pool_size=<span class="number">2</span>, strides=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<h3 id="5-多层卷积"><a href="#5-多层卷积" class="headerlink" title="5. 多层卷积"></a>5. <strong>多层卷积</strong></h3><p>1D-CNN 通常由多个卷积层堆叠而成，上一层的输出特征图作为下一层的输入，进一步提取特征。每一层的卷积核数量通常会增加，从而提取更多的特征。</p>
<h3 id="6-全连接层与分类层"><a href="#6-全连接层与分类层" class="headerlink" title="6. 全连接层与分类层"></a>6. <strong>全连接层与分类层</strong></h3><p>在卷积层的最后，1D-CNN 输出的特征图会通过一个全连接层（fully connected layer，FC）或多层感知器（MLP）进行进一步处理，通常用来进行分类、回归等任务。为了进行分类，最后的输出维度会设置为分类的类别数，并可能通过 softmax 函数将输出转化为概率分布。</p>
<h3 id="7-损失函数与优化"><a href="#7-损失函数与优化" class="headerlink" title="7. 损失函数与优化"></a>7. <strong>损失函数与优化</strong></h3><p>在分类任务中，1D-CNN 最终的输出会与真实标签计算损失（例如交叉熵损失），然后通过反向传播算法更新网络中的参数，优化模型的性能。</p>
<h3 id="1D-CNN-工作流程总结"><a href="#1D-CNN-工作流程总结" class="headerlink" title="1D-CNN 工作流程总结"></a>1D-CNN 工作流程总结</h3><ol>
<li><strong>输入</strong>：输入序列数据，如时间序列、文本数据等。</li>
<li><strong>卷积</strong>：卷积核滑动提取局部特征。</li>
<li><strong>激活</strong>：使用激活函数（如 ReLU）引入非线性。</li>
<li><strong>池化（可选）</strong>：下采样特征图，减少维度。</li>
<li><strong>多层卷积</strong>：重复堆叠卷积层，提取高级特征。</li>
<li><strong>全连接层</strong>：将提取的特征用于分类或回归任务。</li>
<li><strong>输出</strong>：分类或回归的结果，应用损失函数优化模型。</li>
</ol>
<h3 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h3><p>以下是一个简单的 1D-CNN 的实现示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义1D-CNN模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cnn_1d_model</span>(<span class="params">input_shape, num_classes</span>):</span><br><span class="line">    model = tf.keras.models.Sequential([</span><br><span class="line">        tf.keras.layers.Conv1D(filters=<span class="number">64</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=input_shape),</span><br><span class="line">        tf.keras.layers.MaxPooling1D(pool_size=<span class="number">2</span>),</span><br><span class="line">        tf.keras.layers.Conv1D(filters=<span class="number">128</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        tf.keras.layers.MaxPooling1D(pool_size=<span class="number">2</span>),</span><br><span class="line">        tf.keras.layers.Flatten(),</span><br><span class="line">        tf.keras.layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        tf.keras.layers.Dense(num_classes, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">    ])</span><br><span class="line">    </span><br><span class="line">    model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入形状 (sequence_length, channels)，假设序列长度为100，特征维度为10</span></span><br><span class="line">input_shape = (<span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line">num_classes = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">model = cnn_1d_model(input_shape, num_classes)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<h3 id="应用领域"><a href="#应用领域" class="headerlink" title="应用领域"></a>应用领域</h3><ul>
<li><strong>时间序列分析</strong>：如股票数据、传感器数据、心电图（ECG）信号。</li>
<li><strong>自然语言处理</strong>：文本分类、情感分析等任务。</li>
<li><strong>音频处理</strong>：如语音识别中的声学特征提取。</li>
</ul>
<p>1D-CNN 通过对一维序列数据的局部特征提取和特征组合，在许多应用中表现出色。</p>
<h2 id="2D-CNN"><a href="#2D-CNN" class="headerlink" title="2D-CNN"></a>2D-CNN</h2><p>2D卷积神经网络（2D-CNN）是处理二维数据的深度学习模型，特别适合处理图像、视频帧等二维结构的数据。它在计算机视觉任务（如图像分类、目标检测和分割）中广泛应用。以下是2D-CNN的详细过程：</p>
<h3 id="1-输入数据-1"><a href="#1-输入数据-1" class="headerlink" title="1. 输入数据"></a>1. <strong>输入数据</strong></h3><p>2D-CNN 的输入通常是二维数据，常见于图像。输入的形状一般为 <code>(batch_size, height, width, channels)</code>，其中：</p>
<ul>
<li><code>batch_size</code>：一次性处理的样本数。</li>
<li><code>height</code> 和 <code>width</code>：图像的高度和宽度。</li>
<li><code>channels</code>：通道数，如灰度图的通道数为1，RGB图像的通道数为3。</li>
</ul>
<p>例如，输入可能是 <code>28x28</code> 的灰度图像，形状为 <code>(batch_size, 28, 28, 1)</code>。</p>
<h3 id="2-卷积操作-1"><a href="#2-卷积操作-1" class="headerlink" title="2. 卷积操作"></a>2. <strong>卷积操作</strong></h3><p>卷积操作是 CNN 的核心，通过卷积核（filter）对输入图像进行局部特征提取。卷积操作通过将一个小窗口在输入图像上滑动，并计算其与窗口内数据的点积来生成输出特征图（feature map）。</p>
<h4 id="卷积步骤"><a href="#卷积步骤" class="headerlink" title="卷积步骤"></a><strong>卷积步骤</strong></h4><ul>
<li><strong>卷积核（kernel&#x2F;filter）</strong>：通常大小为 <code>k x k</code> 的二维矩阵（如 <code>3x3</code> 或 <code>5x5</code>），在输入图像上滑动。</li>
<li><strong>滑动窗口</strong>：卷积核从左上角开始，按照指定的步长（stride）在图像上滑动，生成每个局部区域的卷积输出。滑动的步长决定了特征图的输出大小。</li>
<li><strong>输出特征图</strong>：卷积操作在整个输入图像上滑动，输出一个新的二维特征图。多个卷积核可以提取不同的特征，因此会输出多个特征图。</li>
</ul>
<p>卷积操作的公式如下：<br>$$<br>{output}(i, j) &#x3D; \sum_{m&#x3D;1}^{k} \sum_{n&#x3D;1}^{k} \text{input}(i+m, j+n) \times \text{kernel}(m, n)<br>$$<br> 其中 <code>i, j</code> 是卷积核在输入图像上的位置。</p>
<h4 id="填充（Padding）"><a href="#填充（Padding）" class="headerlink" title="填充（Padding）"></a><strong>填充（Padding）</strong></h4><ul>
<li><strong>valid padding</strong>：不使用填充，卷积核只能滑动到图像的边界内，输出特征图的尺寸小于原图。</li>
<li><strong>same padding</strong>：在图像的边缘添加零填充，使得卷积操作后输出特征图的尺寸与输入图像相同。</li>
</ul>
<h3 id="3-激活函数-1"><a href="#3-激活函数-1" class="headerlink" title="3. 激活函数"></a>3. <strong>激活函数</strong></h3><p>卷积后的特征图通常通过激活函数（如 ReLU）来引入非线性，激活函数作用在每个卷积输出的元素上。ReLU（Rectified Linear Unit）的常用公式是：<br>$$<br>f(x)&#x3D;max⁡(0,x)<br>$$<br> ReLU 将负值置为 0，保持正值不变，提高了模型的非线性表达能力。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conv_output = tf.nn.relu(conv_output)</span><br></pre></td></tr></table></figure>

<h3 id="4-池化操作（Pooling）"><a href="#4-池化操作（Pooling）" class="headerlink" title="4. 池化操作（Pooling）"></a>4. <strong>池化操作（Pooling）</strong></h3><p>池化操作通过下采样的方式减少特征图的尺寸，从而减少模型计算量和防止过拟合。常见的池化方法有 <strong>最大池化（Max Pooling）</strong> 和 <strong>平均池化（Average Pooling）</strong>。</p>
<ul>
<li><strong>最大池化</strong>：取窗口内的最大值。</li>
<li><strong>平均池化</strong>：取窗口内所有值的平均值。</li>
</ul>
<p>池化窗口大小通常为 <code>2x2</code>，步长为2，这样每次池化会将特征图的大小减半。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pooled_output = tf.nn.max_pool(conv_output, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="5-多层卷积-1"><a href="#5-多层卷积-1" class="headerlink" title="5. 多层卷积"></a>5. <strong>多层卷积</strong></h3><p>2D-CNN 通常由多层卷积和池化层堆叠而成。每层卷积可以提取更高级的特征：</p>
<ul>
<li>第一层卷积可能提取边缘、角等低级特征。</li>
<li>随着层数加深，后续层能够提取更加复杂的特征，如物体的形状和结构。</li>
</ul>
<p>每一层卷积后的特征图通常会随着通道数增加，但空间维度（高度和宽度）通常会通过池化逐渐减小。</p>
<h3 id="6-全连接层（Fully-Connected-Layer-FC）"><a href="#6-全连接层（Fully-Connected-Layer-FC）" class="headerlink" title="6. 全连接层（Fully Connected Layer, FC）"></a>6. <strong>全连接层（Fully Connected Layer, FC）</strong></h3><p>在卷积层之后，通常会将2D特征图展平（Flatten），转化为一维向量，并通过全连接层进行分类或回归任务。</p>
<ul>
<li><strong>展平</strong>：将二维的特征图转换为一维向量，方便全连接层处理。</li>
<li><strong>全连接层</strong>：将展平的特征输入到全连接层，经过线性变换后输出最终的分类结果。最后一层的输出维度与类别数相等，表示每个类别的预测分数。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flattened = tf.layers.flatten(pooled_output)</span><br><span class="line">fc = tf.layers.dense(flattened, units=<span class="number">128</span>, activation=tf.nn.relu)</span><br><span class="line">logits = tf.layers.dense(fc, units=num_classes)</span><br></pre></td></tr></table></figure>

<h3 id="7-损失函数与优化-1"><a href="#7-损失函数与优化-1" class="headerlink" title="7. 损失函数与优化"></a>7. <strong>损失函数与优化</strong></h3><p>对于分类任务，最后一层通常输出一个类别数的向量，通过 <strong>softmax</strong> 函数将其转化为概率分布：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predictions = tf.nn.softmax(logits)</span><br></pre></td></tr></table></figure>

<p>损失函数通常使用交叉熵损失，通过反向传播和优化器（如 Adam 或 SGD）来优化模型。</p>
<h3 id="2D-CNN-工作流程总结"><a href="#2D-CNN-工作流程总结" class="headerlink" title="2D-CNN 工作流程总结"></a>2D-CNN 工作流程总结</h3><ol>
<li><strong>输入</strong>：二维数据，如图像。</li>
<li><strong>卷积层</strong>：提取局部特征，卷积核在图像上滑动。</li>
<li><strong>激活函数</strong>：如 ReLU 引入非线性。</li>
<li><strong>池化层</strong>：下采样特征图，减少维度。</li>
<li><strong>多层卷积与池化</strong>：堆叠多个卷积和池化层提取高级特征。</li>
<li><strong>展平与全连接层</strong>：将特征图展平，输入全连接层。</li>
<li><strong>输出层</strong>：通过 softmax 等进行分类，输出类别概率。</li>
</ol>
<h3 id="示例代码-1"><a href="#示例代码-1" class="headerlink" title="示例代码"></a>示例代码</h3><p>以下是一个简单的2D-CNN实现示例，用于处理输入的图像数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义2D-CNN模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cnn_2d_model</span>(<span class="params">input_shape, num_classes</span>):</span><br><span class="line">    model = tf.keras.models.Sequential([</span><br><span class="line">        tf.keras.layers.Conv2D(filters=<span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=input_shape),</span><br><span class="line">        tf.keras.layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">        tf.keras.layers.Conv2D(filters=<span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        tf.keras.layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">        tf.keras.layers.Flatten(),</span><br><span class="line">        tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        tf.keras.layers.Dense(num_classes, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">    ])</span><br><span class="line">    </span><br><span class="line">    model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设输入形状为28x28的灰度图，通道数为1，类别数为10</span></span><br><span class="line">input_shape = (<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">model = cnn_2d_model(input_shape, num_classes)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<h3 id="应用领域-1"><a href="#应用领域-1" class="headerlink" title="应用领域"></a>应用领域</h3><ul>
<li><strong>图像分类</strong>：如手写数字识别（MNIST）、物体识别（CIFAR-10）。</li>
<li><strong>目标检测</strong>：如人脸检测、行人检测等。</li>
<li><strong>图像分割</strong>：如医学图像的病灶区域分割。</li>
</ul>
<p>2D-CNN 通过局部卷积提取图像中的层级特征，逐步缩小空间维度，保留重要的高层次语义信息，在图像处理中取得了显著的成功。</p>
<h2 id="3D-CNN"><a href="#3D-CNN" class="headerlink" title="3D-CNN"></a>3D-CNN</h2><p>3D卷积神经网络（3D-CNN）是处理三维数据的深度学习模型，常用于视频处理、医学图像（如CT、MRI扫描）和体素数据等领域。与2D-CNN不同，3D-CNN的卷积操作在三维空间中进行，能够捕捉数据的空间和时间上的特征。以下是3D-CNN的详细过程：</p>
<h3 id="1-输入数据-2"><a href="#1-输入数据-2" class="headerlink" title="1. 输入数据"></a>1. <strong>输入数据</strong></h3><p>3D-CNN的输入通常是三维数据，常见于视频或医学图像。输入的形状一般为 <code>(batch_size, depth, height, width, channels)</code>，其中：</p>
<ul>
<li><code>batch_size</code>：一次性处理的样本数。</li>
<li><code>depth</code>：深度，表示输入数据的第三个维度，例如视频的帧数、体素数据的深度等。</li>
<li><code>height</code> 和 <code>width</code>：高度和宽度，表示输入的二维空间维度。</li>
<li><code>channels</code>：通道数，表示输入数据的通道数（如RGB图像的通道数为3）。</li>
</ul>
<p>例如，输入可能是 <code>16x128x128</code> 的体积数据（深度16，宽度128，高度128），形状为 <code>(batch_size, 16, 128, 128, 1)</code>。</p>
<h3 id="2-卷积操作-2"><a href="#2-卷积操作-2" class="headerlink" title="2. 卷积操作"></a>2. <strong>卷积操作</strong></h3><p>3D卷积操作与2D卷积类似，不同之处在于它在三维空间中滑动卷积核，提取局部的体积特征。卷积核在<code>depth</code>、<code>height</code>、<code>width</code>三个维度上滑动，产生三维的特征图。</p>
<h4 id="卷积步骤-1"><a href="#卷积步骤-1" class="headerlink" title="卷积步骤"></a><strong>卷积步骤</strong></h4><ul>
<li><strong>卷积核（kernel&#x2F;filter）</strong>：大小为 <code>k x k x k</code> 的三维矩阵（例如 <code>3x3x3</code> 或 <code>5x5x5</code>），在输入的体积数据上滑动，生成输出特征图。</li>
<li><strong>滑动窗口</strong>：卷积核在三维输入数据上滑动，按照指定的步长（stride）进行移动，步长可以在三维空间内控制移动的步幅。</li>
<li><strong>输出特征图</strong>：每次滑动后，将局部的输入数据与卷积核计算点积，生成一个输出值。整个卷积过程结束后，会生成三维的特征图。</li>
</ul>
<p>公式上，3D卷积的操作可以表示为：<br>$$<br>{output}(i, j, k) &#x3D; \sum_{d&#x3D;1}^{D} \sum_{h&#x3D;1}^{H} \sum_{w&#x3D;1}^{W} \text{input}(i+d, j+h, k+w) \times \text{kernel}(d, h, w)<br>$$<br>其中，<code>i, j, k</code> 是卷积核在输入数据上的位置，<code>D, H, W</code> 分别是卷积核的深度、高度和宽度。</p>
<h4 id="填充（Padding）-1"><a href="#填充（Padding）-1" class="headerlink" title="填充（Padding）"></a><strong>填充（Padding）</strong></h4><ul>
<li><strong>valid padding</strong>：不使用填充，卷积核只能滑动到数据的边界内，输出的特征图比输入数据尺寸小。</li>
<li><strong>same padding</strong>：在输入数据的边缘添加零填充，确保输出特征图的尺寸与输入相同。</li>
</ul>
<h3 id="3-激活函数-2"><a href="#3-激活函数-2" class="headerlink" title="3. 激活函数"></a>3. <strong>激活函数</strong></h3><p>卷积后的特征图通常会通过一个激活函数（如 ReLU）引入非线性。ReLU（Rectified Linear Unit）是最常见的激活函数，它将负值置为 0，保持正值不变。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conv_output = tf.nn.relu(conv_output)</span><br></pre></td></tr></table></figure>

<h3 id="4-池化操作（Pooling）-1"><a href="#4-池化操作（Pooling）-1" class="headerlink" title="4. 池化操作（Pooling）"></a>4. <strong>池化操作（Pooling）</strong></h3><p>在3D-CNN中，池化操作通常也在三维空间内进行，称为 <strong>3D池化（3D pooling）</strong>。它通过对体积特征的下采样，减少数据的空间和深度维度，从而减少计算量和防止过拟合。常用的池化方法有：</p>
<ul>
<li><strong>最大池化（Max Pooling）</strong>：取池化窗口内的最大值。</li>
<li><strong>平均池化（Average Pooling）</strong>：取池化窗口内所有值的平均值。</li>
</ul>
<p>池化的窗口通常为 <code>2x2x2</code>，步长为2，这样每次池化操作会将特征图的大小减半。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pooled_output = tf.nn.max_pool3d(conv_output, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="5-多层卷积-2"><a href="#5-多层卷积-2" class="headerlink" title="5. 多层卷积"></a>5. <strong>多层卷积</strong></h3><p>3D-CNN通常由多层卷积和池化层堆叠而成。每一层卷积提取的特征越来越复杂，前面的卷积层可能提取边缘、角等低级特征，而后面的层则提取更高级的特征，如物体的形状或视频中的运动模式。</p>
<h3 id="6-全连接层（Fully-Connected-Layer-FC）-1"><a href="#6-全连接层（Fully-Connected-Layer-FC）-1" class="headerlink" title="6. 全连接层（Fully Connected Layer, FC）"></a>6. <strong>全连接层（Fully Connected Layer, FC）</strong></h3><p>在卷积层和池化层之后，输出的三维特征图会被展平（Flatten）为一维向量，并通过全连接层处理，用于分类或回归任务。</p>
<ul>
<li><strong>展平</strong>：将3D特征图转换为一维向量，方便后续的全连接层处理。</li>
<li><strong>全连接层</strong>：一维向量输入到全连接层，通过线性变换后输出分类结果。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flattened = tf.layers.flatten(pooled_output)</span><br><span class="line">fc = tf.layers.dense(flattened, units=<span class="number">128</span>, activation=tf.nn.relu)</span><br><span class="line">logits = tf.layers.dense(fc, units=num_classes)</span><br></pre></td></tr></table></figure>

<h3 id="7-损失函数与优化-2"><a href="#7-损失函数与优化-2" class="headerlink" title="7. 损失函数与优化"></a>7. <strong>损失函数与优化</strong></h3><p>在分类任务中，最后的输出通常是一个类别数的向量，通过 <strong>softmax</strong> 函数将其转化为概率分布。损失函数通常使用交叉熵损失，然后通过反向传播和优化器（如Adam或SGD）来优化模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predictions = tf.nn.softmax(logits)</span><br></pre></td></tr></table></figure>

<h3 id="3D-CNN-工作流程总结"><a href="#3D-CNN-工作流程总结" class="headerlink" title="3D-CNN 工作流程总结"></a>3D-CNN 工作流程总结</h3><ol>
<li><strong>输入</strong>：三维数据，如视频序列、体素数据或医学图像（CT&#x2F;MRI）。</li>
<li><strong>卷积层</strong>：在三维数据上进行卷积操作，提取局部体积特征。</li>
<li><strong>激活函数</strong>：如 ReLU 引入非线性。</li>
<li><strong>池化层</strong>：对体积特征进行下采样，减少数据维度。</li>
<li><strong>多层卷积与池化</strong>：堆叠多个卷积层，提取更高级的特征。</li>
<li><strong>展平与全连接层</strong>：将三维特征图展平为一维向量，输入全连接层进行分类或回归。</li>
<li><strong>输出层</strong>：通过softmax等进行分类，输出类别概率。</li>
</ol>
<h3 id="示例代码-2"><a href="#示例代码-2" class="headerlink" title="示例代码"></a>示例代码</h3><p>以下是一个简单的3D-CNN实现示例，用于处理输入的三维体积数据（如视频或体素数据）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义3D-CNN模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cnn_3d_model</span>(<span class="params">input_shape, num_classes</span>):</span><br><span class="line">    model = tf.keras.models.Sequential([</span><br><span class="line">        tf.keras.layers.Conv3D(filters=<span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=input_shape),</span><br><span class="line">        tf.keras.layers.MaxPooling3D(pool_size=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">        tf.keras.layers.Conv3D(filters=<span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        tf.keras.layers.MaxPooling3D(pool_size=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">        tf.keras.layers.Flatten(),</span><br><span class="line">        tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        tf.keras.layers.Dense(num_classes, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">    ])</span><br><span class="line">    </span><br><span class="line">    model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设输入形状为16x128x128的体积数据，通道数为1，类别数为10</span></span><br><span class="line">input_shape = (<span class="number">16</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="number">1</span>)</span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">model = cnn_3d_model(input_shape, num_classes)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<h3 id="应用领域-2"><a href="#应用领域-2" class="headerlink" title="应用领域"></a>应用领域</h3><ul>
<li><strong>视频分析</strong>：如动作识别、视频分类。</li>
<li><strong>医学图像处理</strong>：如三维CT、MRI扫描的病灶检测与分类。</li>
<li><strong>体素数据分析</strong>：如3D建模、3D物体识别。</li>
</ul>
<p>3D-CNN通过对三维数据的局部卷积提取体积特征，可以捕捉空间和时间上的依赖性，特别适合处理三维或多帧数据。</p>

        
        
          <blockquote id="copyright">
              <p>Original link: <a href="http://example.com/index.html">http://example.com/index.html</a></p>
              <p>Copyright Notice: 转载请注明出处.</p>
          </blockquote>
        
      
    </div>
    <footer class="article-footer">
      
        <div class="article-tag-wrap">
          

          
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CNN-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">CNN 深度学习</a></li></ul>

          
    <div class="social-share">
      <span>Share:</span>
    </div>



        </div>
      
      
      
    </footer>
  </div>
</article>


  <article id="post-test" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/09/09/test/">test</a>
    </h1>
  


      </header>
    
    <div class="article-meta">
      
      <span class="article-date">
  <i class="fa fa-date"></i>
  <time class="dt-published" datetime="2024-09-09T07:34:28.000Z" itemprop="datePublished">2024年09月09日</time>
</span>
      
      
      
<a href="/2024/09/09/test/#comments" class="article-comment-link">
  
  <i class="fa fa-commt"></i>
  Guestbook
</a>


    </div>
    <div class="e-content article-entry" itemprop="articleBody">
      
        <img src="image-20240909153448635.png">


        
        
          <blockquote id="copyright">
              <p>Original link: <a href="http://example.com/index.html">http://example.com/index.html</a></p>
              <p>Copyright Notice: 转载请注明出处.</p>
          </blockquote>
        
      
    </div>
    <footer class="article-footer">
      
        <div class="article-tag-wrap">
          

          
          
    <div class="social-share">
      <span>Share:</span>
    </div>



        </div>
      
      
      
    </footer>
  </div>
</article>


  <article id="post-NumPy" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/07/01/NumPy/">NumPy</a>
    </h1>
  


      </header>
    
    <div class="article-meta">
      
      <span class="article-date">
  <i class="fa fa-date"></i>
  <time class="dt-published" datetime="2024-07-01T08:18:24.000Z" itemprop="datePublished">2024年07月01日</time>
</span>
      
      
      
<a href="/2024/07/01/NumPy/#comments" class="article-comment-link">
  
  <i class="fa fa-commt"></i>
  Guestbook
</a>


    </div>
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="NumPy"><a href="#NumPy" class="headerlink" title="NumPy"></a>NumPy</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>NumPy是一个开源的Python库，专为数值计算设计。它为高性能的多维数组对象提供了支持，并包含了大量的操作这些数组的函数和工具。由于其功能强大、使用简便，NumPy成为了科学计算、数据分析、机器学习等领域中使用Python的基石之一。</p>
<h3 id="核心特性"><a href="#核心特性" class="headerlink" title="核心特性"></a>核心特性</h3><ol>
<li><strong>多维数组对象（ndarray）</strong>：NumPy的核心是多维数组对象，也即ndarray。这个对象是一个快速、灵活的大数据容器，允许你进行向量化的数学运算。</li>
<li><strong>广播功能</strong>：在进行数组运算时，NumPy能够处理不同形状的数组，使得数组间的运算变得简单、直观。</li>
<li><strong>高效的数学函数库</strong>：提供了大量的数学函数，包括线性代数运算、傅里叶变换和统计操作等，以便对这些多维数组进行高效操作。</li>
<li><strong>集成C&#x2F;C++和Fortran代码</strong>：NumPy允许你将C&#x2F;C++和Fortran代码直接集成到Python环境中，这使得在算法上可以达到极高的计算效率。</li>
<li><strong>灵活的内存映射</strong>：支持让数据直接在硬盘和内存中映射存储，这对处理大量数据尤其有用。</li>
</ol>
<h3 id="应用领域"><a href="#应用领域" class="headerlink" title="应用领域"></a>应用领域</h3><ul>
<li><strong>科学计算</strong>：NumPy提供了大量的数学函数库，使其成为科学计算中不可或缺的工具，广泛应用于物理、天文、工程等领域。</li>
<li><strong>数据分析</strong>：在数据预处理、转换和操作等方面，NumPy提供了简便、快速的方法，是进行数据分析不可分割的一部分。</li>
<li><strong>机器学习</strong>：作为机器学习中进行数值计算和数据处理的基础库，NumPy为各种机器学习框架提供了底层支持。</li>
<li><strong>图像处理与计算机视觉</strong>：NumPy的数组操作能够方便地用于图像上的各种变换和处理。</li>
</ul>
<h2 id="ndarray：多维数组对象"><a href="#ndarray：多维数组对象" class="headerlink" title="ndarray：多维数组对象"></a>ndarray：多维数组对象</h2><p>NumPy最重要的一个特点就是其N维数组对象（即ndarray），该对象是一个快速而灵活的大数据集容器。你可以利用这种数组对整块数据执行一些数学运算，其语法跟标量元素之间的运算一样。</p>
<p>ndarray是一个通用的同构数据多维容器，也就是说，其中的所有元素必须是相同类型的。每个数组都有一个shape（一个表示各维度大小的元组）和一个dtype（一个用于说明数组数据类型的对象）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">data = np.random.randn(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(data)</span><br><span class="line">data1 = data * <span class="number">100</span></span><br><span class="line"><span class="built_in">print</span>(data1)</span><br><span class="line">data1 += data1</span><br><span class="line"><span class="built_in">print</span>(data1)</span><br><span class="line"><span class="built_in">print</span>(data.shape, data.dtype)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="创建ndarry对象"><a href="#创建ndarry对象" class="headerlink" title="创建ndarry对象"></a>创建ndarry对象</h3><p>创建数组最简单的办法就是使用array函数。它接受一切序列型的对象（包括其他数组），然后产生一个新的含有传入数据的NumPy数组。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个列表转换</span></span><br><span class="line">arr1 = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">8.7</span>]</span><br><span class="line">nparr1 = np.array(arr1)</span><br><span class="line"><span class="built_in">print</span>(nparr1, nparr1.shape, nparr1.dtype)</span><br><span class="line"><span class="comment"># 嵌套序列（比如由一组等长列表组成的列表）将会被转换为一个多维数组：</span></span><br><span class="line">arr2 = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]</span><br><span class="line">nparr2 = np.array(arr2)</span><br><span class="line"><span class="built_in">print</span>(nparr2, <span class="string">&#x27;\n&#x27;</span>, nparr2.shape, nparr2.dtype)</span><br></pre></td></tr></table></figure>

<p>除非特别说明（稍后将会详细介绍），np.array会尝试为新建的这个数组推断出一个较为合适的数据类型。数据类型保存在一个特殊的dtype对象中。</p>
<p>除np.array之外，还有一些函数也可以新建数组。比如，zeros和ones分别可以创建指定长度或形状的全0或全1数组。empty可以创建一个没有任何具体值的数组。要用这些方法创建多维数组，只需传入一个表示形状的元组即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nparr3 = np.zeros((<span class="number">3</span>, <span class="number">3</span>), numpy.int32)</span><br><span class="line"><span class="built_in">print</span>(nparr3)</span><br><span class="line"><span class="built_in">print</span>(np.empty((<span class="number">3</span>, <span class="number">3</span>)))</span><br><span class="line"><span class="built_in">print</span>(np.ones((<span class="number">3</span>, <span class="number">3</span>)))</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：认为np.empty会返回全0数组的想法是不安全的。很多情况下（如前所示），它返回的都是一些未初始化的垃圾值(随机值)。</p>
</blockquote>
<p>arange是Python内置函数range的数组版：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.arange(<span class="number">20</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]</span></span><br></pre></td></tr></table></figure>

<p>下表列出了一些数组创建函数。由于NumPy关注的是数值计算，因此，如果没有特别指定，数据类型基本都是float64（浮点数）。</p>
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>array</td>
<td>将输入数据转化为narray，默认直接复制输入数据</td>
</tr>
<tr>
<td>asarray</td>
<td>将输入数据转化为ndarray，如果输入数据是ndarray就不进行复制</td>
</tr>
<tr>
<td>arrange</td>
<td>返回在指定区间内的均匀分布的值</td>
</tr>
<tr>
<td>zeros</td>
<td>返回具有指定shape和类型的新数组，填充元素0</td>
</tr>
<tr>
<td>zeros_like</td>
<td>返回和输入参数参数具有相同shape和类型的新数组，填充元素0</td>
</tr>
<tr>
<td>ones</td>
<td>返回指定形状和类型的数组、填充元素‘1’.</td>
</tr>
<tr>
<td>ones_like</td>
<td>返回和给定数组具有相同形状和类型的数组</td>
</tr>
<tr>
<td>identity</td>
<td>返回主对角线上都是1的数组</td>
</tr>
<tr>
<td>empty</td>
<td>返回指定形状和类型的数组，并未初始化条目</td>
</tr>
<tr>
<td>empty_like</td>
<td>返回指定数组形状和类型的数组，并未初始化条目</td>
</tr>
</tbody></table>
<h3 id="ndarray数据类型"><a href="#ndarray数据类型" class="headerlink" title="ndarray数据类型"></a>ndarray数据类型</h3><p>numpy 支持的数据类型比 Python 内置的类型要多很多，基本上可以和 C 语言的数据类型对应上，其中部分类型对应为 Python 内置的类型。下表列举了常用 NumPy 基本类型。</p>
<table>
<thead>
<tr>
<th>数据类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>bool_</td>
<td>布尔型数据类型（True 或者 False）</td>
</tr>
<tr>
<td>int_</td>
<td>默认的整数类型（类似于 C 语言中的 long，int32 或 int64）</td>
</tr>
<tr>
<td>intc</td>
<td>与 C 的 int 类型一样，一般是 int32 或 int 64</td>
</tr>
<tr>
<td>intp</td>
<td>用于索引的整数类型（类似于 C 的 ssize_t，一般情况下仍然是 int32 或 int64）</td>
</tr>
<tr>
<td>int8</td>
<td>字节（-128 to 127）</td>
</tr>
<tr>
<td>int16</td>
<td>整数（-32768 to 32767）</td>
</tr>
<tr>
<td>int32</td>
<td>整数（-2147483648 to 2147483647）</td>
</tr>
<tr>
<td>int64</td>
<td>整数（-9223372036854775808 to 9223372036854775807）</td>
</tr>
<tr>
<td>uint8</td>
<td>无符号整数（0 to 255）</td>
</tr>
<tr>
<td>uint16</td>
<td>无符号整数（0 to 65535）</td>
</tr>
<tr>
<td>uint32</td>
<td>无符号整数（0 to 4294967295）</td>
</tr>
<tr>
<td>uint64</td>
<td>无符号整数（0 to 18446744073709551615）</td>
</tr>
<tr>
<td>float_</td>
<td>float64 类型的简写</td>
</tr>
<tr>
<td>float16</td>
<td>半精度浮点数，包括：1 个符号位，5 个指数位，10 个尾数位</td>
</tr>
<tr>
<td>float32</td>
<td>单精度浮点数，包括：1 个符号位，8 个指数位，23 个尾数位</td>
</tr>
<tr>
<td>float64</td>
<td>双精度浮点数，包括：1 个符号位，11 个指数位，52 个尾数位</td>
</tr>
<tr>
<td>complex_</td>
<td>complex128 类型的简写，即 128 位复数</td>
</tr>
<tr>
<td>complex64</td>
<td>复数，表示双 32 位浮点数（实数部分和虚数部分）</td>
</tr>
<tr>
<td>complex128</td>
<td>复数，表示双 64 位浮点数（实数部分和虚数部分）</td>
</tr>
<tr>
<td>object</td>
<td>python对象类型</td>
</tr>
<tr>
<td>string_</td>
<td>固定长度的字符串类型</td>
</tr>
<tr>
<td>unicode_</td>
<td>固定长度的unicode类型</td>
</tr>
</tbody></table>
<p>可以通过ndarray的astype方法明确地将一个数组从一个dtype转换成另一个dtype：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用astype改变数据类型</span></span><br><span class="line">arr2 = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]</span><br><span class="line">nparr2 = np.array(arr2)</span><br><span class="line">asarr = nparr2.astype(np.float32)</span><br><span class="line"><span class="built_in">print</span>(asarr)</span><br><span class="line"><span class="built_in">print</span>(asarr.dtype)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果将浮点数转换成整数，则小数部分将会被截取删除</p>
</blockquote>
<p><strong>注意：</strong>调用astype总会创建一个新的数组（一个数据的备份），即使新的dtype与旧的dtype相同。</p>
<h3 id="NumPy数组的运算"><a href="#NumPy数组的运算" class="headerlink" title="NumPy数组的运算"></a>NumPy数组的运算</h3><p>数组很重要，因为它使你不用编写循环即可对数据执行批量运算。NumPy用户称其为矢量化（vectorization）。大小相等的数组之间的任何算术运算都会将运算应用到元素级：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">arr = [[<span class="number">1.</span>,<span class="number">2.</span>, <span class="number">3.</span>], [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>], [<span class="number">7.</span>, <span class="number">8.</span>, <span class="number">9.</span>]]</span><br><span class="line">arr1 = np.array(arr)</span><br><span class="line"><span class="built_in">print</span>(arr1)</span><br><span class="line"><span class="built_in">print</span>(arr1 * arr1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># [[1. 2. 3.]</span></span><br><span class="line"><span class="comment">#  [4. 5. 6.]</span></span><br><span class="line"><span class="comment"># [7. 8. 9.]]</span></span><br><span class="line"><span class="comment"># [[ 1.  4.  9.]</span></span><br><span class="line"><span class="comment">#  [16. 25. 36.]</span></span><br><span class="line"><span class="comment"># [49. 64. 81.]]</span></span><br></pre></td></tr></table></figure>

<p>数组与标量的算术运算会将标量值传播到各个元素：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(arr1 + <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="number">1</span> / arr1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># [[ 3.  4.  5.]</span></span><br><span class="line"><span class="comment">#  [ 6.  7.  8.]</span></span><br><span class="line"><span class="comment"># [ 9. 10. 11.]]</span></span><br><span class="line"><span class="comment"># [[1.         0.5        0.33333333]</span></span><br><span class="line"><span class="comment">#  [0.25       0.2        0.16666667]</span></span><br><span class="line"><span class="comment"># [0.14285714 0.125      0.11111111]]</span></span><br></pre></td></tr></table></figure>

<p>大小相同的数组之间的比较会生成布尔值数组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">arr = [[<span class="number">1.</span>,<span class="number">2.3</span>, <span class="number">3.55</span>], [<span class="number">3.1</span>, <span class="number">3.78</span>, <span class="number">6.1</span>], [<span class="number">5.986</span>, <span class="number">8.1</span>, <span class="number">2.43</span>]]</span><br><span class="line">arr2 = np.array(arr)</span><br><span class="line"><span class="built_in">print</span>(arr2 &gt; arr1)</span><br><span class="line"><span class="comment"># [[False  True  True]</span></span><br><span class="line"><span class="comment">#  [False False  True]</span></span><br><span class="line"><span class="comment"># [False  True False]]</span></span><br></pre></td></tr></table></figure>

<h3 id="基本的索引和切片"><a href="#基本的索引和切片" class="headerlink" title="基本的索引和切片"></a>基本的索引和切片</h3><p>NumPy数组的索引是一个内容丰富的主题，因为选取数据子集或单个元素的方式有很多。一维数组很简单。从表面上看，它们跟Python列表的功能差不多：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">arr = np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(arr[<span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span>(arr[<span class="number">2</span>: <span class="number">5</span>])</span><br><span class="line">arr[<span class="number">2</span>: <span class="number">5</span>] = <span class="number">20</span></span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line"><span class="comment"># 4</span></span><br><span class="line"><span class="comment"># [2 3 4]</span></span><br><span class="line"><span class="comment"># [ 0  1 20 20 20  5  6  7  8  9]</span></span><br></pre></td></tr></table></figure>

<p>如上所示，当你将一个标量值赋值给一个切片时（如arr[5:8]&#x3D;12），该值会自动传播（也就说后面将会讲到的“广播”）到整个选区。跟列表最重要的区别在于，数组切片是原始数组的视图。这意味着数据不会被复制，视图上的任何修改都会直接反映到源数组上。</p>
<p>先创建一个arr的切片，当我修改arr_slice中的值，变动也会体现在原始数组arr中，切片[ : ]会给数组中的所有值赋值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建arr切片，得到arr_slice视图</span></span><br><span class="line">arr_slice = arr[<span class="number">2</span>:<span class="number">5</span>]</span><br><span class="line"><span class="built_in">print</span>(arr_slice)</span><br><span class="line"><span class="comment"># 修改arr_slice试图，arr也会随着修改</span></span><br><span class="line">arr_slice[<span class="number">0</span>: <span class="number">2</span>] = <span class="number">1000</span></span><br><span class="line"><span class="built_in">print</span>(arr_slice)</span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line">arr[:] = <span class="number">62</span></span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line"><span class="comment"># [20 20 20]</span></span><br><span class="line"><span class="comment"># [1000 1000   20]</span></span><br><span class="line"><span class="comment"># [   0    1 1000 1000   20    5    6    7    8    9]</span></span><br><span class="line"><span class="comment"># [62 62 62 62 62 62 62 62 62 62]</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：如果想要得到的是ndarray切片的一份副本而非视图，就需要明确地进行复制操作，例如<code>arr[5:8].copy()</code>。</p>
</blockquote>
<p>对于高维度数组，能做的事情更多。在一个二维数组中，各索引位置上的元素不再是标量而是一维数组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">arr = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]]</span><br><span class="line">np_arr = np.array(arr)</span><br><span class="line"><span class="built_in">print</span>(np_arr)</span><br><span class="line"><span class="built_in">print</span>(np_arr[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># [[1 2 3]</span></span><br><span class="line"><span class="comment">#  [4 5 6]</span></span><br><span class="line"><span class="comment"># [7 8 9]]</span></span><br><span class="line"><span class="comment"># [1 2 3]</span></span><br></pre></td></tr></table></figure>

<p>因此，可以对各个元素进行递归访问，但这样需要做的事情有点多。你可以传入一个以逗号隔开的索引列表来选取单个元素。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np_arr[<span class="number">1</span>][<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(np_arr[<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"><span class="comment"># 5</span></span><br><span class="line"><span class="comment"># 5</span></span><br></pre></td></tr></table></figure>

<h3 id="切片索引"><a href="#切片索引" class="headerlink" title="切片索引"></a>切片索引</h3><p>ndarray的切片语法跟Python列表这样的一维对象差不多：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arr = np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(arr[<span class="number">1</span>: <span class="number">7</span>])</span><br><span class="line"><span class="comment"># [1 2 3 4 5 6]</span></span><br></pre></td></tr></table></figure>

<p>对于之前的二维数组，其切片方式稍显不同：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arr = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]]</span><br><span class="line">np_arr = np.array(arr)</span><br><span class="line"><span class="built_in">print</span>(np_arr[<span class="number">1</span>, :<span class="number">3</span>])</span><br><span class="line"><span class="comment"># [[4 5 6]]</span></span><br></pre></td></tr></table></figure>

<p><strong>对切片表达式的赋值操作也会被扩散到整个选区</strong></p>
<h3 id="布尔型索引"><a href="#布尔型索引" class="headerlink" title="布尔型索引"></a>布尔型索引</h3><p>假设有一个用于存储数据的数组以及一个存储姓名的数组（含有重复项），假设每个名字都对应data数组中的一行，而我们想要选出对应于名字”Bob”的所有行。跟算术运算一样，数组的比较运算（如&#x3D;&#x3D;）也是矢量化的。因此，对names和字符串”Bob”的比较运算将会产生一个布尔型数组，这个布尔型数组可用于数组索引：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">names = np.array([<span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>, <span class="string">&#x27;Will&#x27;</span>, <span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Will&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>])</span><br><span class="line">data = np.random.randn(<span class="number">7</span>, <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;data = \n&#x27;</span>, data)</span><br><span class="line"><span class="comment"># names和字符串&quot;Bob&quot;的比较运算将会产生一个布尔型数组</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;names == \&#x27;Bob\&#x27;: \n&#x27;</span>, names == <span class="string">&#x27;Bob&#x27;</span>)</span><br><span class="line"><span class="comment"># 布尔型数组可用于数组索引</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;data[names == \&#x27;Bob\&#x27;]: \n&#x27;</span>, data[names == <span class="string">&#x27;Bob&#x27;</span>])</span><br><span class="line"><span class="comment"># data =</span></span><br><span class="line"><span class="comment"># [[-2.06312192 -0.47269856 -1.92389771  0.91278498]</span></span><br><span class="line"><span class="comment">#  [-2.58358617 -0.03263164 -0.08267246 -0.69128665]</span></span><br><span class="line"><span class="comment">#  [ 0.52652726 -0.48812597  0.09661174  1.18237505]</span></span><br><span class="line"><span class="comment"># [-0.25987874 -1.07423519  0.52132457  0.04803203]</span></span><br><span class="line"><span class="comment"># [-0.16248655 -0.98312311 -0.35371249 -0.26627604]</span></span><br><span class="line"><span class="comment"># [-0.75293904 -1.11616931  0.17385702 -0.55176087]</span></span><br><span class="line"><span class="comment"># [ 0.71264865 -0.25099606  0.36425637  0.41166286]]</span></span><br><span class="line"><span class="comment"># names == &#x27;Bob&#x27;:</span></span><br><span class="line"><span class="comment"># [ True False False  True False False False]</span></span><br><span class="line"><span class="comment"># data[names == &#x27;Bob&#x27;]:</span></span><br><span class="line"><span class="comment"># [[-2.06312192 -0.47269856 -1.92389771  0.91278498]</span></span><br><span class="line"><span class="comment">#  [-0.25987874 -1.07423519  0.52132457  0.04803203]]</span></span><br></pre></td></tr></table></figure>

<p>布尔型数组的长度必须跟被索引的轴长度一致。此外，还可以将布尔型数组跟切片、整数混合使用。</p>
<blockquote>
<p>注意：如果布尔型数组的长度不对，布尔型选择就会出错，因此一定要小心。</p>
</blockquote>
<p>要选择除”Bob”以外的其他值，既可以使用不等于符号（!&#x3D;），也可以通过~对条件进行否定：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;data[names != \&#x27;Bob\&#x27;]: \n&#x27;</span>, data[names != <span class="string">&#x27;Bob&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;data[names != \&#x27;Bob\&#x27;]: \n&#x27;</span>, data[~(names == <span class="string">&#x27;Bob&#x27;</span>)])</span><br><span class="line"><span class="comment"># data[names != &#x27;Bob&#x27;]:</span></span><br><span class="line"><span class="comment"># [[ 0.16468039 -1.03862911 -1.17996131  0.05199666]</span></span><br><span class="line"><span class="comment">#  [-1.43097098 -0.0990478   1.03564949  0.95265985]</span></span><br><span class="line"><span class="comment"># [-1.46271439 -2.02827434 -1.33157357 -1.14378972]</span></span><br><span class="line"><span class="comment"># [-0.66219836 -0.40306316 -0.62727381 -0.21806554]</span></span><br><span class="line"><span class="comment"># [ 0.40196128  1.11803113 -0.51840519 -1.18794547]]</span></span><br><span class="line"><span class="comment"># data[names != &#x27;Bob&#x27;]:</span></span><br><span class="line"><span class="comment"># [[ 0.16468039 -1.03862911 -1.17996131  0.05199666]</span></span><br><span class="line"><span class="comment">#  [-1.43097098 -0.0990478   1.03564949  0.95265985]</span></span><br><span class="line"><span class="comment"># [-1.46271439 -2.02827434 -1.33157357 -1.14378972]</span></span><br><span class="line"><span class="comment"># [-0.66219836 -0.40306316 -0.62727381 -0.21806554]</span></span><br><span class="line"><span class="comment"># [ 0.40196128  1.11803113 -0.51840519 -1.18794547]]</span></span><br></pre></td></tr></table></figure>

<p>选取这三个名字中的两个需要组合应用多个布尔条件，使用&amp;（和）、|（或）之类的布尔算术运算符即可，通过布尔型索引选取数组中的数据，将总是创建数据的副本，即使返回一模一样的数组也是如此。</p>
<blockquote>
<p>注意：Python关键字and和or在布尔型数组中无效。要使用&amp;与|。</p>
</blockquote>
<h3 id="花式索引"><a href="#花式索引" class="headerlink" title="花式索引"></a>花式索引</h3><p>花式索引（Fancy indexing）是一个NumPy术语，它指的是利用整数数组进行索引。对于二维数组而言第一个数组选取的是二维数组的行，第二个数组选取的是二维数组的列。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">arr = np.arange(<span class="number">32</span>).reshape(<span class="number">8</span>, <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line"><span class="built_in">print</span>(arr[[<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(arr[[<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">0</span>, <span class="number">3</span>, <span class="number">2</span>]])</span><br><span class="line"><span class="comment"># [[ 0  1  2  3]</span></span><br><span class="line"><span class="comment">#  [ 4  5  6  7]</span></span><br><span class="line"><span class="comment"># [ 8  9 10 11]</span></span><br><span class="line"><span class="comment"># [12 13 14 15]</span></span><br><span class="line"><span class="comment"># [16 17 18 19]</span></span><br><span class="line"><span class="comment"># [20 21 22 23]</span></span><br><span class="line"><span class="comment"># [24 25 26 27]</span></span><br><span class="line"><span class="comment"># [28 29 30 31]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># [[ 4  5  6  7]</span></span><br><span class="line"><span class="comment">#  [12 13 14 15]</span></span><br><span class="line"><span class="comment"># [16 17 18 19]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># [ 4 15 18]</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>使用负数索引将会从末尾开始选取行。</p>
</blockquote>
<h2 id="数组转置和轴对换"><a href="#数组转置和轴对换" class="headerlink" title="数组转置和轴对换"></a>数组转置和轴对换</h2><p>转置是重塑的一种特殊形式，它返回的是源数据的视图（不会进行任何复制操作）。数组不仅有transpose方法，还有一个特殊的T属性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">arr = np.arange(<span class="number">15</span>).reshape(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line"><span class="built_in">print</span>(arr.T)</span><br><span class="line"><span class="comment"># [[ 0  1  2  3  4]</span></span><br><span class="line"><span class="comment">#  [ 5  6  7  8  9]</span></span><br><span class="line"><span class="comment"># [10 11 12 13 14]]</span></span><br><span class="line"><span class="comment"># [[ 0  5 10]</span></span><br><span class="line"><span class="comment">#  [ 1  6 11]</span></span><br><span class="line"><span class="comment"># [ 2  7 12]</span></span><br><span class="line"><span class="comment"># [ 3  8 13]</span></span><br><span class="line"><span class="comment"># [ 4  9 14]]</span></span><br></pre></td></tr></table></figure>

<p>在进行矩阵计算时，经常需要用到该操作，比如利用np.dot计算矩阵内积：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.dot(arr, arr.T))</span><br><span class="line"><span class="comment"># [[ 30  80 130]</span></span><br><span class="line"><span class="comment">#  [ 80 255 430]</span></span><br><span class="line"><span class="comment"># [130 430 730]]</span></span><br></pre></td></tr></table></figure>

<p>对于高维数组，transpose需要得到一个由轴编号组成的元组才能对这些轴进行转置（比较费脑子）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">arr = np.arange(<span class="number">16</span>).reshape((<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>))</span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line"><span class="built_in">print</span>(arr.transpose(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># [[ 0  1  2  3  4]</span></span><br><span class="line"><span class="comment">#  [ 5  6  7  8  9]</span></span><br><span class="line"><span class="comment"># [10 11 12 13 14]]</span></span><br><span class="line"><span class="comment"># [[ 0  5 10]</span></span><br><span class="line"><span class="comment">#  [ 1  6 11]</span></span><br><span class="line"><span class="comment"># [ 2  7 12]</span></span><br><span class="line"><span class="comment"># [ 3  8 13]</span></span><br><span class="line"><span class="comment"># [ 4  9 14]]</span></span><br><span class="line"><span class="comment"># [[ 30  80 130]</span></span><br><span class="line"><span class="comment">#  [ 80 255 430]</span></span><br><span class="line"><span class="comment"># [130 430 730]]</span></span><br><span class="line"><span class="comment"># [[[ 0  1  2  3]</span></span><br><span class="line"><span class="comment">#   [ 4  5  6  7]]</span></span><br></pre></td></tr></table></figure>

<h2 id="通用函数"><a href="#通用函数" class="headerlink" title="通用函数"></a>通用函数</h2><p>通用函数（即ufunc）是一种对ndarray中的数据执行元素级运算的函数。你可以将其看做简单函数（接受一个或多个标量值，并产生一个或多个标量值）的矢量化包装器。</p>
<p>许多ufunc都是简单的元素级变体，如sqrt和exp：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">arr = np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(np.sqrt(arr))</span><br><span class="line"><span class="built_in">print</span>(np.exp(arr))	</span><br><span class="line"><span class="comment"># [0.         1.         1.41421356 1.73205081 2.         2.23606798</span></span><br><span class="line"><span class="comment">#  2.44948974 2.64575131 2.82842712 3.        ]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># [1.00000000e+00 2.71828183e+00 7.38905610e+00 2.00855369e+01</span></span><br><span class="line"><span class="comment">#  5.45981500e+01 1.48413159e+02 4.03428793e+02 1.09663316e+03</span></span><br><span class="line"><span class="comment">#  2.98095799e+03 8.10308393e+03]</span></span><br></pre></td></tr></table></figure>

<p>这些都是一元（unary）ufunc。另外一些（如add或maximum）接受2个数组（因此也叫二元（binary）ufunc），并返回一个结果数组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">arr1 = np.random.randn(<span class="number">10</span>)</span><br><span class="line">arr2 = np.random.randn(<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(arr1)</span><br><span class="line"><span class="built_in">print</span>(arr2)</span><br><span class="line">add_arr = np.add(arr1, arr2)</span><br><span class="line"><span class="built_in">print</span>(add_arr)</span><br><span class="line"><span class="built_in">print</span>(np.sqrt(add_arr))</span><br><span class="line">max_arr = np.maximum(arr1, arr2)</span><br><span class="line"><span class="built_in">print</span>(max_arr)</span><br><span class="line"><span class="comment"># [ 1.38436386 -1.15920008 -0.14072652  0.18714392 -0.02133517 -0.45635813</span></span><br><span class="line"><span class="comment">#   2.23557513  0.60269672  0.57079306 -0.30629098]</span></span><br><span class="line"><span class="comment"># [-0.70702438  0.81761517  1.1078126  -2.25015848  0.32766901 -2.14322612</span></span><br><span class="line"><span class="comment">#  -0.18305529 -0.90640026  0.30361236  0.15709559]</span></span><br><span class="line"><span class="comment"># [ 0.67733948 -0.34158491  0.96708608 -2.06301456  0.30633383 -2.59958425</span></span><br><span class="line"><span class="comment">#   2.05251984 -0.30370355  0.87440541 -0.1491954 ]</span></span><br><span class="line"><span class="comment"># [0.82300637        nan 0.98340535        nan 0.55347433        nan</span></span><br><span class="line"><span class="comment">#  1.4326618         nan 0.93509647        nan]</span></span><br><span class="line"><span class="comment"># [ 1.38436386  0.81761517  1.1078126   0.18714392  0.32766901 -0.45635813</span></span><br><span class="line"><span class="comment">#   2.23557513  0.60269672  0.57079306  0.15709559]</span></span><br></pre></td></tr></table></figure>

<p>虽然并不常见，但有些ufunc的确可以返回多个数组。modf就是一个例子，它是Python内置函数divmod的矢量化版本，它会返回浮点数数组的小数和整数部分：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">arr1 = np.random.randn(<span class="number">10</span>) * <span class="number">10</span></span><br><span class="line">arr_float, arr_int = np.modf(arr1)</span><br><span class="line"><span class="built_in">print</span>(arr_int)</span><br><span class="line"><span class="built_in">print</span>(arr_float)</span><br><span class="line"><span class="comment"># [  1.  -1.  -3.  17.  -9.   2.  -5.   1. -22.  -1.]</span></span><br><span class="line"><span class="comment"># [ 0.47596625 -0.74938756 -0.06916514  0.11201267 -0.19124248  0.72119225</span></span><br><span class="line"><span class="comment">#   -0.2189372   0.60465544 -0.75157779 -0.83174716]</span></span><br></pre></td></tr></table></figure>

<p>常用一元二元ufunc如下表：</p>
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>abs&#x2F;fabs</td>
<td>计算整数、浮点数、复数的绝对值。对于非复数值可使用更快的fabs</td>
</tr>
<tr>
<td>sqrt</td>
<td>计算各元素的平方根</td>
</tr>
<tr>
<td>square</td>
<td>计算各元素的平方</td>
</tr>
<tr>
<td>exp</td>
<td>计算各元素的指数e^x</td>
</tr>
<tr>
<td>log&#x2F;log10&#x2F;log2&#x2F;log1p<code>(log(1+x))</code></td>
<td>对数函数</td>
</tr>
<tr>
<td>sign</td>
<td>符号函数（1：正数；0：零；-1：负数）</td>
</tr>
<tr>
<td>cell</td>
<td>计算各元素大于等于该元素最小整数（向上取整）</td>
</tr>
<tr>
<td>floor</td>
<td>计算各元素小于等于该元素最大整数（向下取整）</td>
</tr>
<tr>
<td>rint</td>
<td>将各元素四舍五入到最接近的整数，保留dtype</td>
</tr>
<tr>
<td>modf</td>
<td>将各元素整数和小数部分以两个独立数组形式返回</td>
</tr>
<tr>
<td>isnan</td>
<td>返回一个表示“哪些值是nan的”布尔型数组</td>
</tr>
<tr>
<td>isfinite&#x2F;isinf</td>
<td>返回一个哪些元素是有穷的&#x2F;无穷的布尔型数组</td>
</tr>
<tr>
<td>cos&#x2F;cosh&#x2F;sin&#x2F;sinh&#x2F;tan&#x2F;tanh</td>
<td>普通型和双曲型三角函数</td>
</tr>
<tr>
<td>arcsin&#x2F;arccos&#x2F;arctan&#x2F;arcsinh&#x2F;arccosh&#x2F;arctanh</td>
<td>反三角函数</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>add</td>
<td>将数组中对应的元素相加</td>
</tr>
<tr>
<td>subtract</td>
<td>冲第一个数组中减去第二个数组中的元素</td>
</tr>
<tr>
<td>multiply</td>
<td>数组元素相乘</td>
</tr>
<tr>
<td>divide&#x2F;floor_divide</td>
<td>除法&#x2F;除法取整</td>
</tr>
<tr>
<td>power</td>
<td>对第一个数组的A元素，根据第二个数组的B元素，计算A^B</td>
</tr>
<tr>
<td>maximum&#x2F;fmax</td>
<td>元素级的最大值计算，fmax将忽略NaN</td>
</tr>
<tr>
<td>minimum&#x2F;fmin</td>
<td>元素级的最小值计算，fmin将忽略NaN</td>
</tr>
<tr>
<td>mod</td>
<td>元素级的球模计算</td>
</tr>
<tr>
<td>copysign</td>
<td>将第二个数组中的值的符号复制给第一个数组中的值</td>
</tr>
</tbody></table>
<h2 id="利用数组处理数据"><a href="#利用数组处理数据" class="headerlink" title="利用数组处理数据"></a>利用数组处理数据</h2><p>NumPy数组使你可以将许多种数据处理任务表述为简洁的数组表达式（否则需要编写循环）。用数组表达式代替循环的做法，通常被称为矢量化。一般来说，矢量化数组运算要比等价的纯Python方式快上一两个数量级（甚至更多），尤其是各种数值计算。</p>
<h3 id="将条件逻辑表示为数组运算"><a href="#将条件逻辑表示为数组运算" class="headerlink" title="将条件逻辑表示为数组运算"></a>将条件逻辑表示为数组运算</h3><p><code>numpy.where</code>函数是三元表达式<code>x if condition else y</code>的矢量化版本。</p>
<p>假设想要根据cond中的值选取xarr和yarr的值：当cond中的值为True时，选取xarr的值，否则从yarr中选取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">xarr = np.array([<span class="number">1.1</span>, <span class="number">1.2</span>, <span class="number">1.3</span>, <span class="number">1.4</span>, <span class="number">1.5</span>])</span><br><span class="line">yarr = np.array([<span class="number">2.1</span>, <span class="number">2.2</span>, <span class="number">2.3</span>, <span class="number">2.4</span>, <span class="number">2.5</span>])</span><br><span class="line">cond = np.array([<span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">False</span>])</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    where(condition, [x, y], /):</span></span><br><span class="line"><span class="string">        根据condition返回,x/y的元素</span></span><br><span class="line"><span class="string">    当仅提供 &#x27;condition&#x27; 时，此函数是 &#x27;&#x27;np.asarray（condition）.nonzero（）&#x27;&#x27; 的简写。</span></span><br><span class="line"><span class="string">    直接使用“nonzero”应该是首选，因为它对于子类的行为是正确的。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">zarr = np.where(cond, xarr, yarr)</span><br><span class="line"><span class="built_in">print</span>(zarr)</span><br></pre></td></tr></table></figure>

<p><code>np.where</code>第二个和第三个参数不必是数组，它们都可以是标量值。在数据分析工作中，<code>where</code>通常用于根据另一个数组而产生一个新的数组。假设有一个由随机数据组成的矩阵，将所有正值替换为<code>1</code>将所有负值替换为<code>－1</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">arr = np.random.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line"><span class="built_in">print</span>(np.where(arr &gt; <span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line"><span class="comment"># [[ 1.07412227 -0.89988959 -1.42862674 -0.48433742]</span></span><br><span class="line"><span class="comment">#  [ 0.85388065 -1.15168922 -2.2994721   1.17801869]</span></span><br><span class="line"><span class="comment"># [-0.02056903  0.01658992 -0.66251106  0.73234217]</span></span><br><span class="line"><span class="comment"># [-0.68449445 -1.40815878  1.20124381 -0.63892402]]</span></span><br><span class="line"><span class="comment"># [[ 1 -1 -1 -1]</span></span><br><span class="line"><span class="comment">#  [ 1 -1 -1  1]</span></span><br><span class="line"><span class="comment"># [-1  1 -1  1]</span></span><br><span class="line"><span class="comment"># [-1 -1  1 -1]]</span></span><br></pre></td></tr></table></figure>

<p>使用<code>np.where</code>，可以将标量和数组结合起来。例如，我可用常数<code>1</code>替换<code>arr</code>中所有正的值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.where(arr &gt; <span class="number">0</span>, <span class="number">1</span>, arr))</span><br><span class="line"><span class="comment"># [[-0.66384462  1.          1.          1.        ]</span></span><br><span class="line"><span class="comment">#  [ 1.         -0.71134976  1.         -0.44296096]</span></span><br><span class="line"><span class="comment"># [ 1.         -0.98135017 -0.51546953 -0.47090388]</span></span><br><span class="line"><span class="comment"># [ 1.          1.          1.         -0.01663538]]</span></span><br></pre></td></tr></table></figure>

<p>传递给where的数组大小可以不相等，甚至可以是标量值。</p>
<h3 id="数学和统计方法"><a href="#数学和统计方法" class="headerlink" title="数学和统计方法"></a>数学和统计方法</h3><p>可以通过数组上的一组数学函数对整个数组或某个轴向的数据进行统计计算。<code>sum</code>、<code>mean</code>以及标准差<code>std</code>等聚合计算（<code>aggregation，通常叫做约简（reduction）</code>）既可以当做数组的实例方法调用，也可以当做顶级<code>NumPy</code>函数使用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">arr = np.random.randn(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line"><span class="comment"># 计算指定轴向的算数平均值</span></span><br><span class="line">x = arr.mean()</span><br><span class="line">y = np.mean(arr)</span><br><span class="line"><span class="built_in">print</span>(x, <span class="string">&#x27;\n&#x27;</span>, y)</span><br><span class="line"><span class="built_in">print</span>(arr.<span class="built_in">sum</span>())</span><br></pre></td></tr></table></figure>

<p><code>mean</code>和<code>sum</code>这类的函数可以接受一个<code>axis</code>选项参数，用于计算该轴向上的统计值，最终结果是一个少一维的数组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>, arr.mean(axis=<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>, arr.<span class="built_in">sum</span>(axis=<span class="number">0</span>))</span><br></pre></td></tr></table></figure>

<p>这里，<code>arr.mean(axis=1)</code>是“计算行的平均值”，<code>arr.sum(axis=0)</code>是“计算每列的和”。</p>
<p>其他如<code>cumsum</code>和<code>cumprod</code>之类的方法则不聚合，而是产生一个由中间结果组成的数组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">arr = np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line">arr_sum = arr.cumsum()</span><br><span class="line"><span class="built_in">print</span>(arr_sum)</span><br><span class="line">arr1 = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(arr1)</span><br><span class="line"><span class="comment"># 返回数组元素在给定轴上的累积乘积。</span></span><br><span class="line"><span class="built_in">print</span>(arr1.cumprod(axis=<span class="number">0</span>))</span><br><span class="line"><span class="comment"># 若未指定轴向则会被压缩为一个一维数组</span></span><br><span class="line"><span class="built_in">print</span>(arr1.cumprod())	</span><br><span class="line"><span class="comment"># [0 1 2 3 4 5 6 7 8 9]</span></span><br><span class="line"><span class="comment"># [ 0  1  3  6 10 15 21 28 36 45]</span></span><br><span class="line"><span class="comment"># [[0 1 2]</span></span><br><span class="line"><span class="comment">#  [3 4 5]</span></span><br><span class="line"><span class="comment"># [6 7 8]]</span></span><br><span class="line"><span class="comment"># [[ 0  1  2]</span></span><br><span class="line"><span class="comment">#  [ 0  4 10]</span></span><br><span class="line"><span class="comment"># [ 0 28 80]]</span></span><br><span class="line"><span class="comment"># [0 0 0 0 0 0 0 0 0]</span></span><br></pre></td></tr></table></figure>

<p>下表为基本数组统计方法：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>sum</td>
<td>对数组中全部或指定轴向的元素求和。零长度的数组和为0</td>
</tr>
<tr>
<td>mean</td>
<td>对数组中全部或指定轴向的元素求算术平均值。零长度的数组的mean为NaN</td>
</tr>
<tr>
<td>std&#x2F;var</td>
<td>计算数组的标准差和方差，自由度可调（默认为n）</td>
</tr>
<tr>
<td>min&#x2F;max</td>
<td>计算数组的最小值&#x2F;最大值</td>
</tr>
<tr>
<td>argmin&#x2F;argmax</td>
<td>返回数组最小值&#x2F;最大值的索引</td>
</tr>
<tr>
<td>cumsum</td>
<td>返回所有元素的累计和</td>
</tr>
<tr>
<td>sumprod</td>
<td>返回所有元素的累计积</td>
</tr>
</tbody></table>
<h3 id="用于布尔型数组的方法"><a href="#用于布尔型数组的方法" class="headerlink" title="用于布尔型数组的方法"></a>用于布尔型数组的方法</h3><p>在上面这些方法中，布尔值会被强制转换为<code>1（True）</code>和<code>0（False）</code>。因此，<code>sum</code>经常被用来对布尔型数组中的<code>True</code>值计数，另外还有两个方法any和all，它们对布尔型数组非常有用。	<code>any</code>用于测试数组中是否存在一个或多个<code>True</code>，而<code>all</code>则检查数组中所有值是否都是<code>True</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">arr = np.random.randn(<span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>((arr &gt; <span class="number">0</span>).<span class="built_in">sum</span>())</span><br><span class="line">arr_bool = np.array([<span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">False</span>])</span><br><span class="line"><span class="built_in">print</span>(arr_bool.<span class="built_in">all</span>())</span><br><span class="line"><span class="built_in">print</span>(arr_bool.<span class="built_in">any</span>())</span><br><span class="line"><span class="comment"># 57</span></span><br><span class="line"><span class="comment"># False</span></span><br><span class="line"><span class="comment"># True</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>这两个方法也能用于非布尔型数组，所有非0元素将会被当做True。</p>
</blockquote>
<h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><p>和<code>Python</code>内置的列表类型一样，<code>NumPy</code>数组也可以通过<code>sort</code>方法就地排序：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">arr = np.random.randn(<span class="number">6</span>)</span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line">arr.sort()</span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line"><span class="comment"># [0.70480627 0.4956195  0.2680823  0.31612777 0.89898296 0.53086524]</span></span><br><span class="line"><span class="comment"># [0.2680823  0.31612777 0.4956195  0.53086524 0.70480627 0.89898296]</span></span><br></pre></td></tr></table></figure>

<p>多维数组可以在任何一个轴向上进行排序，只需将轴编号传给<code>sort</code>即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">arr1 = np.random.randn(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(arr1)</span><br><span class="line">arr1.sort(axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(arr1)</span><br><span class="line">arr1.sort(axis=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(arr1)</span><br><span class="line"><span class="comment"># [[-0.57557726  0.3814267   0.91631978]</span></span><br><span class="line"><span class="comment">#  [ 0.37041056 -0.11733325 -0.82948637]</span></span><br><span class="line"><span class="comment">#  [ 0.78834361  0.46324695  0.19573421]]</span></span><br><span class="line"><span class="comment"># [[-0.57557726  0.3814267   0.91631978]</span></span><br><span class="line"><span class="comment">#  [-0.82948637 -0.11733325  0.37041056]</span></span><br><span class="line"><span class="comment"># [ 0.19573421  0.46324695  0.78834361]]</span></span><br><span class="line"><span class="comment"># [[-0.82948637 -0.11733325  0.37041056]</span></span><br><span class="line"><span class="comment">#  [-0.57557726  0.3814267   0.78834361]</span></span><br><span class="line"><span class="comment"># [ 0.19573421  0.46324695  0.91631978]]</span></span><br></pre></td></tr></table></figure>

<p>顶级方法<code>np.sort</code>返回的是数组的已排序副本，而就地排序则会修改数组本身。计算数组分位数最简单的办法是对其进行排序，然后选取特定位置的值。</p>
<h3 id="唯一化及其它的集合逻辑"><a href="#唯一化及其它的集合逻辑" class="headerlink" title="唯一化及其它的集合逻辑"></a>唯一化及其它的集合逻辑</h3><p><code>NumPy</code>提供了一些针对一维<code>ndarray</code>的基本集合运算。最常用的可能要数<code>np.unique</code>了，它用于找出数组中的唯一值并返回已排序的结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">names = np.array([<span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>, <span class="string">&#x27;Will&#x27;</span>, <span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Will&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>])</span><br><span class="line">name = np.unique(names)</span><br><span class="line"><span class="built_in">print</span>(name, <span class="string">&#x27; dtype=&#x27;</span>, name.dtype)</span><br></pre></td></tr></table></figure>

<p>另一个函数<code>np.in1d</code>用于测试一个数组中的值在另一个数组中的成员资格，返回一个布尔型数组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">values = np.array([<span class="number">6</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">is_exist = np.in1d(values, [<span class="number">1</span>,<span class="number">4</span>,<span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(is_exist)</span><br></pre></td></tr></table></figure>

<p><code>NumPy</code>中的集合函数请参见下表</p>
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>unique(x)</td>
<td>计算x中唯一的元素，并返回有序结果</td>
</tr>
<tr>
<td>intersect1d(x,y)</td>
<td>计算x和y的公共元素，并返回有序结果</td>
</tr>
<tr>
<td>union1d(x,y)</td>
<td>计算x和y的并集，并返回有序结果</td>
</tr>
<tr>
<td>in1d(x,y)</td>
<td>计算得到x中的元素是否包含在y中的布尔型数组</td>
</tr>
<tr>
<td>setdiff1d(x,y)</td>
<td>集合的差，即元素在x中但不在y中</td>
</tr>
<tr>
<td>setxor1d(x,y)</td>
<td>集合的对称差，即存在于一个数组中但不同时出现在两个数组中</td>
</tr>
</tbody></table>

        
        
          <blockquote id="copyright">
              <p>Original link: <a href="http://example.com/index.html">http://example.com/index.html</a></p>
              <p>Copyright Notice: 转载请注明出处.</p>
          </blockquote>
        
      
    </div>
    <footer class="article-footer">
      
        <div class="article-tag-wrap">
          

          
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NumPy/" rel="tag">NumPy</a></li></ul>

          
    <div class="social-share">
      <span>Share:</span>
    </div>



        </div>
      
      
      
    </footer>
  </div>
</article>


  <article id="post-hexo博客使用" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/06/30/hexo%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8/">hexo博客使用</a>
    </h1>
  


      </header>
    
    <div class="article-meta">
      
      <span class="article-date">
  <i class="fa fa-date"></i>
  <time class="dt-published" datetime="2024-06-30T15:04:06.000Z" itemprop="datePublished">2024年06月30日</time>
</span>
      
      
      
<a href="/2024/06/30/hexo%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8/#comments" class="article-comment-link">
  
  <i class="fa fa-commt"></i>
  Guestbook
</a>


    </div>
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="创建新文章"><a href="#创建新文章" class="headerlink" title="创建新文章"></a>创建新文章</h3><p>中端进入<code>D:\hexo\source\_posts（项目存放目录）</code>目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;文章名&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean</span><br><span class="line">$ hexo g</span><br><span class="line">$ hexo d</span><br></pre></td></tr></table></figure>


        
        
          <blockquote id="copyright">
              <p>Original link: <a href="http://example.com/index.html">http://example.com/index.html</a></p>
              <p>Copyright Notice: 转载请注明出处.</p>
          </blockquote>
        
      
    </div>
    <footer class="article-footer">
      
        <div class="article-tag-wrap">
          

          
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8/" rel="tag">博客使用</a></li></ul>

          
    <div class="social-share">
      <span>Share:</span>
    </div>



        </div>
      
      
      
    </footer>
  </div>
</article>


  <article id="post-随心记" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/06/27/%E9%9A%8F%E5%BF%83%E8%AE%B0/">随心记</a>
    </h1>
  


      </header>
    
    <div class="article-meta">
      
      <span class="article-date">
  <i class="fa fa-date"></i>
  <time class="dt-published" datetime="2024-06-27T08:13:52.000Z" itemprop="datePublished">2024年06月27日</time>
</span>
      
      
      
<a href="/2024/06/27/%E9%9A%8F%E5%BF%83%E8%AE%B0/#comments" class="article-comment-link">
  
  <i class="fa fa-commt"></i>
  Guestbook
</a>


    </div>
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h1><h2 id="找文献"><a href="#找文献" class="headerlink" title="找文献"></a>找文献</h2><p><a href="www.webofscience.com">web of science</a> </p>
<p><a target="_blank" rel="noopener" href="https://scholar.google.com.hk/?hl=zh-CN">谷歌学术</a></p>
<p>知网</p>
<p>万方维普</p>
<h2 id="读文献工具"><a href="#读文献工具" class="headerlink" title="读文献工具"></a>读文献工具</h2><p><strong>zotero</strong></p>
<p><strong>endNote</strong></p>
<h2 id="读文献"><a href="#读文献" class="headerlink" title="读文献"></a>读文献</h2><h3 id="读什么"><a href="#读什么" class="headerlink" title="读什么"></a>读什么</h3><ol>
<li><p>研究问题是什么？</p>
</li>
<li><p>研究方法和结论是什么？</p>
<p>是用什么方法展开研究的。这种研究方法得到了哪些具有创新性的研究结论。这些方法和结论对于自己的研究有哪些启示和可借鉴的地方<br>①他的研究方法是否可以迁移到我的研究中<br>②他的研究结论是否有局限性<br>③对他的局限性是否可以拓展</p>
</li>
<li><p>对我的研究有什么用？</p>
</li>
</ol>
<h3 id="怎么读"><a href="#怎么读" class="headerlink" title="怎么读"></a>怎么读</h3><p><strong>读一篇文献的基本步骤：</strong></p>
<p><strong>粗读</strong>：浏览<strong>摘要</strong>和<strong>标题</strong>（了解研究问题和得出哪儿些结论）</p>
<p><strong>泛读：</strong></p>
<ol>
<li><p>重点关注<strong>引言后半段</strong>（细化研究问题）文献综述部分这个阶段可以略过</p>
</li>
<li><p>文章核心内容重点关注<strong>研究方法</strong>和<strong>研究过程。</strong>通过图、表来预了解文章的研究过程和方法；通过文章研究结论来看这篇文章是否能够为自己的研究有所帮助和借鉴，以及有什么创新性和不足；</p>
</li>
</ol>
<p><strong>精读：</strong>（通过泛读来判断是否这篇文章需要精读）</p>
<p>更深入的了解文献综述、研究方法、研究过程。文献综述：可以帮助我们对文章所涉及的核心概念以及领域中历史脉络有更清楚的了解；研究过程研究方法：更好的了解文章是通过什么流程来实现的，碰到不大懂的研究方法过程可以阅读相关文献来解疑。</p>
<p><strong>最后：</strong>总结文章 将旧领域迁移到新领域</p>
<h1 id="如何学习新知识"><a href="#如何学习新知识" class="headerlink" title="如何学习新知识"></a>如何学习新知识</h1><ol>
<li>了解新知识可以做什么</li>
<li>初步学习新知识，掌握新知识基本使用方法</li>
<li>应用到项目进一步掌握新知识</li>
</ol>

        
        
          <blockquote id="copyright">
              <p>Original link: <a href="http://example.com/index.html">http://example.com/index.html</a></p>
              <p>Copyright Notice: 转载请注明出处.</p>
          </blockquote>
        
      
    </div>
    <footer class="article-footer">
      
        <div class="article-tag-wrap">
          

          
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%97%A5%E5%B8%B8%E7%A7%AF%E7%B4%AF/" rel="tag">日常积累</a></li></ul>

          
    <div class="social-share">
      <span>Share:</span>
    </div>



        </div>
      
      
      
    </footer>
  </div>
</article>


  <article id="post-深度学习1-0" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/05/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01-0/">深度学习1.0</a>
    </h1>
  


      </header>
    
    <div class="article-meta">
      
      <span class="article-date">
  <i class="fa fa-date"></i>
  <time class="dt-published" datetime="2024-05-21T06:40:36.000Z" itemprop="datePublished">2024年05月21日</time>
</span>
      
      
      
<a href="/2024/05/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01-0/#comments" class="article-comment-link">
  
  <i class="fa fa-commt"></i>
  Guestbook
</a>


    </div>
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="卷积神经网络（CNN）"><a href="#卷积神经网络（CNN）" class="headerlink" title="卷积神经网络（CNN）"></a>卷积神经网络（CNN）</h1>
        
        
          <blockquote id="copyright">
              <p>Original link: <a href="http://example.com/index.html">http://example.com/index.html</a></p>
              <p>Copyright Notice: 转载请注明出处.</p>
          </blockquote>
        
      
    </div>
    <footer class="article-footer">
      
        <div class="article-tag-wrap">
          

          
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li></ul>

          
    <div class="social-share">
      <span>Share:</span>
    </div>



        </div>
      
      
      
    </footer>
  </div>
</article>


  <article id="post-python学习" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/05/20/python%E5%AD%A6%E4%B9%A0/">python学习</a>
    </h1>
  


      </header>
    
    <div class="article-meta">
      
      <span class="article-date">
  <i class="fa fa-date"></i>
  <time class="dt-published" datetime="2024-05-20T11:25:37.000Z" itemprop="datePublished">2024年05月20日</time>
</span>
      
      
      
<a href="/2024/05/20/python%E5%AD%A6%E4%B9%A0/#comments" class="article-comment-link">
  
  <i class="fa fa-commt"></i>
  Guestbook
</a>


    </div>
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h1><h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><p><strong>int</strong> </p>
<p><strong>float</strong></p>
<p><strong>string</strong></p>
<p><strong>bool</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1</span></span><br><span class="line">b = <span class="number">1.1</span></span><br><span class="line">c = <span class="string">&#x27;python&#x27;</span></span><br><span class="line">c = <span class="string">&quot;python&quot;</span></span><br><span class="line">d = true</span><br><span class="line">d = <span class="number">0</span></span><br></pre></td></tr></table></figure>

<h3 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h3><table>
<thead>
<tr>
<th>运算符</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>[]</code> <code>[:]</code></td>
<td>下标，切片</td>
</tr>
<tr>
<td><code>**</code></td>
<td>指数</td>
</tr>
<tr>
<td><code>~</code> <code>+</code> <code>-</code></td>
<td>按位取反, 正负号</td>
</tr>
<tr>
<td><code>*</code> <code>/</code> <code>%</code> <code>//</code></td>
<td>乘，除，模，整除</td>
</tr>
<tr>
<td><code>+</code> <code>-</code></td>
<td>加，减</td>
</tr>
<tr>
<td><code>&gt;&gt;</code> <code>&lt;&lt;</code></td>
<td>右移，左移</td>
</tr>
<tr>
<td><code>&amp;</code></td>
<td>按位与</td>
</tr>
<tr>
<td><code>^</code> &#96;</td>
<td>&#96;</td>
</tr>
<tr>
<td><code>&lt;=</code> <code>&lt;</code> <code>&gt;</code> <code>&gt;=</code></td>
<td>小于等于，小于，大于，大于等于</td>
</tr>
<tr>
<td><code>==</code> <code>!=</code></td>
<td>等于，不等于</td>
</tr>
<tr>
<td><code>is</code> <code>is not</code></td>
<td>身份运算符</td>
</tr>
<tr>
<td><code>in</code> <code>not in</code></td>
<td>成员运算符</td>
</tr>
<tr>
<td><code>not</code> <code>or</code> <code>and</code></td>
<td>逻辑运算符</td>
</tr>
<tr>
<td><code>=</code> <code>+=</code> <code>-=</code> <code>*=</code> <code>/=</code> <code>%=</code> <code>//=</code> <code>**=</code> <code>&amp;=</code> &#96;</td>
<td>&#x3D;<code> </code>^&#x3D;<code> </code>&gt;&gt;&#x3D;<code> </code>&lt;&lt;&#x3D;&#96;</td>
</tr>
</tbody></table>
<h3 id="变量命名"><a href="#变量命名" class="headerlink" title="变量命名"></a>变量命名</h3><p>对于每个变量我们需要给它取一个名字，就如同我们每个人都有属于自己的响亮的名字一样。在Python中，变量命名需要遵循以下这些必须遵守硬性规则和强烈建议遵守的非硬性规则。</p>
<ul>
<li>硬性规则：<ul>
<li>变量名由字母（广义的Unicode字符，不包括特殊字符）、数字和下划线构成，数字不能开头。</li>
<li>大小写敏感（大写的<code>a</code>和小写的<code>A</code>是两个不同的变量）。</li>
<li>不要跟关键字（有特殊含义的单词，后面会讲到）和系统保留字（如函数、模块等的名字）冲突。</li>
</ul>
</li>
<li>PEP 8要求：<ul>
<li>用小写字母拼写，多个单词用下划线连接。</li>
<li>受保护的实例属性用单个下划线开头（后面会讲到）。</li>
<li>私有的实例属性用两个下划线开头（后面会讲到）。</li>
</ul>
</li>
</ul>
<p>当然，作为一个专业的程序员，给变量（事实上应该是所有的标识符）命名时做到见名知意也是非常重要的。</p>
<h3 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h3><ul>
<li><code>int()</code> 将一个浮点型或字符串转换为整型</li>
<li><code>float()</code> 将一个字符串转换为浮点数</li>
<li><code>str()</code> 将指定对象转换为字符串</li>
<li><code>chr()</code> 将整数转换成该编码对应的字符串（一个字符）</li>
<li><code>ord()</code> 将字符串（一个字符）转换成对应的编码（整数）</li>
</ul>
<h3 id="分支结构"><a href="#分支结构" class="headerlink" title="分支结构"></a>分支结构</h3><p>构造分支结构的关键字为<code>if</code> <code>elif</code> <code>else:</code> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入被加数：&quot;</span>))</span><br><span class="line">b = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入加数：&quot;</span>))</span><br><span class="line">c = a + b</span><br><span class="line"><span class="keyword">if</span> c &gt; <span class="number">10</span>:</span><br><span class="line">    <span class="built_in">print</span>(c)</span><br><span class="line"><span class="keyword">elif</span> c &gt; <span class="number">5</span>:</span><br><span class="line">    <span class="built_in">print</span>(c+<span class="number">50</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(c+<span class="number">100</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 格式为 </span></span><br><span class="line">	<span class="keyword">if</span> 条件 :</span><br><span class="line">		处理语句</span><br><span class="line">	<span class="keyword">elif</span> 条件 :</span><br><span class="line">		处理语句</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		处理语句</span><br></pre></td></tr></table></figure>

<h3 id="循环结构"><a href="#循环结构" class="headerlink" title="循环结构"></a>循环结构</h3><ul>
<li>使用<code>for in</code>关键字构造</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">101</span>):</span><br><span class="line">    <span class="built_in">sum</span> += i</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;1到100自加等于%d&#x27;</span> %<span class="built_in">sum</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#格式为</span></span><br><span class="line">	<span class="keyword">for</span> 循环变量 <span class="built_in">range</span>():</span><br><span class="line">		循环语句</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>range</code>的用法非常灵活，下面给出了一个例子：</p>
<ul>
<li><code>range(101)</code>：可以用来产生0到100范围的整数，需要注意的是取不到101。</li>
<li><code>range(1, 101)</code>：可以用来产生1到100范围的整数，相当于前面是闭区间后面是开区间。</li>
<li><code>range(1, 101, 2)</code>：可以用来产生1到100的奇数，其中2是步长，即每次数值递增的值。</li>
<li><code>range(100, 0, -2)</code>：可以用来产生100到1的偶数，其中-2是步长，即每次数字递减的值。</li>
</ul>
</blockquote>
<ul>
<li>使用<code>while</code>关键字构造</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> i &lt;= <span class="number">100</span>:</span><br><span class="line">    <span class="built_in">sum</span> += i</span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sum</span>)</span><br></pre></td></tr></table></figure>



<h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><p>使用def关键字定义格式如下(在pycharm中函数前后空两行否则会出现警告)</p>
<blockquote>
<p>def 函数名(参数):</p>
<p>​	函数体</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">jie_cheng</span>(<span class="params">num</span>):</span><br><span class="line">    result = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,num+<span class="number">1</span>):</span><br><span class="line">        result *= i</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;10的阶乘：%d&#x27;</span> %jie_cheng(<span class="number">10</span>))</span><br></pre></td></tr></table></figure>

<h4 id="函数的参数"><a href="#函数的参数" class="headerlink" title="函数的参数"></a>函数的参数</h4><p>在Python中，函数的参数可以有默认值，也支持使用可变参数，所以Python并不支持函数的重载，因为我们在定义一个函数的时候可以让它有多种不同的使用方式，例如</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a=<span class="number">0</span>, b=<span class="number">0</span>, c=<span class="number">0</span></span>):</span><br><span class="line">    <span class="keyword">return</span> a + b + c</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(add(<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(add(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(add(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure>

<p>为了达到让使用者决定参数个数的目的函数还可以使用可变参数，例如</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; *参数：定义可变参数 &quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">*args</span>):</span><br><span class="line">    sum1 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> arg <span class="keyword">in</span> args:</span><br><span class="line">        sum1 += arg</span><br><span class="line">    <span class="keyword">return</span> sum1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(add(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line"><span class="built_in">print</span>(add(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(add(<span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p>所谓<strong>字符串</strong>，就是由零个或多个字符组成的有限序列，在Python程序中，如果我们把单个或多个字符用单引号或者双引号包围起来，就可以表示一个字符串。可以在字符串中使用<code>\</code>（反斜杠）来表示转义，也就是说<code>\</code>后面的字符不再是它原来的意义，例如：<code>\n</code>不是代表反斜杠和字符n，而是表示换行；而<code>\t</code>也不是代表反斜杠和字符t，而是表示制表符。所以如果想在字符串中表示<code>&#39;</code>要写成<code>\&#39;</code>，同理想表示<code>\</code>要写成<code>\\</code>。如果不希望字符串中的<code>\</code>表示转义，我们可以通过在字符串的最前面加上字母<code>r</code>来加以说明。</p>
<p>Python为字符串类型提供了非常丰富的运算符，我们可以使用<code>+</code>运算符来实现字符串的拼接，可以使用<code>*</code>运算符来重复一个字符串的内容，可以使用<code>in</code>和<code>not in</code>来判断一个字符串是否包含另外一个字符串（成员运算），我们也可以用<code>[]</code>和<code>[:]</code>运算符从字符串取出某个字符或某些字符（切片运算），代码如下所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">s1 = <span class="string">&#x27;hello &#x27;</span> * <span class="number">3</span></span><br><span class="line"><span class="built_in">print</span>(s1) <span class="comment"># hello hello hello </span></span><br><span class="line">s2 = <span class="string">&#x27;world&#x27;</span></span><br><span class="line">s1 += s2</span><br><span class="line"><span class="built_in">print</span>(s1) <span class="comment"># hello hello hello world</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;ll&#x27;</span> <span class="keyword">in</span> s1) <span class="comment"># True</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;good&#x27;</span> <span class="keyword">in</span> s1) <span class="comment"># False</span></span><br><span class="line">str2 = <span class="string">&#x27;abc123456&#x27;</span></span><br><span class="line"><span class="comment"># 从字符串中取出指定位置的字符(下标运算)</span></span><br><span class="line"><span class="built_in">print</span>(str2[<span class="number">2</span>]) <span class="comment"># c</span></span><br><span class="line"><span class="comment"># 字符串切片(从指定的开始索引到指定的结束索引)(左闭右开)</span></span><br><span class="line"><span class="built_in">print</span>(str2[<span class="number">2</span>:<span class="number">5</span>]) <span class="comment"># c12</span></span><br><span class="line"><span class="built_in">print</span>(str2[<span class="number">2</span>:]) <span class="comment"># c123456</span></span><br><span class="line"><span class="built_in">print</span>(str2[<span class="number">2</span>::<span class="number">2</span>]) <span class="comment"># c246</span></span><br><span class="line"><span class="built_in">print</span>(str2[::<span class="number">2</span>]) <span class="comment"># ac246</span></span><br><span class="line"><span class="built_in">print</span>(str2[::-<span class="number">1</span>]) <span class="comment"># 654321cba</span></span><br><span class="line"><span class="built_in">print</span>(str2[-<span class="number">3</span>:-<span class="number">1</span>]) <span class="comment"># 45</span></span><br></pre></td></tr></table></figure>

<p>在Python中，我们还可以通过一系列的方法来完成对字符串的处理，代码如下所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">str1 = <span class="string">&#x27;hello, world!&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过内置函数len计算字符串的长度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(str1)) <span class="comment"># 13</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得字符串首字母大写的拷贝</span></span><br><span class="line"><span class="built_in">print</span>(str1.capitalize()) <span class="comment"># Hello, world!</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得字符串每个单词首字母大写的拷贝</span></span><br><span class="line"><span class="built_in">print</span>(str1.title()) <span class="comment"># Hello, World!</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得字符串变大写后的拷贝</span></span><br><span class="line"><span class="built_in">print</span>(str1.upper()) <span class="comment"># HELLO, WORLD!</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从字符串中查找子串所在位置</span></span><br><span class="line"><span class="built_in">print</span>(str1.find(<span class="string">&#x27;or&#x27;</span>)) <span class="comment"># 8</span></span><br><span class="line"><span class="built_in">print</span>(str1.find(<span class="string">&#x27;shit&#x27;</span>)) <span class="comment"># -1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 与find类似但找不到子串时会引发异常</span></span><br><span class="line"><span class="comment"># print(str1.index(&#x27;or&#x27;))</span></span><br><span class="line"><span class="comment"># print(str1.index(&#x27;shit&#x27;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查字符串是否以指定的字符串开头</span></span><br><span class="line"><span class="built_in">print</span>(str1.startswith(<span class="string">&#x27;He&#x27;</span>)) <span class="comment"># False</span></span><br><span class="line"><span class="built_in">print</span>(str1.startswith(<span class="string">&#x27;hel&#x27;</span>)) <span class="comment"># True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查字符串是否以指定的字符串结尾</span></span><br><span class="line"><span class="built_in">print</span>(str1.endswith(<span class="string">&#x27;!&#x27;</span>)) <span class="comment"># True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将字符串以指定的宽度居中并在两侧填充指定的字符</span></span><br><span class="line"><span class="built_in">print</span>(str1.center(<span class="number">50</span>, <span class="string">&#x27;*&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将字符串以指定的宽度靠右放置左侧填充指定的字符</span></span><br><span class="line"><span class="built_in">print</span>(str1.rjust(<span class="number">50</span>, <span class="string">&#x27; &#x27;</span>))</span><br><span class="line">str2 = <span class="string">&#x27;abc123456&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查字符串是否由数字构成</span></span><br><span class="line"><span class="built_in">print</span>(str2.isdigit())  <span class="comment"># False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查字符串是否以字母构成</span></span><br><span class="line"><span class="built_in">print</span>(str2.isalpha())  <span class="comment"># False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查字符串是否以数字和字母构成</span></span><br><span class="line"><span class="built_in">print</span>(str2.isalnum())  <span class="comment"># True</span></span><br><span class="line">str3 = <span class="string">&#x27;  jackfrued@126.com &#x27;</span></span><br><span class="line"><span class="built_in">print</span>(str3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得字符串修剪左右两侧空格之后的拷贝</span></span><br><span class="line"><span class="built_in">print</span>(str3.strip())</span><br></pre></td></tr></table></figure>

<h4 id="字符串的输出"><a href="#字符串的输出" class="headerlink" title="字符串的输出"></a>字符串的输出</h4><p>Python 3.6以后，格式化字符串还有更为简洁的书写方式，就是在字符串前加上字母<code>f</code>，我们可以使用下面的语法糖来简化上面的代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s3 = <span class="number">10</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;%s&#x27;</span> % s3)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;s3&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(s3))  <span class="comment">#int</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>除了字符串，Python还内置了多种类型的数据结构，如果要在程序中保存和操作数据，绝大多数时候可以利用现有的数据结构来实现，最常用的包括列表、元组、集合和字典。</p>
</blockquote>
<h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><p>我们讲到的字符串类型（<code>str</code>）和之前我们讲到的数值类型（<code>int</code>和<code>float</code>）有一些区别。数值类型是标量类型，也就是说这种类型的对象没有可以访问的内部结构；而字符串类型是一种结构化的、非标量类型，所以才会有一系列的属性和方法。接下来我们要介绍的列表（<code>list</code>），也是一种结构化的、非标量类型，它是值的有序序列，每个值都可以通过索引进行标识，定义列表可以将列表的元素放在<code>[]</code>中，多个元素用<code>,</code>进行分隔，可以使用<code>for</code>循环对列表元素进行遍历，也可以使用<code>[]</code>或<code>[:]</code>运算符取出列表中的一个或多个元素。<code>如果学过Java则可以类比List集合。</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">list1 = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">list2 = [<span class="string">&#x27;hello&#x27;</span>, <span class="string">&#x27;world&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(list1)</span><br><span class="line"><span class="built_in">print</span>(list2 * <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(list1))</span><br><span class="line"><span class="built_in">print</span>(list1[<span class="number">0</span>:<span class="number">3</span>])</span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(list2)):  <span class="comment"># 获取索引</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%d&#x27;</span> % index + <span class="string">&#x27; &#x27;</span> + list2[index])</span><br><span class="line"><span class="keyword">for</span> elem <span class="keyword">in</span> list1:  <span class="comment"># 获取元素</span></span><br><span class="line">    <span class="built_in">print</span>(elem)</span><br><span class="line"><span class="keyword">for</span> index, elem <span class="keyword">in</span> <span class="built_in">enumerate</span>(list2):  <span class="comment"># 获取索引和元素</span></span><br><span class="line">    <span class="built_in">print</span>(index, elem)</span><br><span class="line"></span><br><span class="line">list1.append(<span class="number">200</span>)  <span class="comment"># 列表后加元素</span></span><br><span class="line">list1.extend([<span class="number">1</span>, <span class="number">2</span>])  <span class="comment"># 合并列表</span></span><br><span class="line">list1.insert(<span class="number">0</span>, <span class="number">340</span>)  <span class="comment"># 指定位置加元素</span></span><br><span class="line"><span class="built_in">print</span>(list1)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="number">2</span> <span class="keyword">in</span> list1:</span><br><span class="line">    list1.remove(<span class="number">2</span>)  <span class="comment"># 删除元素</span></span><br><span class="line"><span class="built_in">print</span>(list1)</span><br><span class="line"></span><br><span class="line">list1.pop(-<span class="number">1</span>)  <span class="comment"># 指定位置删除元素</span></span><br><span class="line"><span class="built_in">print</span>(list1)</span><br><span class="line"></span><br><span class="line">list1.reverse()</span><br><span class="line"><span class="built_in">print</span>(list1)</span><br><span class="line"></span><br><span class="line">list1.clear()</span><br><span class="line"><span class="built_in">print</span>(list1)</span><br></pre></td></tr></table></figure>

<h3 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h3><p>Python中的元组与列表类似也是一种容器数据类型，可以用一个变量（对象）来存储多个数据，不同之处在于元组的元素不能修改，在前面的代码中我们已经不止一次使用过元组了。顾名思义，我们把多个元素组合到一起就形成了一个元组，所以它和列表一样可以保存多条数据。下面的代码演示了如何定义和使用元组。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用元组</span></span><br><span class="line">person = (<span class="string">&#x27;程茂强&#x27;</span>, <span class="number">21</span>, <span class="string">&#x27;男&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> elem <span class="keyword">in</span> person:</span><br><span class="line">    <span class="built_in">print</span>(elem)</span><br><span class="line"><span class="built_in">print</span>(person)</span><br><span class="line"><span class="comment"># 元组转化为列表</span></span><br><span class="line">person_list = <span class="built_in">list</span>(person)</span><br><span class="line"><span class="built_in">print</span>(person_list)</span><br><span class="line">person_list[<span class="number">0</span>] = <span class="string">&#x27;程久书&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(person_list)</span><br><span class="line"><span class="comment"># 列表转化为元组</span></span><br><span class="line">person_tuple = <span class="built_in">tuple</span>(person_list)</span><br><span class="line"><span class="built_in">print</span>(person_tuple)</span><br></pre></td></tr></table></figure>

<h3 id="集合（set）"><a href="#集合（set）" class="headerlink" title="集合（set）"></a>集合（set）</h3><p>Python中的集合跟数学上的集合是一致的，不允许有重复元素，而且可以进行交集、并集、差集等运算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建集合的字面量语法</span></span><br><span class="line">set1 = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(set1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Length =&#x27;</span>, <span class="built_in">len</span>(set1))</span><br><span class="line"><span class="comment"># 创建集合的构造器语法(面向对象部分会进行详细讲解)</span></span><br><span class="line">set2 = <span class="built_in">set</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>))</span><br><span class="line">set3 = <span class="built_in">set</span>((<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(set2, set3)</span><br><span class="line"><span class="comment"># 创建集合的推导式语法(推导式也可以用于推导集合)</span></span><br><span class="line">set4 = &#123;num <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">100</span>) <span class="keyword">if</span> num % <span class="number">3</span> == <span class="number">0</span> <span class="keyword">or</span> num % <span class="number">5</span> == <span class="number">0</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(set4)</span><br></pre></td></tr></table></figure>

<p>向集合添加元素和从集合删除元素。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">set1.add(<span class="number">4</span>)</span><br><span class="line">set1.add(<span class="number">5</span>)</span><br><span class="line">set2.update([<span class="number">11</span>, <span class="number">12</span>])</span><br><span class="line">set2.discard(<span class="number">5</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="number">4</span> <span class="keyword">in</span> set2:</span><br><span class="line">    set2.remove(<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(set1, set2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(set3)</span><br><span class="line"><span class="built_in">print</span>(set3.pop())  <span class="comment"># 移除并返回第一个元素</span></span><br><span class="line"><span class="built_in">print</span>(set3)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>pop()此方法可能有bug：文档注释为删除并返回最后一个元素但实际却是删除并返回第一个元素</p>
</blockquote>
<p>集合的成员、交集、并集、差集等运算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 集合的交集、并集、差集、对称差运算</span></span><br><span class="line"><span class="built_in">print</span>(set1 &amp; set2)</span><br><span class="line"><span class="comment"># print(set1.intersection(set2))</span></span><br><span class="line"><span class="built_in">print</span>(set1 | set2)</span><br><span class="line"><span class="comment"># print(set1.union(set2))</span></span><br><span class="line"><span class="built_in">print</span>(set1 - set2)</span><br><span class="line"><span class="comment"># print(set1.difference(set2))</span></span><br><span class="line"><span class="built_in">print</span>(set1 ^ set2)</span><br><span class="line"><span class="comment"># print(set1.symmetric_difference(set2))</span></span><br><span class="line"><span class="comment"># 判断子集和超集</span></span><br><span class="line"><span class="built_in">print</span>(set2 &lt;= set1)</span><br><span class="line"><span class="comment"># print(set2.issubset(set1))</span></span><br><span class="line"><span class="built_in">print</span>(set3 &lt;= set1)</span><br><span class="line"><span class="comment"># print(set3.issubset(set1))</span></span><br><span class="line"><span class="built_in">print</span>(set1 &gt;= set2)</span><br><span class="line"><span class="comment"># print(set1.issuperset(set2))</span></span><br><span class="line"><span class="built_in">print</span>(set1 &gt;= set3)</span><br><span class="line"><span class="comment"># print(set1.issuperset(set3))</span></span><br></pre></td></tr></table></figure>

<h3 id="字典-dict"><a href="#字典-dict" class="headerlink" title="字典(dict)"></a>字典(dict)</h3><p>Python内置了字典：dict的支持，dict全称dictionary，在其他语言中也称为map，使用键-值（key-value）存储，具有极快的查找速度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">person = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;久书&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">21</span>, <span class="string">&#x27;sex&#x27;</span>: <span class="string">&#x27;男&#x27;</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(person[<span class="string">&#x27;name&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(person[<span class="string">&#x27;age&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(person[<span class="string">&#x27;sex&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过get(key)获取value</span></span><br><span class="line"><span class="built_in">print</span>(person.get(<span class="string">&#x27;name&#x27;</span>))</span><br><span class="line"><span class="comment"># 如果key不存在返回设定的值</span></span><br><span class="line"><span class="built_in">print</span>(person.get(<span class="string">&#x27;score&#x27;</span>, <span class="number">0</span>))</span><br><span class="line"><span class="comment"># 通过key添加value</span></span><br><span class="line">person[<span class="string">&#x27;score&#x27;</span>] = <span class="number">100</span></span><br><span class="line"><span class="built_in">print</span>(person.get(<span class="string">&#x27;score&#x27;</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;age&#x27;</span> <span class="keyword">in</span> person:</span><br><span class="line">    <span class="keyword">if</span> person[<span class="string">&#x27;age&#x27;</span>] &gt; <span class="number">7</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;要努力学习哦&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;快乐的玩耍吧&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;年龄查找失败&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(person)</span><br><span class="line"><span class="comment"># 查找后会删除</span></span><br><span class="line"><span class="built_in">print</span>(person.pop(<span class="string">&#x27;sex&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(person)</span><br></pre></td></tr></table></figure>

<p>dict内部存放的顺序和key放入的顺序是没有关系的。</p>
<p>和list比较，dict有以下几个特点：</p>
<ol>
<li>查找和插入的速度极快，不会随着key的增加而变慢；</li>
<li>需要占用大量的内存，内存浪费多。</li>
</ol>
<p>而list相反：</p>
<ol>
<li>查找和插入的时间随着元素的增加而增加；</li>
<li>占用空间小，浪费内存很少。</li>
</ol>
<p>所以，dict是用空间来换取时间的一种方法。</p>
<p>dict可以用在需要高速查找的很多地方，在Python代码中几乎无处不在，正确使用dict非常重要，需要牢记的第一条就是dict的key必须是<strong>不可变对象</strong>。</p>
<p>这是因为dict根据key来计算value的存储位置，如果每次计算相同的key得出的结果不同，那dict内部就完全混乱了。这个通过key计算位置的算法称为哈希算法（Hash）。</p>
<p>要保证hash的正确性，作为key的对象就不能变。在Python中，字符串、整数等都是不可变的，因此，可以放心地作为key。而list是可变的，就不能作为key。</p>
<h3 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h3><p>使用<code>class</code>关键字创建类，使用<code>def</code> 关键字创建方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构造器</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, age</span>):</span><br><span class="line">        <span class="variable language_">self</span>.name = name</span><br><span class="line">        <span class="variable language_">self</span>.age = age</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">study</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.age &lt; <span class="number">5</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;开心的玩吧&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;快去学习吧&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sleep</span>(<span class="params">self, age</span>):</span><br><span class="line">        <span class="keyword">if</span> age &lt; <span class="variable language_">self</span>.age:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;你应该睡午觉&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;你应该学习&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cmq = Student(<span class="string">&#x27;程茂强&#x27;</span>, <span class="number">11</span>)</span><br><span class="line">cmq.study()</span><br><span class="line">cmq.sleep(<span class="number">10</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在Python中，属性和方法的访问权限只有两种，也就是公开的和私有的，如果希望属性是私有的，在给属性命名时可以用两个下划线作为开头</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Teacher</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, course</span>):</span><br><span class="line">        <span class="variable language_">self</span>.__course = course</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">teach</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;老师教的是&#x27;</span> + <span class="variable language_">self</span>.__course)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_course</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.__course</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">teacher = Teacher(<span class="string">&#x27;python&#x27;</span>)</span><br><span class="line">teacher.teach()</span><br><span class="line"><span class="built_in">print</span>(teacher.get_course())</span><br></pre></td></tr></table></figure>

<h4 id="property装饰器"><a href="#property装饰器" class="headerlink" title="@property装饰器"></a>@property装饰器</h4><p>之前我们讨论过Python中属性和方法访问权限的问题，虽然我们不建议将属性设置为私有的，但是如果直接将属性暴露给外界也是有问题的，比如我们没有办法检查赋给属性的值是否有效。我们之前的建议是将属性命名以单下划线开头，通过这种方式来暗示属性是受保护的，不建议外界直接访问，那么如果想访问属性可以通过属性的getter（访问器）和setter（修改器）方法进行对应的操作。如果要做到这点，就可以考虑使用@property包装器来包装getter和setter方法，使得对属性的访问既安全又方便，代码如下所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, age</span>):</span><br><span class="line">        <span class="variable language_">self</span>._name = name</span><br><span class="line">        <span class="variable language_">self</span>._age = age</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property  </span><span class="comment"># getter方法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">name</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._name</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">age</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._age</span><br><span class="line"></span><br><span class="line"><span class="meta">    @name.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">name</span>(<span class="params">self, name</span>):</span><br><span class="line">        <span class="variable language_">self</span>._name = name</span><br><span class="line"></span><br><span class="line"><span class="meta">    @age.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">age</span>(<span class="params">self, age</span>):</span><br><span class="line">        <span class="variable language_">self</span>._age = age</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">play</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>._age &lt; <span class="number">18</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;self._name&#125;</span>正在玩耍&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;self._name&#125;</span>正在学习&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">jiu_shu = Person(<span class="string">&#x27;久书&#x27;</span>, <span class="number">20</span>)</span><br><span class="line">jiu_shu.play()</span><br><span class="line">jiu_shu.age = <span class="number">10</span></span><br><span class="line">jiu_shu.play()</span><br></pre></td></tr></table></figure>

<h4 id="slots"><a href="#slots" class="headerlink" title="slots"></a><strong>slots</strong></h4><p>Python是一门<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%8A%A8%E6%80%81%E8%AF%AD%E8%A8%80">动态语言</a>。通常，动态语言允许我们在程序运行时给对象绑定新的属性或方法，当然也可以对已经绑定的属性和方法进行解绑定。但是如果我们需要限定自定义类型的对象只能绑定某些属性，可以通过在类中定义__slots__变量来进行限定<code>使用方法创建的对象属性仅为slots定义的属性</code>。需要注意的是__slots__的限定只对当前类的对象生效，对子类并不起任何作用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    __slots__ = (<span class="string">&#x27;_name&#x27;</span>, <span class="string">&#x27;_age&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, age</span>):</span><br><span class="line">        <span class="variable language_">self</span>._name = name</span><br><span class="line">        <span class="variable language_">self</span>._age = age</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">name</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._name</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">age</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._age</span><br><span class="line"></span><br><span class="line"><span class="meta">    @age.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">age</span>(<span class="params">self, age</span>):</span><br><span class="line">        <span class="variable language_">self</span>._age = age</span><br><span class="line"></span><br><span class="line"><span class="meta">    @name.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">name</span>(<span class="params">self, name</span>):</span><br><span class="line">        <span class="variable language_">self</span>._name = name</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">jiu_shu = Person(<span class="string">&#x27;jiu_shu&#x27;</span>,<span class="number">21</span>)</span><br><span class="line"><span class="built_in">print</span>(jiu_shu.name)</span><br><span class="line">jiu_shu._gander = <span class="string">&#x27;男&#x27;</span> <span class="comment"># AttributeError: &#x27;Person&#x27; object has no attribute &#x27;_gander&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="with关键字"><a href="#with关键字" class="headerlink" title="with关键字"></a>with关键字</h3><p>Python 中的 <strong>with</strong> 语句用于异常处理，封装了 <strong>try…except…finally</strong> 编码范式，提高了易用性。<strong>with</strong> 语句使代码更清晰、更具可读性， 它简化了文件流等公共资源的管理。在处理文件对象时使用 with 关键字是一种很好的做法。with 语句实现原理建立在上下文管理器之上。上下文管理器是一个实现 <strong>_<em>enter</em>_</strong> 和 <strong>_<em>exit</em>_</strong> 方法的类。使用 with 语句确保在嵌套块的末尾调用 _<em>exit</em>_ 方法。这个概念类似于 try…finally 块的使用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;loss&#x27;</span>):</span><br><span class="line">   <span class="comment"># 计算交叉熵损失</span></span><br><span class="line">   loss_cross_entropy = tf.losses.sparse_softmax_cross_entropy(<span class="variable language_">self</span>.label, <span class="variable language_">self</span>.pre_label,</span><br><span class="line">                                                                        		scope=<span class="string">&#x27;loss_cross_entropy&#x27;</span>)</span><br><span class="line">   loss_cross_entropy = tf.reduce_mean(loss_cross_entropy)</span><br><span class="line">   <span class="variable language_">self</span>.loss_total = loss_cross_entropy</span><br><span class="line">   <span class="comment"># 记录总损失</span></span><br><span class="line">   tf.summary.scalar(<span class="string">&#x27;loss_total&#x27;</span>, <span class="variable language_">self</span>.loss_total)</span><br></pre></td></tr></table></figure>




















































        
        
          <blockquote id="copyright">
              <p>Original link: <a href="http://example.com/index.html">http://example.com/index.html</a></p>
              <p>Copyright Notice: 转载请注明出处.</p>
          </blockquote>
        
      
    </div>
    <footer class="article-footer">
      
        <div class="article-tag-wrap">
          

          
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python%E5%AD%A6%E4%B9%A0/" rel="tag">python学习</a></li></ul>

          
    <div class="social-share">
      <span>Share:</span>
    </div>



        </div>
      
      
      
    </footer>
  </div>
</article>


  <article id="post-Git学习" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/05/20/Git%E5%AD%A6%E4%B9%A0/">git学习</a>
    </h1>
  


      </header>
    
    <div class="article-meta">
      
      <span class="article-date">
  <i class="fa fa-date"></i>
  <time class="dt-published" datetime="2024-05-20T10:25:37.000Z" itemprop="datePublished">2024年05月20日</time>
</span>
      
      
      
<a href="/2024/05/20/Git%E5%AD%A6%E4%B9%A0/#comments" class="article-comment-link">
  
  <i class="fa fa-commt"></i>
  Guestbook
</a>


    </div>
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Git学习"><a href="#Git学习" class="headerlink" title="Git学习"></a>Git学习</h1><h2 id="设置用户签名"><a href="#设置用户签名" class="headerlink" title="设置用户签名"></a>设置用户签名</h2><p>git config –global user.name 用户名</p>
<p>git config –global user.email 邮箱</p>
<p> 第一次使用时设置，否则提交代码时会报错</p>
<h2 id="初始化本地库"><a href="#初始化本地库" class="headerlink" title="初始化本地库"></a>初始化本地库</h2><p>git init </p>
<h2 id="查看本地库状态"><a href="#查看本地库状态" class="headerlink" title="查看本地库状态"></a>查看本地库状态</h2><p>git status</p>
<h2 id="添加文件至暂存区"><a href="#添加文件至暂存区" class="headerlink" title="添加文件至暂存区"></a>添加文件至暂存区</h2><p>git add 文件名(eg: hello.txt)</p>
<p>git add * : 提交全部文件至暂存区</p>
<h2 id="将暂存区文件添加到本地库"><a href="#将暂存区文件添加到本地库" class="headerlink" title="将暂存区文件添加到本地库"></a>将暂存区文件添加到本地库</h2><p>git commit -m “提交信息” 文件名</p>
<h2 id="查看提交日志"><a href="#查看提交日志" class="headerlink" title="查看提交日志"></a>查看提交日志</h2><p>git reflog</p>
<p>git log</p>
<h2 id="将本地仓库代码推送至远端仓库"><a href="#将本地仓库代码推送至远端仓库" class="headerlink" title="将本地仓库代码推送至远端仓库"></a>将本地仓库代码推送至远端仓库</h2><p>git push origin master</p>
<h2 id="版本穿梭"><a href="#版本穿梭" class="headerlink" title="版本穿梭"></a>版本穿梭</h2><p>git reset –hard 版本号</p>
<h2 id="Git分支操作"><a href="#Git分支操作" class="headerlink" title="Git分支操作"></a>Git分支操作</h2><h3 id="创建分支"><a href="#创建分支" class="headerlink" title="创建分支"></a>创建分支</h3><p>git branch 分支名</p>
<h3 id="查看分支"><a href="#查看分支" class="headerlink" title="查看分支"></a>查看分支</h3><p>git branch -v</p>
<h3 id="切换分支"><a href="#切换分支" class="headerlink" title="切换分支"></a>切换分支</h3><p>git checkout 分支名</p>
<h3 id="将指定的分支合并到当前分支"><a href="#将指定的分支合并到当前分支" class="headerlink" title="将指定的分支合并到当前分支"></a>将指定的分支合并到当前分支</h3><p>git merge 分支名</p>
<h2 id="合并冲突"><a href="#合并冲突" class="headerlink" title="合并冲突"></a>合并冲突</h2><p>1.手动修改冲突位置</p>
<p>2.添加至暂存区</p>
<p>3.提交到本地库（注意：此时git commit -m “信息” 后不能加任何文件名）</p>
<h2 id="查看别名"><a href="#查看别名" class="headerlink" title="查看别名"></a>查看别名</h2><p>git remote -v</p>
<h2 id="创建别名"><a href="#创建别名" class="headerlink" title="创建别名"></a>创建别名</h2><p>git remote add 别名 http链接（git仓库链接）</p>
<p>建议： 别名与项目名称一致</p>

        
        
          <blockquote id="copyright">
              <p>Original link: <a href="http://example.com/index.html">http://example.com/index.html</a></p>
              <p>Copyright Notice: 转载请注明出处.</p>
          </blockquote>
        
      
    </div>
    <footer class="article-footer">
      
        <div class="article-tag-wrap">
          

          
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/git-%E5%AD%A6%E4%B9%A0/" rel="tag">git 学习</a></li></ul>

          
    <div class="social-share">
      <span>Share:</span>
    </div>



        </div>
      
      
      
    </footer>
  </div>
</article>



</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fa fa-posts"></i> Recent</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/09/13/CNN%E4%BB%A3%E7%A0%81%E5%85%A5%E9%97%A8/">CNN代码入门</a>
          </li>
        
          <li>
            <a href="/2024/09/09/CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">CNN卷积神经网络</a>
          </li>
        
          <li>
            <a href="/2024/09/09/test/">test</a>
          </li>
        
          <li>
            <a href="/2024/07/01/NumPy/">NumPy</a>
          </li>
        
          <li>
            <a href="/2024/06/30/hexo%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8/">hexo博客使用</a>
          </li>
        
      </ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fa fa-tag"></i> Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CNN-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 10px;">CNN 图像处理</a> <a href="/tags/CNN-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">CNN 深度学习</a> <a href="/tags/NumPy/" style="font-size: 10px;">NumPy</a> <a href="/tags/git-%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">git 学习</a> <a href="/tags/python%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">python学习</a> <a href="/tags/%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8/" style="font-size: 10px;">博客使用</a> <a href="/tags/%E6%97%A5%E5%B8%B8%E7%A7%AF%E7%B4%AF/" style="font-size: 10px;">日常积累</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">深度学习</a>
    </div>
  </div>

  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fa fa-archive"></i> Archive</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/">2024年09月</a><span class="archive-list-count">9</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fa fa-tag"></i> Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" rel="tag">CNN 图像处理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">CNN 深度学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NumPy/" rel="tag">NumPy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git-%E5%AD%A6%E4%B9%A0/" rel="tag">git 学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python%E5%AD%A6%E4%B9%A0/" rel="tag">python学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8/" rel="tag">博客使用</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A5%E5%B8%B8%E7%A7%AF%E7%B4%AF/" rel="tag">日常积累</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>


  
    

  
</aside>
        
      </div>
      <a id="totop" href="#top"></a>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      <p>
        <a href="/sitemap.xml">Site Map</a>
        <span> | </span><a href="/atom.xml">Subscribe to this site</a>
        <span> | </span><a href="/about/">Contact the blogger</a>
      </p>
      
        <p>
          <i class="fa fa-visitors"></i>
          <i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>
          ，
          <i class="fa fa-views"></i>
          <i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>
        </p>
      
      <p>
        <span>Copyright &copy; 2024 John Doe.</span>
        <span>Theme by <a href="https://github.com/chaooo/hexo-theme-BlueLake/" target="_blank">BlueLake.</a></span>
        <span>Powered by <a href="https://hexo.io/" target="_blank">Hexo.</a></span>
      </p>
    </div>
  </div>
</footer>

    </div>
  </div>
  
<script src="/js/jquery-3.4.1.min.js"></script>


<script src="/js/search.json.js"></script>


  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>






  
<script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>








  



</body>
</html>